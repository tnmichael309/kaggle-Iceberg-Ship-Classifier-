{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_497</th>\n",
       "      <th>f_498</th>\n",
       "      <th>f_499</th>\n",
       "      <th>f_500</th>\n",
       "      <th>f_501</th>\n",
       "      <th>f_502</th>\n",
       "      <th>f_503</th>\n",
       "      <th>f_504</th>\n",
       "      <th>f_505</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.078176</td>\n",
       "      <td>0.358596</td>\n",
       "      <td>-0.215716</td>\n",
       "      <td>-0.372415</td>\n",
       "      <td>-1.290822</td>\n",
       "      <td>0.039064</td>\n",
       "      <td>0.134564</td>\n",
       "      <td>0.787661</td>\n",
       "      <td>-0.613845</td>\n",
       "      <td>0.108084</td>\n",
       "      <td>...</td>\n",
       "      <td>1.777018</td>\n",
       "      <td>-0.151202</td>\n",
       "      <td>0.480548</td>\n",
       "      <td>1.827665</td>\n",
       "      <td>0.479858</td>\n",
       "      <td>0.244300</td>\n",
       "      <td>0.729476</td>\n",
       "      <td>-1.061594</td>\n",
       "      <td>-0.839429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.273724</td>\n",
       "      <td>1.087702</td>\n",
       "      <td>-1.793496</td>\n",
       "      <td>-1.264303</td>\n",
       "      <td>0.042096</td>\n",
       "      <td>0.182288</td>\n",
       "      <td>0.078520</td>\n",
       "      <td>0.412620</td>\n",
       "      <td>0.980071</td>\n",
       "      <td>-1.091136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117945</td>\n",
       "      <td>-0.056131</td>\n",
       "      <td>-1.075378</td>\n",
       "      <td>-2.459079</td>\n",
       "      <td>0.350045</td>\n",
       "      <td>0.778946</td>\n",
       "      <td>-0.002505</td>\n",
       "      <td>-0.605706</td>\n",
       "      <td>-2.108809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.481582</td>\n",
       "      <td>-1.725730</td>\n",
       "      <td>0.391214</td>\n",
       "      <td>-1.857765</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>-0.145043</td>\n",
       "      <td>-0.434842</td>\n",
       "      <td>-0.503897</td>\n",
       "      <td>-0.264354</td>\n",
       "      <td>0.272160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059628</td>\n",
       "      <td>2.373542</td>\n",
       "      <td>-0.670700</td>\n",
       "      <td>-1.097062</td>\n",
       "      <td>-0.900625</td>\n",
       "      <td>0.762092</td>\n",
       "      <td>0.226062</td>\n",
       "      <td>0.464445</td>\n",
       "      <td>-1.965059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.089239</td>\n",
       "      <td>0.445182</td>\n",
       "      <td>0.128932</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>-0.324501</td>\n",
       "      <td>0.164366</td>\n",
       "      <td>0.122997</td>\n",
       "      <td>1.574274</td>\n",
       "      <td>-0.467762</td>\n",
       "      <td>0.552849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935038</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>-0.982558</td>\n",
       "      <td>-1.232302</td>\n",
       "      <td>-0.370637</td>\n",
       "      <td>-1.022586</td>\n",
       "      <td>0.878860</td>\n",
       "      <td>-0.016119</td>\n",
       "      <td>0.663128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.038766</td>\n",
       "      <td>0.221048</td>\n",
       "      <td>-0.418525</td>\n",
       "      <td>0.133892</td>\n",
       "      <td>-0.974831</td>\n",
       "      <td>-0.889494</td>\n",
       "      <td>0.028311</td>\n",
       "      <td>1.753731</td>\n",
       "      <td>-0.450525</td>\n",
       "      <td>0.435784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.918367</td>\n",
       "      <td>0.498966</td>\n",
       "      <td>0.385581</td>\n",
       "      <td>0.517203</td>\n",
       "      <td>-0.014826</td>\n",
       "      <td>1.858226</td>\n",
       "      <td>0.682199</td>\n",
       "      <td>0.906725</td>\n",
       "      <td>-0.257054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0 -1.078176  0.358596 -0.215716 -0.372415 -1.290822  0.039064  0.134564   \n",
       "1 -1.273724  1.087702 -1.793496 -1.264303  0.042096  0.182288  0.078520   \n",
       "2  0.481582 -1.725730  0.391214 -1.857765  0.999916 -0.145043 -0.434842   \n",
       "3 -1.089239  0.445182  0.128932  0.059036 -0.324501  0.164366  0.122997   \n",
       "4 -1.038766  0.221048 -0.418525  0.133892 -0.974831 -0.889494  0.028311   \n",
       "\n",
       "        f_7       f_8       f_9     ...         f_497     f_498     f_499  \\\n",
       "0  0.787661 -0.613845  0.108084     ...      1.777018 -0.151202  0.480548   \n",
       "1  0.412620  0.980071 -1.091136     ...      0.117945 -0.056131 -1.075378   \n",
       "2 -0.503897 -0.264354  0.272160     ...      0.059628  2.373542 -0.670700   \n",
       "3  1.574274 -0.467762  0.552849     ...      0.935038  0.164698 -0.982558   \n",
       "4  1.753731 -0.450525  0.435784     ...     -0.918367  0.498966  0.385581   \n",
       "\n",
       "      f_500     f_501     f_502     f_503     f_504     f_505  is_iceberg  \n",
       "0  1.827665  0.479858  0.244300  0.729476 -1.061594 -0.839429           0  \n",
       "1 -2.459079  0.350045  0.778946 -0.002505 -0.605706 -2.108809           0  \n",
       "2 -1.097062 -0.900625  0.762092  0.226062  0.464445 -1.965059           1  \n",
       "3 -1.232302 -0.370637 -1.022586  0.878860 -0.016119  0.663128           0  \n",
       "4  0.517203 -0.014826  1.858226  0.682199  0.906725 -0.257054           0  \n",
       "\n",
       "[5 rows x 507 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('Data/pca_projected_506_nc_from_resnet_train.csv')\n",
    "#train_df.reset_index(drop=True, inplace=True)\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 506) (1604,)\n"
     ]
    }
   ],
   "source": [
    "features = train_df.columns.tolist()\n",
    "features.remove('is_iceberg')\n",
    "\n",
    "train_X = train_df[features]\n",
    "train_y = np.array(train_df['is_iceberg']).reshape((train_X.shape[0],))\n",
    "\n",
    "print(train_X.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, SparsePCA, MiniBatchSparsePCA, KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "kfold = KFold(5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgb__boosting_type': 'gbdt'} -0.116621045968\n",
      "   mean_train_score  mean_test_score  std_test_score  \\\n",
      "1         -0.032865        -0.116621        0.028763   \n",
      "0         -0.073187        -0.123540        0.022169   \n",
      "\n",
      "                           params  rank_test_score  \n",
      "1  {'lgb__boosting_type': 'gbdt'}                1  \n",
      "0  {'lgb__boosting_type': 'dart'}                2  \n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, objective='binary', random_state=0, n_estimators=100)\n",
    "pca = PCA(whiten=False, random_state=0, n_components=30)\n",
    "pipe = Pipeline([\n",
    "    ('pca', pca),\n",
    "    ('lgb', lg_clf)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'lgb__boosting_type': ['dart', 'gbdt']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgb__learning_rate': 0.05, 'lgb__n_estimators': 100} -0.11563557816\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "4          -0.053173        -0.115636        0.026175   \n",
      "11         -0.039165        -0.116266        0.026461   \n",
      "5          -0.033234        -0.116307        0.027611   \n",
      "0          -0.032865        -0.116621        0.028763   \n",
      "10         -0.063028        -0.118136        0.024898   \n",
      "15         -0.063071        -0.118168        0.024959   \n",
      "6          -0.021453        -0.120740        0.030703   \n",
      "1          -0.021147        -0.121834        0.031711   \n",
      "7          -0.015080        -0.126744        0.033876   \n",
      "2          -0.014970        -0.128001        0.034876   \n",
      "3          -0.012849        -0.130976        0.036043   \n",
      "9          -0.129394        -0.163704        0.018741   \n",
      "14         -0.129536        -0.163812        0.018685   \n",
      "8          -0.252382        -0.271382        0.013413   \n",
      "13         -0.252635        -0.271632        0.013342   \n",
      "12         -0.396039        -0.405352        0.008474   \n",
      "\n",
      "                                               params  rank_test_score  \n",
      "4   {'lgb__learning_rate': 0.05, 'lgb__n_estimator...                1  \n",
      "11  {'lgb__learning_rate': 0.01, 'lgb__n_estimator...                2  \n",
      "5   {'lgb__learning_rate': 0.05, 'lgb__n_estimator...                3  \n",
      "0   {'lgb__learning_rate': 0.1, 'lgb__n_estimators...                4  \n",
      "10  {'lgb__learning_rate': 0.01, 'lgb__n_estimator...                5  \n",
      "15  {'lgb__learning_rate': 0.005, 'lgb__n_estimato...                6  \n",
      "6   {'lgb__learning_rate': 0.05, 'lgb__n_estimator...                7  \n",
      "1   {'lgb__learning_rate': 0.1, 'lgb__n_estimators...                8  \n",
      "7   {'lgb__learning_rate': 0.05, 'lgb__n_estimator...                9  \n",
      "2   {'lgb__learning_rate': 0.1, 'lgb__n_estimators...               10  \n",
      "3   {'lgb__learning_rate': 0.1, 'lgb__n_estimators...               11  \n",
      "9   {'lgb__learning_rate': 0.01, 'lgb__n_estimator...               12  \n",
      "14  {'lgb__learning_rate': 0.005, 'lgb__n_estimato...               13  \n",
      "8   {'lgb__learning_rate': 0.01, 'lgb__n_estimator...               14  \n",
      "13  {'lgb__learning_rate': 0.005, 'lgb__n_estimato...               15  \n",
      "12  {'lgb__learning_rate': 0.005, 'lgb__n_estimato...               16  \n",
      "[{'lgb__learning_rate': 0.05, 'lgb__n_estimators': 100}, {'lgb__learning_rate': 0.01, 'lgb__n_estimators': 800}, {'lgb__learning_rate': 0.05, 'lgb__n_estimators': 200}, {'lgb__learning_rate': 0.1, 'lgb__n_estimators': 100}, {'lgb__learning_rate': 0.01, 'lgb__n_estimators': 400}, {'lgb__learning_rate': 0.005, 'lgb__n_estimators': 800}, {'lgb__learning_rate': 0.05, 'lgb__n_estimators': 400}, {'lgb__learning_rate': 0.1, 'lgb__n_estimators': 200}, {'lgb__learning_rate': 0.05, 'lgb__n_estimators': 800}, {'lgb__learning_rate': 0.1, 'lgb__n_estimators': 400}, {'lgb__learning_rate': 0.1, 'lgb__n_estimators': 800}, {'lgb__learning_rate': 0.01, 'lgb__n_estimators': 200}, {'lgb__learning_rate': 0.005, 'lgb__n_estimators': 400}, {'lgb__learning_rate': 0.01, 'lgb__n_estimators': 100}, {'lgb__learning_rate': 0.005, 'lgb__n_estimators': 200}, {'lgb__learning_rate': 0.005, 'lgb__n_estimators': 100}]\n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, objective='binary', random_state=0, n_estimators=100, boosting_type='gbdt')\n",
    "pca = PCA(whiten=False, svd_solver='randomized', random_state=0, n_components=30)\n",
    "pipe = Pipeline([\n",
    "    ('pca', pca),\n",
    "    ('lgb', lg_clf)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'lgb__n_estimators': [100, 200, 400, 800],\n",
    "    'lgb__learning_rate': [0.1, 0.05, 0.01, 0.005]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)\n",
    "print(cv_df['params'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgb__min_split_gain': 0.2, 'lgb__num_leaves': 15} -0.11544658773\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "15         -0.054303        -0.115447        0.026319   \n",
      "16         -0.054303        -0.115447        0.026319   \n",
      "17         -0.054303        -0.115447        0.026319   \n",
      "9          -0.053572        -0.115556        0.026063   \n",
      "10         -0.053548        -0.115579        0.026026   \n",
      "11         -0.053548        -0.115579        0.026026   \n",
      "4          -0.053173        -0.115636        0.026175   \n",
      "5          -0.053173        -0.115643        0.026180   \n",
      "3          -0.053508        -0.116238        0.025849   \n",
      "2          -0.058423        -0.117316        0.024888   \n",
      "8          -0.058423        -0.117316        0.024888   \n",
      "14         -0.058471        -0.117317        0.024889   \n",
      "1          -0.097403        -0.122375        0.024696   \n",
      "7          -0.097403        -0.122375        0.024696   \n",
      "13         -0.097403        -0.122375        0.024696   \n",
      "0          -0.115947        -0.131350        0.023707   \n",
      "6          -0.115947        -0.131350        0.023707   \n",
      "12         -0.115947        -0.131350        0.023707   \n",
      "\n",
      "                                               params  rank_test_score  \n",
      "15  {'lgb__min_split_gain': 0.2, 'lgb__num_leaves'...                1  \n",
      "16  {'lgb__min_split_gain': 0.2, 'lgb__num_leaves'...                1  \n",
      "17  {'lgb__min_split_gain': 0.2, 'lgb__num_leaves'...                1  \n",
      "9   {'lgb__min_split_gain': 0.1, 'lgb__num_leaves'...                4  \n",
      "10  {'lgb__min_split_gain': 0.1, 'lgb__num_leaves'...                5  \n",
      "11  {'lgb__min_split_gain': 0.1, 'lgb__num_leaves'...                5  \n",
      "4   {'lgb__min_split_gain': 0.0, 'lgb__num_leaves'...                7  \n",
      "5   {'lgb__min_split_gain': 0.0, 'lgb__num_leaves'...                8  \n",
      "3   {'lgb__min_split_gain': 0.0, 'lgb__num_leaves'...                9  \n",
      "2   {'lgb__min_split_gain': 0.0, 'lgb__num_leaves'...               10  \n",
      "8   {'lgb__min_split_gain': 0.1, 'lgb__num_leaves'...               10  \n",
      "14  {'lgb__min_split_gain': 0.2, 'lgb__num_leaves'...               12  \n",
      "1   {'lgb__min_split_gain': 0.0, 'lgb__num_leaves'...               13  \n",
      "7   {'lgb__min_split_gain': 0.1, 'lgb__num_leaves'...               13  \n",
      "13  {'lgb__min_split_gain': 0.2, 'lgb__num_leaves'...               13  \n",
      "0   {'lgb__min_split_gain': 0.0, 'lgb__num_leaves'...               16  \n",
      "6   {'lgb__min_split_gain': 0.1, 'lgb__num_leaves'...               16  \n",
      "12  {'lgb__min_split_gain': 0.2, 'lgb__num_leaves'...               16  \n",
      "[{'lgb__min_split_gain': 0.2, 'lgb__num_leaves': 15}, {'lgb__min_split_gain': 0.2, 'lgb__num_leaves': 31}, {'lgb__min_split_gain': 0.2, 'lgb__num_leaves': 63}, {'lgb__min_split_gain': 0.1, 'lgb__num_leaves': 15}, {'lgb__min_split_gain': 0.1, 'lgb__num_leaves': 31}, {'lgb__min_split_gain': 0.1, 'lgb__num_leaves': 63}, {'lgb__min_split_gain': 0.0, 'lgb__num_leaves': 31}, {'lgb__min_split_gain': 0.0, 'lgb__num_leaves': 63}, {'lgb__min_split_gain': 0.0, 'lgb__num_leaves': 15}, {'lgb__min_split_gain': 0.0, 'lgb__num_leaves': 7}, {'lgb__min_split_gain': 0.1, 'lgb__num_leaves': 7}, {'lgb__min_split_gain': 0.2, 'lgb__num_leaves': 7}, {'lgb__min_split_gain': 0.0, 'lgb__num_leaves': 3}, {'lgb__min_split_gain': 0.1, 'lgb__num_leaves': 3}, {'lgb__min_split_gain': 0.2, 'lgb__num_leaves': 3}, {'lgb__min_split_gain': 0.0, 'lgb__num_leaves': 2}, {'lgb__min_split_gain': 0.1, 'lgb__num_leaves': 2}, {'lgb__min_split_gain': 0.2, 'lgb__num_leaves': 2}]\n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, objective='binary', random_state=0, \n",
    "                                 n_estimators=100, learning_rate=.05, boosting_type='gbdt')\n",
    "\n",
    "pca = PCA(whiten=False, svd_solver='randomized', random_state=0, n_components=30)\n",
    "pipe = Pipeline([\n",
    "    ('pca', pca),\n",
    "    ('lgb', lg_clf)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'lgb__num_leaves': [2, 3, 7, 15, 31, 63],\n",
    "    'lgb__min_split_gain': [.0, .1, .2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)\n",
    "print(cv_df['params'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgb__colsample_bytree': 1.0, 'lgb__subsample': 1.0} -0.11544658773\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "0          -0.054303        -0.115447        0.026319   \n",
      "5          -0.054258        -0.117008        0.025114   \n",
      "6          -0.062528        -0.117501        0.024364   \n",
      "1          -0.061434        -0.117604        0.023926   \n",
      "2          -0.073312        -0.120069        0.025598   \n",
      "7          -0.074029        -0.120953        0.024829   \n",
      "11         -0.066966        -0.121769        0.024284   \n",
      "8          -0.088773        -0.121864        0.023310   \n",
      "10         -0.058836        -0.122552        0.024147   \n",
      "3          -0.089145        -0.122616        0.025979   \n",
      "12         -0.078328        -0.124660        0.024033   \n",
      "13         -0.093593        -0.127141        0.025174   \n",
      "15         -0.066344        -0.127493        0.023990   \n",
      "16         -0.074648        -0.127825        0.024259   \n",
      "17         -0.085187        -0.128655        0.022738   \n",
      "9          -0.114660        -0.132916        0.024865   \n",
      "4          -0.115952        -0.133603        0.023129   \n",
      "18         -0.101141        -0.134385        0.022869   \n",
      "14         -0.117401        -0.135496        0.023676   \n",
      "19         -0.125734        -0.143292        0.022550   \n",
      "20         -0.100508        -0.165661        0.022814   \n",
      "21         -0.107966        -0.166853        0.022326   \n",
      "22         -0.119522        -0.170676        0.022105   \n",
      "23         -0.139313        -0.177325        0.021224   \n",
      "24         -0.181233        -0.204258        0.019169   \n",
      "\n",
      "                                               params  rank_test_score  \n",
      "0   {'lgb__colsample_bytree': 1.0, 'lgb__subsample...                1  \n",
      "5   {'lgb__colsample_bytree': 0.8, 'lgb__subsample...                2  \n",
      "6   {'lgb__colsample_bytree': 0.8, 'lgb__subsample...                3  \n",
      "1   {'lgb__colsample_bytree': 1.0, 'lgb__subsample...                4  \n",
      "2   {'lgb__colsample_bytree': 1.0, 'lgb__subsample...                5  \n",
      "7   {'lgb__colsample_bytree': 0.8, 'lgb__subsample...                6  \n",
      "11  {'lgb__colsample_bytree': 0.6, 'lgb__subsample...                7  \n",
      "8   {'lgb__colsample_bytree': 0.8, 'lgb__subsample...                8  \n",
      "10  {'lgb__colsample_bytree': 0.6, 'lgb__subsample...                9  \n",
      "3   {'lgb__colsample_bytree': 1.0, 'lgb__subsample...               10  \n",
      "12  {'lgb__colsample_bytree': 0.6, 'lgb__subsample...               11  \n",
      "13  {'lgb__colsample_bytree': 0.6, 'lgb__subsample...               12  \n",
      "15  {'lgb__colsample_bytree': 0.4, 'lgb__subsample...               13  \n",
      "16  {'lgb__colsample_bytree': 0.4, 'lgb__subsample...               14  \n",
      "17  {'lgb__colsample_bytree': 0.4, 'lgb__subsample...               15  \n",
      "9   {'lgb__colsample_bytree': 0.8, 'lgb__subsample...               16  \n",
      "4   {'lgb__colsample_bytree': 1.0, 'lgb__subsample...               17  \n",
      "18  {'lgb__colsample_bytree': 0.4, 'lgb__subsample...               18  \n",
      "14  {'lgb__colsample_bytree': 0.6, 'lgb__subsample...               19  \n",
      "19  {'lgb__colsample_bytree': 0.4, 'lgb__subsample...               20  \n",
      "20  {'lgb__colsample_bytree': 0.2, 'lgb__subsample...               21  \n",
      "21  {'lgb__colsample_bytree': 0.2, 'lgb__subsample...               22  \n",
      "22  {'lgb__colsample_bytree': 0.2, 'lgb__subsample...               23  \n",
      "23  {'lgb__colsample_bytree': 0.2, 'lgb__subsample...               24  \n",
      "24  {'lgb__colsample_bytree': 0.2, 'lgb__subsample...               25  \n",
      "[{'lgb__colsample_bytree': 1.0, 'lgb__subsample': 1.0}, {'lgb__colsample_bytree': 0.8, 'lgb__subsample': 1.0}, {'lgb__colsample_bytree': 0.8, 'lgb__subsample': 0.8}, {'lgb__colsample_bytree': 1.0, 'lgb__subsample': 0.8}, {'lgb__colsample_bytree': 1.0, 'lgb__subsample': 0.6}, {'lgb__colsample_bytree': 0.8, 'lgb__subsample': 0.6}, {'lgb__colsample_bytree': 0.6, 'lgb__subsample': 0.8}, {'lgb__colsample_bytree': 0.8, 'lgb__subsample': 0.4}, {'lgb__colsample_bytree': 0.6, 'lgb__subsample': 1.0}, {'lgb__colsample_bytree': 1.0, 'lgb__subsample': 0.4}, {'lgb__colsample_bytree': 0.6, 'lgb__subsample': 0.6}, {'lgb__colsample_bytree': 0.6, 'lgb__subsample': 0.4}, {'lgb__colsample_bytree': 0.4, 'lgb__subsample': 1.0}, {'lgb__colsample_bytree': 0.4, 'lgb__subsample': 0.8}, {'lgb__colsample_bytree': 0.4, 'lgb__subsample': 0.6}, {'lgb__colsample_bytree': 0.8, 'lgb__subsample': 0.2}, {'lgb__colsample_bytree': 1.0, 'lgb__subsample': 0.2}, {'lgb__colsample_bytree': 0.4, 'lgb__subsample': 0.4}, {'lgb__colsample_bytree': 0.6, 'lgb__subsample': 0.2}, {'lgb__colsample_bytree': 0.4, 'lgb__subsample': 0.2}, {'lgb__colsample_bytree': 0.2, 'lgb__subsample': 1.0}, {'lgb__colsample_bytree': 0.2, 'lgb__subsample': 0.8}, {'lgb__colsample_bytree': 0.2, 'lgb__subsample': 0.6}, {'lgb__colsample_bytree': 0.2, 'lgb__subsample': 0.4}, {'lgb__colsample_bytree': 0.2, 'lgb__subsample': 0.2}]\n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, objective='binary', random_state=0, \n",
    "                                 n_estimators=100, learning_rate=.05, boosting_type='gbdt',\n",
    "                                 num_leaves=15, min_split_gain=.2)\n",
    "\n",
    "pca = PCA(whiten=False, svd_solver='randomized', random_state=0, n_components=30)\n",
    "pipe = Pipeline([\n",
    "    ('pca', pca),\n",
    "    ('lgb', lg_clf)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'lgb__subsample': [1., .8, .6, .4, .2],\n",
    "    'lgb__colsample_bytree': [1., .8, .6, .4, .2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)\n",
    "print(cv_df['params'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgb__colsample_bytree': 1.0, 'lgb__subsample': 1.0} -0.11544658773\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "0          -0.054303        -0.115447        0.026319   \n",
      "4          -0.054162        -0.115714        0.026245   \n",
      "8          -0.054187        -0.115857        0.026426   \n",
      "5          -0.055299        -0.116719        0.026336   \n",
      "13         -0.055699        -0.116989        0.026439   \n",
      "12         -0.054228        -0.117189        0.026329   \n",
      "2          -0.057175        -0.117212        0.024620   \n",
      "1          -0.055470        -0.117239        0.025338   \n",
      "9          -0.055213        -0.117280        0.025298   \n",
      "6          -0.057453        -0.117743        0.025741   \n",
      "10         -0.057336        -0.118196        0.025404   \n",
      "14         -0.057688        -0.118217        0.026630   \n",
      "11         -0.060119        -0.118332        0.025538   \n",
      "7          -0.059177        -0.118357        0.026551   \n",
      "15         -0.060143        -0.118945        0.025779   \n",
      "3          -0.059334        -0.119567        0.025614   \n",
      "\n",
      "                                               params  rank_test_score  \n",
      "0   {'lgb__colsample_bytree': 1.0, 'lgb__subsample...                1  \n",
      "4   {'lgb__colsample_bytree': 0.95, 'lgb__subsampl...                2  \n",
      "8   {'lgb__colsample_bytree': 0.9, 'lgb__subsample...                3  \n",
      "5   {'lgb__colsample_bytree': 0.95, 'lgb__subsampl...                4  \n",
      "13  {'lgb__colsample_bytree': 0.85, 'lgb__subsampl...                5  \n",
      "12  {'lgb__colsample_bytree': 0.85, 'lgb__subsampl...                6  \n",
      "2   {'lgb__colsample_bytree': 1.0, 'lgb__subsample...                7  \n",
      "1   {'lgb__colsample_bytree': 1.0, 'lgb__subsample...                8  \n",
      "9   {'lgb__colsample_bytree': 0.9, 'lgb__subsample...                9  \n",
      "6   {'lgb__colsample_bytree': 0.95, 'lgb__subsampl...               10  \n",
      "10  {'lgb__colsample_bytree': 0.9, 'lgb__subsample...               11  \n",
      "14  {'lgb__colsample_bytree': 0.85, 'lgb__subsampl...               12  \n",
      "11  {'lgb__colsample_bytree': 0.9, 'lgb__subsample...               13  \n",
      "7   {'lgb__colsample_bytree': 0.95, 'lgb__subsampl...               14  \n",
      "15  {'lgb__colsample_bytree': 0.85, 'lgb__subsampl...               15  \n",
      "3   {'lgb__colsample_bytree': 1.0, 'lgb__subsample...               16  \n",
      "[{'lgb__colsample_bytree': 1.0, 'lgb__subsample': 1.0}, {'lgb__colsample_bytree': 0.95, 'lgb__subsample': 1.0}, {'lgb__colsample_bytree': 0.9, 'lgb__subsample': 1.0}, {'lgb__colsample_bytree': 0.95, 'lgb__subsample': 0.95}, {'lgb__colsample_bytree': 0.85, 'lgb__subsample': 0.95}, {'lgb__colsample_bytree': 0.85, 'lgb__subsample': 1.0}, {'lgb__colsample_bytree': 1.0, 'lgb__subsample': 0.9}, {'lgb__colsample_bytree': 1.0, 'lgb__subsample': 0.95}, {'lgb__colsample_bytree': 0.9, 'lgb__subsample': 0.95}, {'lgb__colsample_bytree': 0.95, 'lgb__subsample': 0.9}, {'lgb__colsample_bytree': 0.9, 'lgb__subsample': 0.9}, {'lgb__colsample_bytree': 0.85, 'lgb__subsample': 0.9}, {'lgb__colsample_bytree': 0.9, 'lgb__subsample': 0.85}, {'lgb__colsample_bytree': 0.95, 'lgb__subsample': 0.85}, {'lgb__colsample_bytree': 0.85, 'lgb__subsample': 0.85}, {'lgb__colsample_bytree': 1.0, 'lgb__subsample': 0.85}]\n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, objective='binary', random_state=0, \n",
    "                                 n_estimators=100, learning_rate=.05, boosting_type='gbdt',\n",
    "                                 num_leaves=15, min_split_gain=.2)\n",
    "\n",
    "pca = PCA(whiten=False, svd_solver='randomized', random_state=0, n_components=30)\n",
    "pipe = Pipeline([\n",
    "    ('pca', pca),\n",
    "    ('lgb', lg_clf)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'lgb__subsample': [1., .95, .9, .85],\n",
    "    'lgb__colsample_bytree': [1., .95, .9, .85]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)\n",
    "print(cv_df['params'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.1} -0.11540581195\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "47         -0.055158        -0.115406        0.025432   \n",
      "48         -0.054303        -0.115447        0.026319   \n",
      "46         -0.056152        -0.115774        0.025837   \n",
      "40         -0.056437        -0.115836        0.025787   \n",
      "41         -0.055563        -0.116099        0.025585   \n",
      "43         -0.059780        -0.116136        0.025169   \n",
      "44         -0.058757        -0.116141        0.025362   \n",
      "45         -0.057290        -0.116213        0.025499   \n",
      "42         -0.060885        -0.116227        0.025813   \n",
      "36         -0.060509        -0.116514        0.025184   \n",
      "30         -0.060330        -0.116608        0.025349   \n",
      "32         -0.058244        -0.116659        0.025546   \n",
      "39         -0.057365        -0.116662        0.024795   \n",
      "27         -0.058947        -0.116727        0.025503   \n",
      "34         -0.056902        -0.116836        0.025303   \n",
      "33         -0.057348        -0.116899        0.025203   \n",
      "24         -0.061048        -0.116915        0.024468   \n",
      "37         -0.059802        -0.116939        0.024425   \n",
      "21         -0.063767        -0.117006        0.025601   \n",
      "19         -0.060971        -0.117068        0.025065   \n",
      "22         -0.062857        -0.117187        0.025191   \n",
      "29         -0.061250        -0.117224        0.025883   \n",
      "25         -0.060090        -0.117237        0.026022   \n",
      "26         -0.059547        -0.117254        0.025624   \n",
      "35         -0.061417        -0.117296        0.025541   \n",
      "20         -0.060522        -0.117489        0.025977   \n",
      "28         -0.062305        -0.117525        0.025821   \n",
      "18         -0.061412        -0.117755        0.025429   \n",
      "5          -0.064360        -0.117781        0.026009   \n",
      "38         -0.058424        -0.117856        0.024592   \n",
      "16         -0.063531        -0.117927        0.025356   \n",
      "11         -0.063232        -0.117959        0.024651   \n",
      "15         -0.064228        -0.117969        0.024653   \n",
      "31         -0.059731        -0.118052        0.024807   \n",
      "23         -0.062175        -0.118175        0.025322   \n",
      "12         -0.062746        -0.118178        0.025418   \n",
      "6          -0.064054        -0.118341        0.025416   \n",
      "13         -0.062096        -0.118364        0.025326   \n",
      "17         -0.062438        -0.118394        0.025016   \n",
      "2          -0.066680        -0.118503        0.025181   \n",
      "4          -0.064922        -0.118555        0.025511   \n",
      "1          -0.067870        -0.118681        0.024443   \n",
      "14         -0.065297        -0.118810        0.025072   \n",
      "3          -0.065829        -0.118825        0.025202   \n",
      "8          -0.066210        -0.118887        0.024733   \n",
      "9          -0.065161        -0.118909        0.025796   \n",
      "10         -0.064228        -0.118925        0.025214   \n",
      "7          -0.066737        -0.119192        0.024848   \n",
      "0          -0.068620        -0.119625        0.024763   \n",
      "\n",
      "                                             params  rank_test_score  \n",
      "47  {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.1}                1  \n",
      "48  {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.0}                2  \n",
      "46  {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.2}                3  \n",
      "40  {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.1}                4  \n",
      "41  {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.0}                5  \n",
      "43  {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.8}                6  \n",
      "44  {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.6}                7  \n",
      "45  {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.4}                8  \n",
      "42  {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 1.0}                9  \n",
      "36  {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.8}               10  \n",
      "30  {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.6}               11  \n",
      "32  {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.2}               12  \n",
      "39  {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.2}               13  \n",
      "27  {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.0}               14  \n",
      "34  {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.0}               15  \n",
      "33  {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.1}               16  \n",
      "24  {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.4}               17  \n",
      "37  {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.6}               18  \n",
      "21  {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 1.0}               19  \n",
      "19  {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.1}               20  \n",
      "22  {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.8}               21  \n",
      "29  {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.8}               22  \n",
      "25  {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.2}               23  \n",
      "26  {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.1}               24  \n",
      "35  {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 1.0}               25  \n",
      "20  {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.0}               26  \n",
      "28  {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 1.0}               27  \n",
      "18  {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.2}               28  \n",
      "5   {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.1}               29  \n",
      "38  {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.4}               30  \n",
      "16  {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.6}               31  \n",
      "11  {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.2}               32  \n",
      "15  {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.8}               33  \n",
      "31  {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.4}               34  \n",
      "23  {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.6}               35  \n",
      "12  {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.1}               36  \n",
      "6   {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.0}               37  \n",
      "13  {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.0}               38  \n",
      "17  {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.4}               39  \n",
      "2   {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.6}               40  \n",
      "4   {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.2}               41  \n",
      "1   {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.8}               42  \n",
      "14  {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 1.0}               43  \n",
      "3   {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.4}               44  \n",
      "8   {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.8}               45  \n",
      "9   {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.6}               46  \n",
      "10  {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.4}               47  \n",
      "7   {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 1.0}               48  \n",
      "0   {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 1.0}               49  \n",
      "[{'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.1}, {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.0}, {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.2}, {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.1}, {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.0}, {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.8}, {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.6}, {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 0.4}, {'lgb__reg_alpha': 0.0, 'lgb__reg_lambda': 1.0}, {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.8}, {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.6}, {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.2}, {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.2}, {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.0}, {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.0}, {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.1}, {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.4}, {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.6}, {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 1.0}, {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.1}, {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.8}, {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.8}, {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.2}, {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.1}, {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 1.0}, {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.0}, {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 1.0}, {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.2}, {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.1}, {'lgb__reg_alpha': 0.1, 'lgb__reg_lambda': 0.4}, {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.6}, {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.2}, {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.8}, {'lgb__reg_alpha': 0.2, 'lgb__reg_lambda': 0.4}, {'lgb__reg_alpha': 0.4, 'lgb__reg_lambda': 0.6}, {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.1}, {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.0}, {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.0}, {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 0.4}, {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.6}, {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.2}, {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.8}, {'lgb__reg_alpha': 0.6, 'lgb__reg_lambda': 1.0}, {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 0.4}, {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.8}, {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.6}, {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 0.4}, {'lgb__reg_alpha': 0.8, 'lgb__reg_lambda': 1.0}, {'lgb__reg_alpha': 1.0, 'lgb__reg_lambda': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, objective='binary', random_state=0, \n",
    "                                 n_estimators=100, learning_rate=.05, boosting_type='gbdt',\n",
    "                                 num_leaves=15, min_split_gain=.2)\n",
    "\n",
    "pca = PCA(whiten=False, svd_solver='randomized', random_state=0, n_components=30)\n",
    "pipe = Pipeline([\n",
    "    ('pca', pca),\n",
    "    ('lgb', lg_clf)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'lgb__reg_alpha': [1., .8, .6, .4, .2, .1, .0],\n",
    "    'lgb__reg_lambda': [1., .8, .6, .4, .2, .1, .0]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)\n",
    "print(cv_df['params'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           f_0       f_1      f_10      f_11      f_12      f_13      f_14  \\\n",
      "0    -1.091220  0.450684  0.579754  0.631756  0.175730  0.246387 -0.798950   \n",
      "1    -1.296368  1.124568 -0.022570  0.925351 -0.571950  1.046042  1.303893   \n",
      "10    0.183570 -1.341081 -0.838703  2.923561  1.424435 -1.180463  0.400592   \n",
      "100  -1.218687  0.928520 -0.376063  0.209557 -0.349536 -1.756338  0.076930   \n",
      "1000 -0.309406 -1.530215  0.572226 -0.036990  0.142234  0.326848  0.178937   \n",
      "\n",
      "          f_15      f_16      f_17     ...          f_28      f_29       f_3  \\\n",
      "0    -0.052748 -0.472216 -0.184118     ...     -1.122193  1.526892  0.655805   \n",
      "1     0.040534 -1.066129  0.468961     ...     -0.978814  0.467171  1.264808   \n",
      "10   -0.320883 -0.340515 -0.131296     ...      0.923873 -0.961926  0.251447   \n",
      "100   0.668295 -1.337874 -1.051033     ...      0.008738  1.878277  0.109763   \n",
      "1000  1.578307 -0.153178 -1.820677     ...      0.475919 -2.289491 -1.302198   \n",
      "\n",
      "           f_4       f_5       f_6       f_7       f_8       f_9  is_iceberg  \n",
      "0     0.819764  0.149489 -1.073132  1.129250  0.604005 -0.206736           0  \n",
      "1    -0.038295 -0.210903  0.055941 -0.382279 -0.572397 -0.672330           0  \n",
      "10   -1.255631  0.429431 -0.641643 -1.060354  0.529670  2.937103           1  \n",
      "100   0.105483  0.677907  0.012663 -0.861458 -0.078810 -0.906812           0  \n",
      "1000  1.750927  0.087985 -0.272824  0.319011 -2.808802 -1.924617           0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "(1604, 30) (1604,)\n",
      "[-0.07727687 -0.14056895 -0.13347575 -0.13915516 -0.09915413]\n",
      "[ 0.00747387  0.85670272  0.00645475 ...,  0.00734621  0.99377095\n",
      "  0.00880876]\n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, objective='binary', random_state=0, \n",
    "                                 n_estimators=100, learning_rate=.05, boosting_type='gbdt',\n",
    "                                 num_leaves=15, min_split_gain=.2, reg_lambda=.1)\n",
    "\n",
    "\n",
    "train_df = pd.read_json('Data/pca_projected_30_from_fine_tune_resnet_train.json')\n",
    "print(train_df.head(5))\n",
    "\n",
    "features = train_df.columns.tolist()\n",
    "features.remove('is_iceberg')\n",
    "\n",
    "train_X = train_df[features]\n",
    "train_y = np.array(train_df['is_iceberg']).reshape((train_X.shape[0],))\n",
    "\n",
    "print(train_X.shape, train_y.shape)\n",
    "\n",
    "print(cross_val_score(lg_clf, X=train_X, y=train_y, scoring='neg_log_loss', cv=kfold))\n",
    "\n",
    "lg_clf.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "test_df = pd.read_json('Data/test.json')\n",
    "test_ids = test_df['id']\n",
    "del test_df\n",
    "\n",
    "test_df = pd.read_json('Data/pca_projected_30_from_fine_tune_resnet_test.json')\n",
    "test_df.sort_index(inplace=True)\n",
    "test_df.head(5)\n",
    "test_X = test_df[features]\n",
    "\n",
    "predictions = lg_clf.predict_proba(test_X)[:,1]\n",
    "print(predictions)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_ids\n",
    "submission['is_iceberg'] = predictions\n",
    "submission.to_csv('Submissions/submission_lgb_pca_30.csv', float_format=\"%.15f\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 4, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "print(xgboost.XGBClassifier(n_jobs=4).get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'dart'} -0.159207970604\n",
      "   mean_train_score  mean_test_score  std_test_score                 params  \\\n",
      "0         -0.015699        -0.159208        0.031826    {'booster': 'dart'}   \n",
      "1         -0.015699        -0.159208        0.031826  {'booster': 'gbtree'}   \n",
      "\n",
      "   rank_test_score  \n",
      "0                1  \n",
      "1                1  \n"
     ]
    }
   ],
   "source": [
    "xg_clf = xgboost.XGBClassifier(n_jobs=4, seed=0, objective='binary:logistic', eval_metric='logloss')\n",
    "params = {\n",
    "    'booster': ['dart', 'gbtree']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(xg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.005, 'n_estimators': 1200} -0.147295292216\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "18         -0.042416        -0.147295        0.025783   \n",
      "17         -0.069220        -0.147883        0.023979   \n",
      "11         -0.069102        -0.147886        0.023795   \n",
      "19         -0.025510        -0.150452        0.027202   \n",
      "12         -0.025392        -0.150715        0.026987   \n",
      "5          -0.015804        -0.158000        0.027958   \n",
      "13         -0.010925        -0.162649        0.028223   \n",
      "14         -0.006183        -0.173478        0.029533   \n",
      "6          -0.004321        -0.181741        0.031102   \n",
      "0          -0.004270        -0.183529        0.034884   \n",
      "10         -0.139377        -0.186034        0.015738   \n",
      "16         -0.139543        -0.186079        0.015785   \n",
      "7          -0.002308        -0.198716        0.032094   \n",
      "1          -0.002298        -0.200958        0.035170   \n",
      "8          -0.001855        -0.205807        0.032889   \n",
      "9          -0.001594        -0.209963        0.033045   \n",
      "3          -0.001581        -0.211885        0.036139   \n",
      "4          -0.001581        -0.211885        0.036139   \n",
      "2          -0.001587        -0.211966        0.036063   \n",
      "15         -0.261199        -0.287271        0.009751   \n",
      "\n",
      "                                            params  rank_test_score  \n",
      "18  {'learning_rate': 0.005, 'n_estimators': 1200}                1  \n",
      "17   {'learning_rate': 0.005, 'n_estimators': 800}                2  \n",
      "11    {'learning_rate': 0.01, 'n_estimators': 400}                3  \n",
      "19  {'learning_rate': 0.005, 'n_estimators': 1600}                4  \n",
      "12    {'learning_rate': 0.01, 'n_estimators': 800}                5  \n",
      "5     {'learning_rate': 0.05, 'n_estimators': 200}                6  \n",
      "13   {'learning_rate': 0.01, 'n_estimators': 1200}                7  \n",
      "14   {'learning_rate': 0.01, 'n_estimators': 1600}                8  \n",
      "6     {'learning_rate': 0.05, 'n_estimators': 400}                9  \n",
      "0      {'learning_rate': 0.1, 'n_estimators': 200}               10  \n",
      "10    {'learning_rate': 0.01, 'n_estimators': 200}               11  \n",
      "16   {'learning_rate': 0.005, 'n_estimators': 400}               12  \n",
      "7     {'learning_rate': 0.05, 'n_estimators': 800}               13  \n",
      "1      {'learning_rate': 0.1, 'n_estimators': 400}               14  \n",
      "8    {'learning_rate': 0.05, 'n_estimators': 1200}               15  \n",
      "9    {'learning_rate': 0.05, 'n_estimators': 1600}               16  \n",
      "3     {'learning_rate': 0.1, 'n_estimators': 1200}               17  \n",
      "4     {'learning_rate': 0.1, 'n_estimators': 1600}               18  \n",
      "2      {'learning_rate': 0.1, 'n_estimators': 800}               19  \n",
      "15   {'learning_rate': 0.005, 'n_estimators': 200}               20  \n"
     ]
    }
   ],
   "source": [
    "xg_clf = xgboost.XGBClassifier(n_jobs=4, seed=0, \n",
    "                               objective='binary:logistic', eval_metric='logloss', \n",
    "                               booster='dart')\n",
    "params = {\n",
    "    'n_estimators': [200, 400, 800, 1200, 1600],\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(xg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3} -0.147882765844\n",
      "   mean_train_score  mean_test_score  std_test_score            params  \\\n",
      "1         -0.069220        -0.147883        0.023979  {'max_depth': 3}   \n",
      "2         -0.028266        -0.151612        0.023184  {'max_depth': 5}   \n",
      "0         -0.138066        -0.152458        0.020724  {'max_depth': 1}   \n",
      "3         -0.026659        -0.152860        0.026972  {'max_depth': 7}   \n",
      "4         -0.026567        -0.153167        0.027042  {'max_depth': 9}   \n",
      "\n",
      "   rank_test_score  \n",
      "1                1  \n",
      "2                2  \n",
      "0                3  \n",
      "3                4  \n",
      "4                5  \n"
     ]
    }
   ],
   "source": [
    "xg_clf = xgboost.XGBClassifier(n_jobs=4, seed=0, \n",
    "                               objective='binary:logistic', eval_metric='logloss', \n",
    "                               booster='dart',\n",
    "                               n_estimators=800,\n",
    "                               learning_rate=0.005)\n",
    "                \n",
    "params = {\n",
    "    'max_depth': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(xg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b8a289f6c862>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxg_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_log_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mcv_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 638\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[0;32m    505\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 896\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    897\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xg_clf = xgboost.XGBClassifier(n_jobs=4, seed=0, \n",
    "                               objective='binary:logistic', eval_metric='logloss', \n",
    "                               booster='dart',\n",
    "                               n_estimators=800,\n",
    "                               learning_rate=0.005)\n",
    "params = {\n",
    "    'min_child_weight': [1, 2, 4, 6, 8, 10]\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(xg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1.0, 'subsample': 0.8} -0.143585299155\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "1          -0.092684        -0.143585        0.022723   \n",
      "0          -0.088437        -0.143613        0.023551   \n",
      "2          -0.102406        -0.145123        0.022285   \n",
      "6          -0.099024        -0.146476        0.022311   \n",
      "7          -0.107390        -0.147568        0.022134   \n",
      "5          -0.095441        -0.148552        0.023668   \n",
      "3          -0.118837        -0.149041        0.021774   \n",
      "8          -0.121595        -0.150417        0.021840   \n",
      "11         -0.112972        -0.156757        0.020458   \n",
      "12         -0.120831        -0.157825        0.020431   \n",
      "10         -0.108784        -0.159493        0.021847   \n",
      "13         -0.132032        -0.161072        0.019744   \n",
      "4          -0.147755        -0.161485        0.020825   \n",
      "9          -0.147705        -0.162819        0.021399   \n",
      "14         -0.152582        -0.169873        0.019269   \n",
      "15         -0.134553        -0.180512        0.019815   \n",
      "16         -0.141432        -0.182460        0.019498   \n",
      "17         -0.149139        -0.184171        0.019044   \n",
      "18         -0.159177        -0.189323        0.018471   \n",
      "19         -0.181935        -0.203840        0.015525   \n",
      "20         -0.201333        -0.248038        0.017489   \n",
      "21         -0.208164        -0.252495        0.016526   \n",
      "22         -0.217057        -0.257840        0.016731   \n",
      "23         -0.229888        -0.268145        0.015747   \n",
      "24         -0.263473        -0.297457        0.014106   \n",
      "\n",
      "                                         params  rank_test_score  \n",
      "1   {'colsample_bytree': 1.0, 'subsample': 0.8}                1  \n",
      "0   {'colsample_bytree': 1.0, 'subsample': 1.0}                2  \n",
      "2   {'colsample_bytree': 1.0, 'subsample': 0.6}                3  \n",
      "6   {'colsample_bytree': 0.8, 'subsample': 0.8}                4  \n",
      "7   {'colsample_bytree': 0.8, 'subsample': 0.6}                5  \n",
      "5   {'colsample_bytree': 0.8, 'subsample': 1.0}                6  \n",
      "3   {'colsample_bytree': 1.0, 'subsample': 0.4}                7  \n",
      "8   {'colsample_bytree': 0.8, 'subsample': 0.4}                8  \n",
      "11  {'colsample_bytree': 0.6, 'subsample': 0.8}                9  \n",
      "12  {'colsample_bytree': 0.6, 'subsample': 0.6}               10  \n",
      "10  {'colsample_bytree': 0.6, 'subsample': 1.0}               11  \n",
      "13  {'colsample_bytree': 0.6, 'subsample': 0.4}               12  \n",
      "4   {'colsample_bytree': 1.0, 'subsample': 0.2}               13  \n",
      "9   {'colsample_bytree': 0.8, 'subsample': 0.2}               14  \n",
      "14  {'colsample_bytree': 0.6, 'subsample': 0.2}               15  \n",
      "15  {'colsample_bytree': 0.4, 'subsample': 1.0}               16  \n",
      "16  {'colsample_bytree': 0.4, 'subsample': 0.8}               17  \n",
      "17  {'colsample_bytree': 0.4, 'subsample': 0.6}               18  \n",
      "18  {'colsample_bytree': 0.4, 'subsample': 0.4}               19  \n",
      "19  {'colsample_bytree': 0.4, 'subsample': 0.2}               20  \n",
      "20  {'colsample_bytree': 0.2, 'subsample': 1.0}               21  \n",
      "21  {'colsample_bytree': 0.2, 'subsample': 0.8}               22  \n",
      "22  {'colsample_bytree': 0.2, 'subsample': 0.6}               23  \n",
      "23  {'colsample_bytree': 0.2, 'subsample': 0.4}               24  \n",
      "24  {'colsample_bytree': 0.2, 'subsample': 0.2}               25  \n"
     ]
    }
   ],
   "source": [
    "xg_clf = xgboost.XGBClassifier(n_jobs=6, seed=0, \n",
    "                               objective='binary:logistic', eval_metric='logloss', \n",
    "                               booster='dart',\n",
    "                               n_estimators=800,\n",
    "                               learning_rate=0.005,\n",
    "                               gamma=0.2,\n",
    "                               min_child_weight=8)\n",
    "params = {\n",
    "    'colsample_bytree': [1., .8, .6, .4, .2],\n",
    "    'subsample': [1., .8, .6, .4, .2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(xg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1.0, 'subsample': 0.85} -0.143356138068\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "1          -0.090831        -0.143356        0.022237   \n",
      "7          -0.094013        -0.143523        0.022745   \n",
      "0          -0.089346        -0.143580        0.022947   \n",
      "2          -0.092684        -0.143585        0.022723   \n",
      "5          -0.090772        -0.143614        0.022808   \n",
      "6          -0.092252        -0.143789        0.022444   \n",
      "3          -0.094603        -0.143980        0.022185   \n",
      "12         -0.095264        -0.144174        0.022559   \n",
      "8          -0.095914        -0.144186        0.022408   \n",
      "4          -0.096892        -0.144240        0.021775   \n",
      "10         -0.092174        -0.144455        0.022903   \n",
      "11         -0.093606        -0.144538        0.022342   \n",
      "9          -0.098195        -0.144760        0.022157   \n",
      "16         -0.095040        -0.144802        0.022252   \n",
      "17         -0.096703        -0.144856        0.022192   \n",
      "15         -0.093457        -0.144863        0.022771   \n",
      "13         -0.097346        -0.145009        0.022639   \n",
      "18         -0.098676        -0.145438        0.022265   \n",
      "14         -0.099478        -0.145494        0.022364   \n",
      "19         -0.100797        -0.145606        0.022294   \n",
      "\n",
      "                                           params  rank_test_score  \n",
      "1    {'colsample_bytree': 1.0, 'subsample': 0.85}                1  \n",
      "7    {'colsample_bytree': 0.95, 'subsample': 0.8}                2  \n",
      "0     {'colsample_bytree': 1.0, 'subsample': 0.9}                3  \n",
      "2     {'colsample_bytree': 1.0, 'subsample': 0.8}                4  \n",
      "5    {'colsample_bytree': 0.95, 'subsample': 0.9}                5  \n",
      "6   {'colsample_bytree': 0.95, 'subsample': 0.85}                6  \n",
      "3    {'colsample_bytree': 1.0, 'subsample': 0.75}                7  \n",
      "12    {'colsample_bytree': 0.9, 'subsample': 0.8}                8  \n",
      "8   {'colsample_bytree': 0.95, 'subsample': 0.75}                9  \n",
      "4     {'colsample_bytree': 1.0, 'subsample': 0.7}               10  \n",
      "10    {'colsample_bytree': 0.9, 'subsample': 0.9}               11  \n",
      "11   {'colsample_bytree': 0.9, 'subsample': 0.85}               12  \n",
      "9    {'colsample_bytree': 0.95, 'subsample': 0.7}               13  \n",
      "16  {'colsample_bytree': 0.85, 'subsample': 0.85}               14  \n",
      "17   {'colsample_bytree': 0.85, 'subsample': 0.8}               15  \n",
      "15   {'colsample_bytree': 0.85, 'subsample': 0.9}               16  \n",
      "13   {'colsample_bytree': 0.9, 'subsample': 0.75}               17  \n",
      "18  {'colsample_bytree': 0.85, 'subsample': 0.75}               18  \n",
      "14    {'colsample_bytree': 0.9, 'subsample': 0.7}               19  \n",
      "19   {'colsample_bytree': 0.85, 'subsample': 0.7}               20  \n"
     ]
    }
   ],
   "source": [
    "xg_clf = xgboost.XGBClassifier(n_jobs=6, seed=0, \n",
    "                               objective='binary:logistic', eval_metric='logloss', \n",
    "                               booster='dart',\n",
    "                               n_estimators=800,\n",
    "                               learning_rate=0.005,\n",
    "                               gamma=0.2,\n",
    "                               min_child_weight=8)\n",
    "params = {\n",
    "    'colsample_bytree': [1., .95, .9, .85],\n",
    "    'subsample': [.9, .85, .8, .75, .7]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(xg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0.0, 'reg_lambda': 0.0} -0.142308869044\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "0          -0.086888        -0.142309        0.022346   \n",
      "6          -0.087782        -0.142661        0.022245   \n",
      "1          -0.087603        -0.142719        0.022267   \n",
      "2          -0.088394        -0.142814        0.022232   \n",
      "7          -0.088575        -0.142873        0.022497   \n",
      "12         -0.088867        -0.142968        0.022504   \n",
      "3          -0.089091        -0.143043        0.022105   \n",
      "8          -0.089389        -0.143225        0.022317   \n",
      "18         -0.090191        -0.143242        0.022297   \n",
      "9          -0.090354        -0.143281        0.022178   \n",
      "4          -0.089914        -0.143287        0.022169   \n",
      "13         -0.089855        -0.143296        0.022280   \n",
      "5          -0.090831        -0.143356        0.022237   \n",
      "14         -0.090739        -0.143372        0.022169   \n",
      "15         -0.091555        -0.143413        0.022252   \n",
      "19         -0.091118        -0.143426        0.022327   \n",
      "10         -0.091235        -0.143437        0.022135   \n",
      "24         -0.091508        -0.143468        0.022471   \n",
      "20         -0.091939        -0.143470        0.022195   \n",
      "25         -0.092460        -0.143519        0.022279   \n",
      "11         -0.091973        -0.143584        0.022206   \n",
      "30         -0.092937        -0.143615        0.022371   \n",
      "16         -0.092338        -0.143695        0.022191   \n",
      "26         -0.093327        -0.143749        0.022261   \n",
      "21         -0.092803        -0.143754        0.022292   \n",
      "31         -0.093754        -0.143769        0.022248   \n",
      "22         -0.093627        -0.143863        0.022208   \n",
      "17         -0.093156        -0.143943        0.022288   \n",
      "27         -0.094153        -0.144019        0.022314   \n",
      "32         -0.094519        -0.144111        0.022147   \n",
      "28         -0.094899        -0.144305        0.022259   \n",
      "23         -0.094431        -0.144310        0.022319   \n",
      "33         -0.095318        -0.144392        0.022292   \n",
      "29         -0.095658        -0.144392        0.022331   \n",
      "34         -0.096011        -0.144515        0.022344   \n",
      "35         -0.096745        -0.144649        0.022365   \n",
      "\n",
      "                                   params  rank_test_score  \n",
      "0   {'reg_alpha': 0.0, 'reg_lambda': 0.0}                1  \n",
      "6   {'reg_alpha': 0.2, 'reg_lambda': 0.0}                2  \n",
      "1   {'reg_alpha': 0.0, 'reg_lambda': 0.2}                3  \n",
      "2   {'reg_alpha': 0.0, 'reg_lambda': 0.4}                4  \n",
      "7   {'reg_alpha': 0.2, 'reg_lambda': 0.2}                5  \n",
      "12  {'reg_alpha': 0.4, 'reg_lambda': 0.0}                6  \n",
      "3   {'reg_alpha': 0.0, 'reg_lambda': 0.6}                7  \n",
      "8   {'reg_alpha': 0.2, 'reg_lambda': 0.4}                8  \n",
      "18  {'reg_alpha': 0.6, 'reg_lambda': 0.0}                9  \n",
      "9   {'reg_alpha': 0.2, 'reg_lambda': 0.6}               10  \n",
      "4   {'reg_alpha': 0.0, 'reg_lambda': 0.8}               11  \n",
      "13  {'reg_alpha': 0.4, 'reg_lambda': 0.2}               12  \n",
      "5   {'reg_alpha': 0.0, 'reg_lambda': 1.0}               13  \n",
      "14  {'reg_alpha': 0.4, 'reg_lambda': 0.4}               14  \n",
      "15  {'reg_alpha': 0.4, 'reg_lambda': 0.6}               15  \n",
      "19  {'reg_alpha': 0.6, 'reg_lambda': 0.2}               16  \n",
      "10  {'reg_alpha': 0.2, 'reg_lambda': 0.8}               17  \n",
      "24  {'reg_alpha': 0.8, 'reg_lambda': 0.0}               18  \n",
      "20  {'reg_alpha': 0.6, 'reg_lambda': 0.4}               19  \n",
      "25  {'reg_alpha': 0.8, 'reg_lambda': 0.2}               20  \n",
      "11  {'reg_alpha': 0.2, 'reg_lambda': 1.0}               21  \n",
      "30  {'reg_alpha': 1.0, 'reg_lambda': 0.0}               22  \n",
      "16  {'reg_alpha': 0.4, 'reg_lambda': 0.8}               23  \n",
      "26  {'reg_alpha': 0.8, 'reg_lambda': 0.4}               24  \n",
      "21  {'reg_alpha': 0.6, 'reg_lambda': 0.6}               25  \n",
      "31  {'reg_alpha': 1.0, 'reg_lambda': 0.2}               26  \n",
      "22  {'reg_alpha': 0.6, 'reg_lambda': 0.8}               27  \n",
      "17  {'reg_alpha': 0.4, 'reg_lambda': 1.0}               28  \n",
      "27  {'reg_alpha': 0.8, 'reg_lambda': 0.6}               29  \n",
      "32  {'reg_alpha': 1.0, 'reg_lambda': 0.4}               30  \n",
      "28  {'reg_alpha': 0.8, 'reg_lambda': 0.8}               31  \n",
      "23  {'reg_alpha': 0.6, 'reg_lambda': 1.0}               32  \n",
      "33  {'reg_alpha': 1.0, 'reg_lambda': 0.6}               33  \n",
      "29  {'reg_alpha': 0.8, 'reg_lambda': 1.0}               34  \n",
      "34  {'reg_alpha': 1.0, 'reg_lambda': 0.8}               35  \n",
      "35  {'reg_alpha': 1.0, 'reg_lambda': 1.0}               36  \n"
     ]
    }
   ],
   "source": [
    "xg_clf = xgboost.XGBClassifier(n_jobs=2, seed=0, \n",
    "                               objective='binary:logistic', eval_metric='logloss', \n",
    "                               booster='dart',\n",
    "                               n_estimators=800,\n",
    "                               learning_rate=0.005,\n",
    "                               gamma=0.2,\n",
    "                               min_child_weight=8,\n",
    "                               colsample_bytree=1.,\n",
    "                               subsample=.85)\n",
    "params = {\n",
    "    'reg_alpha': [0., .2, .4, .6, .8, 1.],\n",
    "    'reg_lambda': [0., .2, .4, .6, .8, 1.]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(xg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0.0, 'reg_lambda': 0.0} -0.142308869044\n",
      "   mean_train_score  mean_test_score  std_test_score  \\\n",
      "0         -0.086888        -0.142309        0.022346   \n",
      "1         -0.087074        -0.142350        0.022236   \n",
      "2         -0.087116        -0.142395        0.022226   \n",
      "3         -0.087262        -0.142418        0.022251   \n",
      "\n",
      "                                    params  rank_test_score  \n",
      "0    {'reg_alpha': 0.0, 'reg_lambda': 0.0}                1  \n",
      "1   {'reg_alpha': 0.0, 'reg_lambda': 0.05}                2  \n",
      "2   {'reg_alpha': 0.05, 'reg_lambda': 0.0}                3  \n",
      "3  {'reg_alpha': 0.05, 'reg_lambda': 0.05}                4  \n"
     ]
    }
   ],
   "source": [
    "xg_clf = xgboost.XGBClassifier(n_jobs=6, seed=0, \n",
    "                               objective='binary:logistic', eval_metric='logloss', \n",
    "                               booster='dart',\n",
    "                               n_estimators=800,\n",
    "                               learning_rate=0.005,\n",
    "                               gamma=0.2,\n",
    "                               min_child_weight=8,\n",
    "                               colsample_bytree=1.,\n",
    "                               subsample=.85)\n",
    "params = {\n",
    "    'reg_alpha': [0., .05],\n",
    "    'reg_lambda': [0., .05]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(xg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': 0} -0.142308869044\n",
      "   mean_train_score  mean_test_score  std_test_score               params  \\\n",
      "0         -0.086888        -0.142309        0.022346  {'random_state': 0}   \n",
      "1         -0.086888        -0.142309        0.022346  {'random_state': 1}   \n",
      "2         -0.086888        -0.142309        0.022346  {'random_state': 2}   \n",
      "3         -0.086888        -0.142309        0.022346  {'random_state': 3}   \n",
      "4         -0.086888        -0.142309        0.022346  {'random_state': 4}   \n",
      "5         -0.086888        -0.142309        0.022346  {'random_state': 5}   \n",
      "\n",
      "   rank_test_score  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "3                1  \n",
      "4                1  \n",
      "5                1  \n"
     ]
    }
   ],
   "source": [
    "xg_clf = xgboost.XGBClassifier(n_jobs=6, seed=0, \n",
    "                               objective='binary:logistic', eval_metric='logloss', \n",
    "                               booster='dart',\n",
    "                               n_estimators=800,\n",
    "                               learning_rate=0.005,\n",
    "                               gamma=0.2,\n",
    "                               min_child_weight=8,\n",
    "                               colsample_bytree=1.,\n",
    "                               subsample=.85,\n",
    "                               reg_alpha=.0,\n",
    "                               reg_lambda=.0)\n",
    "params = {\n",
    "    'random_state': [0, 1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(xg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_bin': 255, 'max_depth': -1, 'min_child_samples': 10, 'min_child_weight': 5, 'min_split_gain': 0.0, 'n_estimators': 10, 'n_jobs': 4, 'num_leaves': 31, 'objective': None, 'random_state': 0, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 1.0, 'subsample_for_bin': 50000, 'subsample_freq': 1}\n"
     ]
    }
   ],
   "source": [
    "print(lightgbm.LGBMClassifier(n_jobs=4).get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'dart'} -0.147456417265\n",
      "   mean_train_score  mean_test_score  std_test_score  \\\n",
      "0         -0.063662        -0.147456        0.021195   \n",
      "1         -0.019692        -0.153182        0.032813   \n",
      "\n",
      "                      params  rank_test_score  \n",
      "0  {'boosting_type': 'dart'}                1  \n",
      "1  {'boosting_type': 'gbdt'}                2  \n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, objective='binary', random_state=0, n_estimators=100)\n",
    "params = {\n",
    "    'boosting_type': ['dart', 'gbdt']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(lg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'n_estimators': 400} -0.142953260489\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "6          -0.044408        -0.142953        0.022675   \n",
      "1          -0.037767        -0.143472        0.023018   \n",
      "0          -0.063662        -0.147456        0.021195   \n",
      "7          -0.023997        -0.148801        0.027458   \n",
      "2          -0.025454        -0.149098        0.025622   \n",
      "5          -0.084108        -0.156178        0.018160   \n",
      "3          -0.015780        -0.158232        0.030288   \n",
      "11         -0.123110        -0.179539        0.014419   \n",
      "4          -0.147895        -0.198235        0.014052   \n",
      "15         -0.247622        -0.278105        0.012298   \n",
      "10         -0.261789        -0.290695        0.011888   \n",
      "9          -0.369633        -0.388232        0.008326   \n",
      "14         -0.401139        -0.417383        0.007489   \n",
      "8          -0.458342        -0.470542        0.005942   \n",
      "13         -0.492299        -0.502411        0.005045   \n",
      "12         -0.556524        -0.562869        0.003425   \n",
      "\n",
      "                                           params  rank_test_score  \n",
      "6    {'learning_rate': 0.05, 'n_estimators': 400}                1  \n",
      "1     {'learning_rate': 0.1, 'n_estimators': 200}                2  \n",
      "0     {'learning_rate': 0.1, 'n_estimators': 100}                3  \n",
      "7    {'learning_rate': 0.05, 'n_estimators': 800}                4  \n",
      "2     {'learning_rate': 0.1, 'n_estimators': 400}                5  \n",
      "5    {'learning_rate': 0.05, 'n_estimators': 200}                6  \n",
      "3     {'learning_rate': 0.1, 'n_estimators': 800}                7  \n",
      "11   {'learning_rate': 0.01, 'n_estimators': 800}                8  \n",
      "4    {'learning_rate': 0.05, 'n_estimators': 100}                9  \n",
      "15  {'learning_rate': 0.005, 'n_estimators': 800}               10  \n",
      "10   {'learning_rate': 0.01, 'n_estimators': 400}               11  \n",
      "9    {'learning_rate': 0.01, 'n_estimators': 200}               12  \n",
      "14  {'learning_rate': 0.005, 'n_estimators': 400}               13  \n",
      "8    {'learning_rate': 0.01, 'n_estimators': 100}               14  \n",
      "13  {'learning_rate': 0.005, 'n_estimators': 200}               15  \n",
      "12  {'learning_rate': 0.005, 'n_estimators': 100}               16  \n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, objective='binary', random_state=0, boosting_type='dart')\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 400, 800],\n",
    "    'learning_rate': [0.1, 0.05, 0.01, 0.005]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(lg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_split_gain': 0.2, 'num_leaves': 7} -0.141689966591\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "14         -0.049747        -0.141690        0.023308   \n",
      "9          -0.044263        -0.142117        0.022428   \n",
      "16         -0.044388        -0.142126        0.022325   \n",
      "17         -0.044388        -0.142126        0.022325   \n",
      "10         -0.044167        -0.142142        0.022242   \n",
      "11         -0.044167        -0.142142        0.022242   \n",
      "15         -0.044359        -0.142258        0.021590   \n",
      "2          -0.049720        -0.142365        0.022238   \n",
      "8          -0.049720        -0.142365        0.022238   \n",
      "3          -0.044196        -0.142749        0.022281   \n",
      "5          -0.044251        -0.142908        0.022564   \n",
      "4          -0.044408        -0.142953        0.022675   \n",
      "1          -0.112001        -0.146778        0.023006   \n",
      "7          -0.112001        -0.146778        0.023006   \n",
      "13         -0.112001        -0.146778        0.023006   \n",
      "0          -0.137774        -0.152350        0.022580   \n",
      "6          -0.137774        -0.152350        0.022580   \n",
      "12         -0.137774        -0.152350        0.022580   \n",
      "\n",
      "                                       params  rank_test_score  \n",
      "14   {'min_split_gain': 0.2, 'num_leaves': 7}                1  \n",
      "9   {'min_split_gain': 0.1, 'num_leaves': 15}                2  \n",
      "16  {'min_split_gain': 0.2, 'num_leaves': 31}                3  \n",
      "17  {'min_split_gain': 0.2, 'num_leaves': 63}                3  \n",
      "10  {'min_split_gain': 0.1, 'num_leaves': 31}                5  \n",
      "11  {'min_split_gain': 0.1, 'num_leaves': 63}                5  \n",
      "15  {'min_split_gain': 0.2, 'num_leaves': 15}                7  \n",
      "2    {'min_split_gain': 0.0, 'num_leaves': 7}                8  \n",
      "8    {'min_split_gain': 0.1, 'num_leaves': 7}                8  \n",
      "3   {'min_split_gain': 0.0, 'num_leaves': 15}               10  \n",
      "5   {'min_split_gain': 0.0, 'num_leaves': 63}               11  \n",
      "4   {'min_split_gain': 0.0, 'num_leaves': 31}               12  \n",
      "1    {'min_split_gain': 0.0, 'num_leaves': 3}               13  \n",
      "7    {'min_split_gain': 0.1, 'num_leaves': 3}               13  \n",
      "13   {'min_split_gain': 0.2, 'num_leaves': 3}               13  \n",
      "0    {'min_split_gain': 0.0, 'num_leaves': 2}               16  \n",
      "6    {'min_split_gain': 0.1, 'num_leaves': 2}               16  \n",
      "12   {'min_split_gain': 0.2, 'num_leaves': 2}               16  \n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=0,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=400,\n",
    "                                 learning_rate=0.05)\n",
    "params = {\n",
    "    'num_leaves': [2, 3, 7, 15, 31, 63],\n",
    "    'min_split_gain': [.0, .1, .2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(lg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1.0, 'subsample': 0.6} -0.139383437373\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "2          -0.066348        -0.139383        0.021851   \n",
      "1          -0.054522        -0.140038        0.022573   \n",
      "7          -0.070323        -0.140761        0.020654   \n",
      "0          -0.049747        -0.141690        0.023308   \n",
      "3          -0.085711        -0.142644        0.023617   \n",
      "6          -0.059113        -0.143717        0.023326   \n",
      "5          -0.055333        -0.144224        0.021510   \n",
      "8          -0.088043        -0.144275        0.021337   \n",
      "11         -0.068141        -0.146578        0.021674   \n",
      "12         -0.076466        -0.147078        0.020020   \n",
      "10         -0.064487        -0.148820        0.019845   \n",
      "13         -0.093967        -0.151249        0.020343   \n",
      "4          -0.123644        -0.152072        0.019904   \n",
      "9          -0.124147        -0.152829        0.021594   \n",
      "14         -0.124926        -0.155484        0.020006   \n",
      "15         -0.090128        -0.162650        0.020904   \n",
      "16         -0.092880        -0.164024        0.020662   \n",
      "17         -0.098728        -0.166661        0.020936   \n",
      "18         -0.112310        -0.171372        0.019959   \n",
      "19         -0.142408        -0.180795        0.019429   \n",
      "20         -0.146875        -0.216878        0.017871   \n",
      "21         -0.149436        -0.217904        0.017215   \n",
      "22         -0.153805        -0.222032        0.019680   \n",
      "23         -0.163664        -0.230646        0.018498   \n",
      "24         -0.197006        -0.250573        0.015481   \n",
      "\n",
      "                                         params  rank_test_score  \n",
      "2   {'colsample_bytree': 1.0, 'subsample': 0.6}                1  \n",
      "1   {'colsample_bytree': 1.0, 'subsample': 0.8}                2  \n",
      "7   {'colsample_bytree': 0.8, 'subsample': 0.6}                3  \n",
      "0   {'colsample_bytree': 1.0, 'subsample': 1.0}                4  \n",
      "3   {'colsample_bytree': 1.0, 'subsample': 0.4}                5  \n",
      "6   {'colsample_bytree': 0.8, 'subsample': 0.8}                6  \n",
      "5   {'colsample_bytree': 0.8, 'subsample': 1.0}                7  \n",
      "8   {'colsample_bytree': 0.8, 'subsample': 0.4}                8  \n",
      "11  {'colsample_bytree': 0.6, 'subsample': 0.8}                9  \n",
      "12  {'colsample_bytree': 0.6, 'subsample': 0.6}               10  \n",
      "10  {'colsample_bytree': 0.6, 'subsample': 1.0}               11  \n",
      "13  {'colsample_bytree': 0.6, 'subsample': 0.4}               12  \n",
      "4   {'colsample_bytree': 1.0, 'subsample': 0.2}               13  \n",
      "9   {'colsample_bytree': 0.8, 'subsample': 0.2}               14  \n",
      "14  {'colsample_bytree': 0.6, 'subsample': 0.2}               15  \n",
      "15  {'colsample_bytree': 0.4, 'subsample': 1.0}               16  \n",
      "16  {'colsample_bytree': 0.4, 'subsample': 0.8}               17  \n",
      "17  {'colsample_bytree': 0.4, 'subsample': 0.6}               18  \n",
      "18  {'colsample_bytree': 0.4, 'subsample': 0.4}               19  \n",
      "19  {'colsample_bytree': 0.4, 'subsample': 0.2}               20  \n",
      "20  {'colsample_bytree': 0.2, 'subsample': 1.0}               21  \n",
      "21  {'colsample_bytree': 0.2, 'subsample': 0.8}               22  \n",
      "22  {'colsample_bytree': 0.2, 'subsample': 0.6}               23  \n",
      "23  {'colsample_bytree': 0.2, 'subsample': 0.4}               24  \n",
      "24  {'colsample_bytree': 0.2, 'subsample': 0.2}               25  \n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=0,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=400,\n",
    "                                 learning_rate=0.05,\n",
    "                                 num_leaves=7,\n",
    "                                 min_split_gain=.2)\n",
    "\n",
    "params = {\n",
    "    'subsample': [1., .8, .6, .4, .2],\n",
    "    'colsample_bytree': [1., .8, .6, .4, .2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(lg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 1.0, 'subsample': 0.65} -0.138964156897\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "1          -0.062931        -0.138964        0.023561   \n",
      "6          -0.064000        -0.139073        0.022713   \n",
      "2          -0.066348        -0.139383        0.021851   \n",
      "17         -0.068724        -0.139531        0.021149   \n",
      "3          -0.069896        -0.139855        0.019431   \n",
      "14         -0.075968        -0.139948        0.021660   \n",
      "5          -0.060694        -0.139979        0.022561   \n",
      "0          -0.059749        -0.140015        0.024475   \n",
      "19         -0.076832        -0.140145        0.022471   \n",
      "7          -0.067339        -0.140179        0.022032   \n",
      "8          -0.070515        -0.140436        0.020971   \n",
      "11         -0.064433        -0.140483        0.023455   \n",
      "12         -0.068081        -0.140489        0.022752   \n",
      "13         -0.071169        -0.140811        0.020955   \n",
      "10         -0.061339        -0.140825        0.022971   \n",
      "18         -0.072166        -0.140891        0.022605   \n",
      "9          -0.075863        -0.141577        0.021982   \n",
      "4          -0.074897        -0.141614        0.021657   \n",
      "15         -0.062369        -0.141634        0.020158   \n",
      "16         -0.065303        -0.142060        0.022281   \n",
      "\n",
      "                                           params  rank_test_score  \n",
      "1    {'colsample_bytree': 1.0, 'subsample': 0.65}                1  \n",
      "6   {'colsample_bytree': 0.95, 'subsample': 0.65}                2  \n",
      "2     {'colsample_bytree': 1.0, 'subsample': 0.6}                3  \n",
      "17   {'colsample_bytree': 0.85, 'subsample': 0.6}                4  \n",
      "3    {'colsample_bytree': 1.0, 'subsample': 0.55}                5  \n",
      "14    {'colsample_bytree': 0.9, 'subsample': 0.5}                6  \n",
      "5    {'colsample_bytree': 0.95, 'subsample': 0.7}                7  \n",
      "0     {'colsample_bytree': 1.0, 'subsample': 0.7}                8  \n",
      "19   {'colsample_bytree': 0.85, 'subsample': 0.5}                9  \n",
      "7    {'colsample_bytree': 0.95, 'subsample': 0.6}               10  \n",
      "8   {'colsample_bytree': 0.95, 'subsample': 0.55}               11  \n",
      "11   {'colsample_bytree': 0.9, 'subsample': 0.65}               12  \n",
      "12    {'colsample_bytree': 0.9, 'subsample': 0.6}               13  \n",
      "13   {'colsample_bytree': 0.9, 'subsample': 0.55}               14  \n",
      "10    {'colsample_bytree': 0.9, 'subsample': 0.7}               15  \n",
      "18  {'colsample_bytree': 0.85, 'subsample': 0.55}               16  \n",
      "9    {'colsample_bytree': 0.95, 'subsample': 0.5}               17  \n",
      "4     {'colsample_bytree': 1.0, 'subsample': 0.5}               18  \n",
      "15   {'colsample_bytree': 0.85, 'subsample': 0.7}               19  \n",
      "16  {'colsample_bytree': 0.85, 'subsample': 0.65}               20  \n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=0,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=400,\n",
    "                                 learning_rate=0.05,\n",
    "                                 num_leaves=7,\n",
    "                                 min_split_gain=.2)\n",
    "\n",
    "params = {\n",
    "    'colsample_bytree': [1., .95, .9, .85],\n",
    "    'subsample': [.7, .65, .6, .55, .5]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(lg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0.0, 'reg_lambda': 0.1} -0.1384341404\n",
      "    mean_train_score  mean_test_score  std_test_score  \\\n",
      "47         -0.063499        -0.138434        0.022611   \n",
      "48         -0.062931        -0.138964        0.023561   \n",
      "27         -0.066687        -0.139132        0.021659   \n",
      "26         -0.067155        -0.139265        0.021526   \n",
      "40         -0.064549        -0.139355        0.023350   \n",
      "43         -0.069075        -0.139413        0.022160   \n",
      "41         -0.063746        -0.139430        0.023172   \n",
      "25         -0.068065        -0.139480        0.023170   \n",
      "39         -0.065466        -0.139537        0.022374   \n",
      "45         -0.065760        -0.139592        0.022681   \n",
      "38         -0.066794        -0.139731        0.022304   \n",
      "46         -0.064332        -0.139783        0.023118   \n",
      "32         -0.066594        -0.139834        0.022533   \n",
      "34         -0.064841        -0.140025        0.022977   \n",
      "19         -0.069114        -0.140148        0.022498   \n",
      "20         -0.068417        -0.140158        0.021400   \n",
      "13         -0.070378        -0.140254        0.022002   \n",
      "33         -0.065514        -0.140385        0.022039   \n",
      "24         -0.069611        -0.140671        0.022433   \n",
      "18         -0.069911        -0.140864        0.022726   \n",
      "11         -0.071972        -0.140894        0.022712   \n",
      "5          -0.072904        -0.140978        0.022182   \n",
      "30         -0.069204        -0.141024        0.021939   \n",
      "29         -0.070646        -0.141043        0.023499   \n",
      "31         -0.067834        -0.141106        0.022477   \n",
      "37         -0.068243        -0.141122        0.022532   \n",
      "44         -0.067611        -0.141182        0.023104   \n",
      "17         -0.071289        -0.141266        0.022485   \n",
      "12         -0.071390        -0.141360        0.022783   \n",
      "42         -0.069972        -0.141594        0.022732   \n",
      "36         -0.069847        -0.141603        0.022902   \n",
      "16         -0.072475        -0.141638        0.022468   \n",
      "9          -0.074353        -0.141806        0.023327   \n",
      "6          -0.072290        -0.141806        0.023676   \n",
      "23         -0.071184        -0.141811        0.022799   \n",
      "4          -0.073456        -0.141889        0.022821   \n",
      "10         -0.073280        -0.141970        0.022872   \n",
      "21         -0.073371        -0.142116        0.023137   \n",
      "22         -0.072298        -0.142354        0.022925   \n",
      "35         -0.071138        -0.142365        0.022409   \n",
      "2          -0.076236        -0.142741        0.022544   \n",
      "28         -0.071744        -0.142924        0.023116   \n",
      "3          -0.074946        -0.142943        0.022983   \n",
      "15         -0.073712        -0.142966        0.023781   \n",
      "8          -0.075653        -0.143145        0.022515   \n",
      "1          -0.077320        -0.143273        0.022690   \n",
      "7          -0.076850        -0.143339        0.023480   \n",
      "14         -0.075001        -0.143571        0.023006   \n",
      "0          -0.078579        -0.143581        0.022231   \n",
      "\n",
      "                                   params  rank_test_score  \n",
      "47  {'reg_alpha': 0.0, 'reg_lambda': 0.1}                1  \n",
      "48  {'reg_alpha': 0.0, 'reg_lambda': 0.0}                2  \n",
      "27  {'reg_alpha': 0.4, 'reg_lambda': 0.0}                3  \n",
      "26  {'reg_alpha': 0.4, 'reg_lambda': 0.1}                4  \n",
      "40  {'reg_alpha': 0.1, 'reg_lambda': 0.1}                5  \n",
      "43  {'reg_alpha': 0.0, 'reg_lambda': 0.8}                6  \n",
      "41  {'reg_alpha': 0.1, 'reg_lambda': 0.0}                7  \n",
      "25  {'reg_alpha': 0.4, 'reg_lambda': 0.2}                8  \n",
      "39  {'reg_alpha': 0.1, 'reg_lambda': 0.2}                9  \n",
      "45  {'reg_alpha': 0.0, 'reg_lambda': 0.4}               10  \n",
      "38  {'reg_alpha': 0.1, 'reg_lambda': 0.4}               11  \n",
      "46  {'reg_alpha': 0.0, 'reg_lambda': 0.2}               12  \n",
      "32  {'reg_alpha': 0.2, 'reg_lambda': 0.2}               13  \n",
      "34  {'reg_alpha': 0.2, 'reg_lambda': 0.0}               14  \n",
      "19  {'reg_alpha': 0.6, 'reg_lambda': 0.1}               15  \n",
      "20  {'reg_alpha': 0.6, 'reg_lambda': 0.0}               16  \n",
      "13  {'reg_alpha': 0.8, 'reg_lambda': 0.0}               17  \n",
      "33  {'reg_alpha': 0.2, 'reg_lambda': 0.1}               18  \n",
      "24  {'reg_alpha': 0.4, 'reg_lambda': 0.4}               19  \n",
      "18  {'reg_alpha': 0.6, 'reg_lambda': 0.2}               20  \n",
      "11  {'reg_alpha': 0.8, 'reg_lambda': 0.2}               21  \n",
      "5   {'reg_alpha': 1.0, 'reg_lambda': 0.1}               22  \n",
      "30  {'reg_alpha': 0.2, 'reg_lambda': 0.6}               23  \n",
      "29  {'reg_alpha': 0.2, 'reg_lambda': 0.8}               24  \n",
      "31  {'reg_alpha': 0.2, 'reg_lambda': 0.4}               25  \n",
      "37  {'reg_alpha': 0.1, 'reg_lambda': 0.6}               26  \n",
      "44  {'reg_alpha': 0.0, 'reg_lambda': 0.6}               27  \n",
      "17  {'reg_alpha': 0.6, 'reg_lambda': 0.4}               28  \n",
      "12  {'reg_alpha': 0.8, 'reg_lambda': 0.1}               29  \n",
      "42  {'reg_alpha': 0.0, 'reg_lambda': 1.0}               30  \n",
      "36  {'reg_alpha': 0.1, 'reg_lambda': 0.8}               31  \n",
      "16  {'reg_alpha': 0.6, 'reg_lambda': 0.6}               32  \n",
      "9   {'reg_alpha': 0.8, 'reg_lambda': 0.6}               33  \n",
      "6   {'reg_alpha': 1.0, 'reg_lambda': 0.0}               34  \n",
      "23  {'reg_alpha': 0.4, 'reg_lambda': 0.6}               35  \n",
      "4   {'reg_alpha': 1.0, 'reg_lambda': 0.2}               36  \n",
      "10  {'reg_alpha': 0.8, 'reg_lambda': 0.4}               37  \n",
      "21  {'reg_alpha': 0.4, 'reg_lambda': 1.0}               38  \n",
      "22  {'reg_alpha': 0.4, 'reg_lambda': 0.8}               39  \n",
      "35  {'reg_alpha': 0.1, 'reg_lambda': 1.0}               40  \n",
      "2   {'reg_alpha': 1.0, 'reg_lambda': 0.6}               41  \n",
      "28  {'reg_alpha': 0.2, 'reg_lambda': 1.0}               42  \n",
      "3   {'reg_alpha': 1.0, 'reg_lambda': 0.4}               43  \n",
      "15  {'reg_alpha': 0.6, 'reg_lambda': 0.8}               44  \n",
      "8   {'reg_alpha': 0.8, 'reg_lambda': 0.8}               45  \n",
      "1   {'reg_alpha': 1.0, 'reg_lambda': 0.8}               46  \n",
      "7   {'reg_alpha': 0.8, 'reg_lambda': 1.0}               47  \n",
      "14  {'reg_alpha': 0.6, 'reg_lambda': 1.0}               48  \n",
      "0   {'reg_alpha': 1.0, 'reg_lambda': 1.0}               49  \n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=0,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=400,\n",
    "                                 learning_rate=0.05,\n",
    "                                 num_leaves=7,\n",
    "                                 min_split_gain=.2,\n",
    "                                 colsample_bytree=1.,\n",
    "                                 subsample=.65)\n",
    "\n",
    "params = {\n",
    "    'reg_alpha': [1., .8, .6, .4, .2, .1, .0],\n",
    "    'reg_lambda': [1., .8, .6, .4, .2, .1, .0]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(lg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg_alpha': 0.0, 'reg_lambda': 0.1} -0.1384341404\n",
      "   mean_train_score  mean_test_score  std_test_score  \\\n",
      "1         -0.063499        -0.138434        0.022611   \n",
      "5         -0.063913        -0.138617        0.022427   \n",
      "3         -0.064493        -0.138630        0.023377   \n",
      "2         -0.063577        -0.138934        0.022928   \n",
      "0         -0.064217        -0.139119        0.021800   \n",
      "4         -0.064215        -0.139683        0.022824   \n",
      "\n",
      "                                    params  rank_test_score  \n",
      "1    {'reg_alpha': 0.0, 'reg_lambda': 0.1}                1  \n",
      "5  {'reg_alpha': 0.05, 'reg_lambda': 0.05}                2  \n",
      "3  {'reg_alpha': 0.05, 'reg_lambda': 0.15}                3  \n",
      "2   {'reg_alpha': 0.0, 'reg_lambda': 0.05}                4  \n",
      "0   {'reg_alpha': 0.0, 'reg_lambda': 0.15}                5  \n",
      "4   {'reg_alpha': 0.05, 'reg_lambda': 0.1}                6  \n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=0,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=400,\n",
    "                                 learning_rate=0.05,\n",
    "                                 num_leaves=7,\n",
    "                                 min_split_gain=.2,\n",
    "                                 colsample_bytree=1.,\n",
    "                                 subsample=.65)\n",
    "\n",
    "params = {\n",
    "    'reg_alpha': [.0, .05],\n",
    "    'reg_lambda': [.15, .1, .05]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(lg_clf, params, scoring='neg_log_loss', cv=kfold)\n",
    "gs.fit(train_X, train_y)\n",
    "print(gs.best_params_ , gs.best_score_)\n",
    "cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "cv_df = cv_df[['mean_train_score', 'mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "cv_df.sort_values(by=['rank_test_score', 'std_test_score'], inplace=True)\n",
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13841972171192868, 0.14204997002447101, 0.13921843454679936, 0.14047178852624889, 0.14067191310696964, 0.14057144487186415, 0.14119326800798834, 0.14023561077455832, 0.1389122643391732, 0.13793159944214811]\n",
      "Overall average: 0.13997, stdev: 0.0012\n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=0,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=400,\n",
    "                                 learning_rate=0.05,\n",
    "                                 num_leaves=7,\n",
    "                                 min_split_gain=.2,\n",
    "                                 colsample_bytree=1.,\n",
    "                                 subsample=.65,\n",
    "                                 reg_alpha=0.,\n",
    "                                 reg_lambda=0.1)\n",
    "\n",
    "losses = []\n",
    "test_times = 10\n",
    "for i in range(test_times):\n",
    "    test_k_fold = KFold(5, shuffle=True, random_state=i)\n",
    "    log_loss = cross_val_score(lg_clf, train_X, train_y, scoring='neg_log_loss', cv=test_k_fold)\n",
    "    avg_log_loss = -1. * sum(log_loss) / float(len(log_loss))\n",
    "    losses.append(avg_log_loss)\n",
    "        \n",
    "print(losses)\n",
    "losses = np.array(losses)\n",
    "print(\"Overall average: {:.5f}, stdev: {:.4f}\".format(losses.mean(), losses.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "xg_clf = xgboost.XGBClassifier(n_jobs=4, \n",
    "                               booster='gbtree', \n",
    "                               objective='binary:logistic',\n",
    "                               max_depth=3, \n",
    "                               min_child_weight=4, \n",
    "                               gamma=.1,\n",
    "                               n_estimators=500,\n",
    "                               learning_rate=0.01,\n",
    "                               reg_alpha=.0,\n",
    "                               reg_lambda=.1)\n",
    "\n",
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=0,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=200, \n",
    "                                 min_child_samples=5,\n",
    "                                 num_leaves=7, \n",
    "                                 reg_alpha=.4, \n",
    "                                 reg_lambda=.2)\n",
    "'''  \n",
    "xg_clf = xgboost.XGBClassifier(n_jobs=6, seed=0, \n",
    "                               objective='binary:logistic', eval_metric='logloss', \n",
    "                               booster='dart',\n",
    "                               n_estimators=800,\n",
    "                               learning_rate=0.005,\n",
    "                               gamma=0.2,\n",
    "                               min_child_weight=8,\n",
    "                               colsample_bytree=1.,\n",
    "                               subsample=.85,\n",
    "                               reg_alpha=.0,\n",
    "                               reg_lambda=.0)\n",
    "'''                               \n",
    "xg_clf = xgboost.XGBClassifier(n_jobs=4, seed=0, \n",
    "                               objective='binary:logistic', eval_metric='logloss', \n",
    "                               booster='gbtree',\n",
    "                               n_estimators=1600,\n",
    "                               learning_rate=0.005,\n",
    "                               gamma=0.,\n",
    "                               min_child_weight=10,\n",
    "                               colsample_bytree=.8,\n",
    "                               subsample=.75,\n",
    "                               reg_alpha=.0,\n",
    "                               reg_lambda=.05)\n",
    "'''                                 \n",
    "\n",
    "'''\n",
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=0,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=400,\n",
    "                                 learning_rate=0.05,\n",
    "                                 num_leaves=3,\n",
    "                                 min_child_samples=1,\n",
    "                                 min_split_gain=.0,\n",
    "                                 colsample_bytree=1.,\n",
    "                                 subsample=.85,\n",
    "                                 reg_alpha=.2, \n",
    "                                 reg_lambda=.1,\n",
    "                                 min_child_weights=.0)\n",
    "'''\n",
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=0,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=400,\n",
    "                                 learning_rate=0.05,\n",
    "                                 num_leaves=7,\n",
    "                                 min_split_gain=.2,\n",
    "                                 colsample_bytree=1.,\n",
    "                                 subsample=.65,\n",
    "                                 reg_alpha=0.,\n",
    "                                 reg_lambda=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8424, 4)\n",
      "Index(['f_0', 'f_1', 'f_2', 'f_3', 'f_4', 'f_5', 'f_6', 'f_7', 'f_8', 'f_9',\n",
      "       ...\n",
      "       'f_497', 'f_498', 'f_499', 'f_500', 'f_501', 'f_502', 'f_503', 'f_504',\n",
      "       'f_505', 'is_iceberg'],\n",
      "      dtype='object', length=507)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_497</th>\n",
       "      <th>f_498</th>\n",
       "      <th>f_499</th>\n",
       "      <th>f_500</th>\n",
       "      <th>f_501</th>\n",
       "      <th>f_502</th>\n",
       "      <th>f_503</th>\n",
       "      <th>f_504</th>\n",
       "      <th>f_505</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.937001</td>\n",
       "      <td>-0.046966</td>\n",
       "      <td>-0.123941</td>\n",
       "      <td>1.657609</td>\n",
       "      <td>0.387005</td>\n",
       "      <td>-0.935819</td>\n",
       "      <td>0.875177</td>\n",
       "      <td>-1.270511</td>\n",
       "      <td>-0.197012</td>\n",
       "      <td>-0.564091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.884518</td>\n",
       "      <td>0.744608</td>\n",
       "      <td>1.615025</td>\n",
       "      <td>-0.645318</td>\n",
       "      <td>0.176217</td>\n",
       "      <td>-0.806068</td>\n",
       "      <td>1.856665</td>\n",
       "      <td>-0.350232</td>\n",
       "      <td>-0.865953</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.118640</td>\n",
       "      <td>-1.240150</td>\n",
       "      <td>0.447019</td>\n",
       "      <td>-1.328023</td>\n",
       "      <td>0.787310</td>\n",
       "      <td>-1.598214</td>\n",
       "      <td>-1.202442</td>\n",
       "      <td>1.852692</td>\n",
       "      <td>-0.389426</td>\n",
       "      <td>-1.097326</td>\n",
       "      <td>...</td>\n",
       "      <td>6.759618</td>\n",
       "      <td>-5.750248</td>\n",
       "      <td>1.102224</td>\n",
       "      <td>1.957992</td>\n",
       "      <td>6.739988</td>\n",
       "      <td>-6.828598</td>\n",
       "      <td>-0.316139</td>\n",
       "      <td>0.019994</td>\n",
       "      <td>-0.214197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.764784</td>\n",
       "      <td>3.286722</td>\n",
       "      <td>1.683806</td>\n",
       "      <td>-4.562440</td>\n",
       "      <td>1.846337</td>\n",
       "      <td>4.057018</td>\n",
       "      <td>-1.713150</td>\n",
       "      <td>-2.781449</td>\n",
       "      <td>2.058828</td>\n",
       "      <td>-3.035690</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.019593</td>\n",
       "      <td>13.030576</td>\n",
       "      <td>-24.291735</td>\n",
       "      <td>-20.003954</td>\n",
       "      <td>29.469348</td>\n",
       "      <td>-3.469105</td>\n",
       "      <td>-16.500395</td>\n",
       "      <td>-20.140434</td>\n",
       "      <td>15.906663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.349804</td>\n",
       "      <td>1.111627</td>\n",
       "      <td>-0.250717</td>\n",
       "      <td>0.631179</td>\n",
       "      <td>0.484991</td>\n",
       "      <td>-0.054787</td>\n",
       "      <td>1.577700</td>\n",
       "      <td>-0.875416</td>\n",
       "      <td>0.119568</td>\n",
       "      <td>0.265341</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.307981</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>1.342591</td>\n",
       "      <td>-0.660067</td>\n",
       "      <td>3.665410</td>\n",
       "      <td>0.553088</td>\n",
       "      <td>0.111166</td>\n",
       "      <td>2.663308</td>\n",
       "      <td>-0.349038</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.776327</td>\n",
       "      <td>-0.104925</td>\n",
       "      <td>-1.166807</td>\n",
       "      <td>-0.152499</td>\n",
       "      <td>0.485535</td>\n",
       "      <td>-1.454540</td>\n",
       "      <td>-0.705199</td>\n",
       "      <td>3.206676</td>\n",
       "      <td>-0.383359</td>\n",
       "      <td>-0.126195</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.667099</td>\n",
       "      <td>-0.170659</td>\n",
       "      <td>6.333236</td>\n",
       "      <td>-5.072867</td>\n",
       "      <td>-3.982328</td>\n",
       "      <td>-2.256037</td>\n",
       "      <td>2.386261</td>\n",
       "      <td>-4.194104</td>\n",
       "      <td>-1.747197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
       "0 -0.937001 -0.046966 -0.123941  1.657609  0.387005 -0.935819  0.875177   \n",
       "1  0.118640 -1.240150  0.447019 -1.328023  0.787310 -1.598214 -1.202442   \n",
       "2 -1.764784  3.286722  1.683806 -4.562440  1.846337  4.057018 -1.713150   \n",
       "3  1.349804  1.111627 -0.250717  0.631179  0.484991 -0.054787  1.577700   \n",
       "4 -0.776327 -0.104925 -1.166807 -0.152499  0.485535 -1.454540 -0.705199   \n",
       "\n",
       "        f_7       f_8       f_9     ...          f_497      f_498      f_499  \\\n",
       "0 -1.270511 -0.197012 -0.564091     ...      -0.884518   0.744608   1.615025   \n",
       "1  1.852692 -0.389426 -1.097326     ...       6.759618  -5.750248   1.102224   \n",
       "2 -2.781449  2.058828 -3.035690     ...     -12.019593  13.030576 -24.291735   \n",
       "3 -0.875416  0.119568  0.265341     ...      -1.307981   0.003071   1.342591   \n",
       "4  3.206676 -0.383359 -0.126195     ...      -3.667099  -0.170659   6.333236   \n",
       "\n",
       "       f_500      f_501     f_502      f_503      f_504      f_505  is_iceberg  \n",
       "0  -0.645318   0.176217 -0.806068   1.856665  -0.350232  -0.865953         0.0  \n",
       "1   1.957992   6.739988 -6.828598  -0.316139   0.019994  -0.214197         0.0  \n",
       "2 -20.003954  29.469348 -3.469105 -16.500395 -20.140434  15.906663         0.0  \n",
       "3  -0.660067   3.665410  0.553088   0.111166   2.663308  -0.349038         0.0  \n",
       "4  -5.072867  -3.982328 -2.256037   2.386261  -4.194104  -1.747197         0.0  \n",
       "\n",
       "[5 rows x 507 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json('Data/test.json')\n",
    "print(test_df.shape)\n",
    "test_df.head(5)\n",
    "test_ids = test_df['id']\n",
    "test_df = pd.read_csv('Data/pca_projected_506_from_resnet_test.csv')\n",
    "#test_df.reset_index(drop=True, inplace=True)\n",
    "print(test_df.columns)\n",
    "test_df.sort_index(inplace=True)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = test_df.columns.tolist()\n",
    "features.remove('is_iceberg')\n",
    "\n",
    "test_X = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "       colsample_bytree=1.0, eval_metric='logloss', gamma=0.2,\n",
       "       learning_rate=0.005, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=8, missing=None, n_estimators=800, n_jobs=6,\n",
       "       nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1, seed=0,\n",
       "       silent=True, subsample=0.85)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01472192  0.66985995  0.01974309 ...,  0.01474441  0.98494661\n",
      "  0.01969161]\n"
     ]
    }
   ],
   "source": [
    "predictions = xg_clf.predict_proba(test_X)[:,1]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_ids\n",
    "submission['is_iceberg'] = predictions\n",
    "submission.to_csv('Submissions/submission_xgboost_1130_pca_506_on_old.csv', float_format=\"%.15f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', colsample_bytree=1.0, learning_rate=0.05,\n",
       "        max_bin=255, max_depth=-1, min_child_samples=10,\n",
       "        min_child_weight=5, min_split_gain=0.2, n_estimators=400, n_jobs=4,\n",
       "        num_leaves=7, objective='binary', random_state=0, reg_alpha=0.0,\n",
       "        reg_lambda=0.1, silent=True, subsample=0.65,\n",
       "        subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01289007  0.42760015  0.02315127 ...,  0.01373905  0.98449361\n",
      "  0.02838355]\n"
     ]
    }
   ],
   "source": [
    "predictions = lg_clf.predict_proba(test_X)[:,1]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_ids\n",
    "submission['is_iceberg'] = predictions\n",
    "submission.to_csv('Submissions/submission_lightgbm_1130_pca_506_on_old.csv', float_format=\"%.15f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import copy\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "def get_oof_prediction(model, fold_num = 5):\n",
    "    kf = kfold\n",
    "    counter  = 1\n",
    "    \n",
    "    final_predictions = np.zeros((len(test_ids),))\n",
    "    avg_loss = .0\n",
    "    avg_acc = .0\n",
    "    \n",
    "    for train_index, valid_index in kf.split(train_X, train_y):\n",
    "\n",
    "        _train_X = train_X.loc[train_index].reset_index(drop=True)\n",
    "        _valid_X = train_X.loc[valid_index].reset_index(drop=True)\n",
    "        \n",
    "        _train_y = train_y[train_index]\n",
    "        _valid_y = train_y[valid_index]\n",
    "        \n",
    "        intance = copy.deepcopy(model)\n",
    "        intance.fit(_train_X, _train_y)\n",
    "        \n",
    "        valid_answer = intance.predict_proba(_valid_X)[:,1].reshape((_valid_X.shape[0],))\n",
    "        valid_answer_logit = intance.predict(_valid_X)\n",
    "        loss = log_loss(_valid_y, valid_answer)\n",
    "        acc = accuracy_score(_valid_y, valid_answer_logit)\n",
    "        \n",
    "        avg_loss += loss\n",
    "        avg_acc += acc\n",
    "        print(\"loss={:.4f}, acc={:.3f}\".format(loss, acc))\n",
    "        \n",
    "        predictions = intance.predict_proba(test_X)[:,1]\n",
    "        predictions = predictions.reshape((predictions.shape[0],))\n",
    "        final_predictions += predictions\n",
    "    \n",
    "    print(\"Avg. loss:\", avg_loss / (fold_num * 1.0))\n",
    "    print(\"Avg. acc:\", avg_acc / fold_num * 1.0)\n",
    "    return final_predictions / (fold_num * 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=0.1604, acc=0.950\n",
      "loss=0.1322, acc=0.947\n",
      "loss=0.1168, acc=0.963\n",
      "loss=0.1567, acc=0.941\n",
      "loss=0.1079, acc=0.959\n",
      "Avg. loss: 0.134816371243\n",
      "Avg. acc: 0.951999610592\n",
      "[ 0.01246961  0.45949685  0.02008037 ...,  0.01134609  0.98582233\n",
      "  0.01585756]\n"
     ]
    }
   ],
   "source": [
    "lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=0,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=200,\n",
    "                                 learning_rate=0.1,\n",
    "                                 num_leaves=15,\n",
    "                                 min_child_samples=20,\n",
    "                                 colsample_bytree=.9,\n",
    "                                 subsample=.7,\n",
    "                                 reg_alpha=0.1,\n",
    "                                 reg_lambda=0.4)\n",
    "\n",
    "predictions = get_oof_prediction(lg_clf)\n",
    "print(predictions)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_ids\n",
    "submission['is_iceberg'] = predictions\n",
    "submission.to_csv('Submissions/submission_lgb_1126_pca_70_on_old_oof_avg.csv', float_format=\"%.15f\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965868 0.0395036\n",
      "[ 0.00979236  0.01160072  0.94080621 ...,  0.06268214  0.01758832\n",
      "  0.12943955]\n",
      "Original log loss: 0.0745857695122\n",
      "clipped #= 1273  total#= 1604\n",
      "[  1.00000001e-07   1.00000001e-07   9.40806210e-01 ...,   6.26821443e-02\n",
      "   1.00000001e-07   1.29439548e-01]\n",
      "Clipped log loss: 0.0639064493717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "probs = xg_clf.predict_proba(train_X)[:,1]\n",
    "logit = xg_clf.predict(train_X)\n",
    "error_probs = probs[logit != train_y]\n",
    "#print(error_probs)\n",
    "max_error_prob = max(error_probs)\n",
    "min_error_prob = min(error_probs)\n",
    "print(max_error_prob, min_error_prob)\n",
    "print(probs)\n",
    "print(\"Original log loss:\", log_loss(train_y, probs))\n",
    "\n",
    "clipped_probs = xg_clf.predict_proba(train_X)[:,1].reshape((train_X.shape[0],)).astype(np.float32)\n",
    "count = 0\n",
    "for i, prob in enumerate(clipped_probs):\n",
    "    if prob > .97:\n",
    "        clipped_probs[i] = 0.9999999\n",
    "        count += 1\n",
    "    elif prob < .03:\n",
    "        clipped_probs[i] = 0.0000001\n",
    "        count += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "clipped_probs = np.array(clipped_probs).reshape((clipped_probs.shape[0],))\n",
    "print('clipped #=', count, ' total#=', clipped_probs.shape[0])\n",
    "print(clipped_probs)    \n",
    "print(\"Clipped log loss:\", log_loss(train_y, clipped_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00921421  0.86483711  0.00995382 ...,  0.00742945  0.99213684\n",
      "  0.0262079 ]\n",
      "clipped #= 6182  total#= 8424\n",
      "[  1.00000001e-07   8.64837110e-01   1.00000001e-07 ...,   1.00000001e-07\n",
      "   9.99999881e-01   1.00000001e-07]\n",
      "1e-07\n"
     ]
    }
   ],
   "source": [
    "clipped_probs = xg_clf.predict_proba(test_X)[:,1]\n",
    "count = 0\n",
    "print(clipped_probs)\n",
    "for i, prob in enumerate(clipped_probs):\n",
    "    if prob > .97:\n",
    "        clipped_probs[i] = 0.9999999\n",
    "        count += 1\n",
    "    elif prob < .03:\n",
    "        clipped_probs[i] = 0.0000001\n",
    "        count += 1\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "clipped_probs = np.array(clipped_probs).reshape((clipped_probs.shape[0],))\n",
    "print('clipped #=', count, ' total#=', clipped_probs.shape[0])\n",
    "print(clipped_probs)\n",
    "print(clipped_probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_ids\n",
    "submission['is_iceberg'] = clipped_probs\n",
    "submission.to_csv('Submissions/submission_xgboost_1126_fine_tune_clipped.csv', float_format=\"%.15f\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Several seeds blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repeat_count = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_predictions = np.zeros((test_X.shape[0],))\n",
    "for i in range(repeat_count):\n",
    "    xg_clf = xgboost.XGBClassifier(n_jobs=4, \n",
    "                               booster='gbtree', \n",
    "                               objective='binary:logistic',\n",
    "                               max_depth=3, \n",
    "                               min_child_weight=4, \n",
    "                               gamma=.1,\n",
    "                               n_estimators=510, # slightly more\n",
    "                               learning_rate=0.01,\n",
    "                               reg_alpha=.01, # slight more regularization\n",
    "                               reg_lambda=.12, # slight more regularization\n",
    "                               random_state=i)\n",
    "    xg_clf.fit(train_X, train_y)\n",
    "    xgb_predictions += xg_clf.predict_proba(test_X)[:,1]\n",
    "    \n",
    "xgb_predictions /= (repeat_count*1.0)\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_ids\n",
    "submission['is_iceberg'] = xgb_predictions\n",
    "submission.to_csv('Submissions/submission_xgboost_blend{}.csv'.format(repeat_count), float_format=\"%.15f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lg_predictions = np.zeros((test_X.shape[0],))\n",
    "for i in range(repeat_count):\n",
    "    lg_clf = lightgbm.LGBMClassifier(n_jobs=4, \n",
    "                                 objective='binary', \n",
    "                                 random_state=i,\n",
    "                                 boosting_type='dart',\n",
    "                                 n_estimators=200, \n",
    "                                 min_child_samples=1,\n",
    "                                 num_leaves=7,\n",
    "                                 min_split_gain=.1,\n",
    "                                 colsample_bytree=.95,\n",
    "                                 subsample=.9,\n",
    "                                 reg_alpha=.15, \n",
    "                                 reg_lambda=.15)\n",
    "    lg_clf.fit(train_X, train_y)\n",
    "    lg_predictions += lg_clf.predict_proba(test_X)[:,1]\n",
    "    \n",
    "lg_predictions /= (repeat_count*1.0)\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_ids\n",
    "submission['is_iceberg'] = lg_predictions\n",
    "submission.to_csv('Submissions/submission_lightgbm_blend{}_1119_fine_tune.csv'.format(repeat_count), float_format=\"%.15f\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
