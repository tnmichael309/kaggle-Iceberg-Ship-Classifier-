{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from resnet import lessFilterResNet50FeatureExtract\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_json('Data/denoised_processed_train.json')\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test feature extraction functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(df, fold=1, seed=0):\n",
    "    is_transfer_learning = False\n",
    "    model = lessFilterResNet50FeatureExtract()\n",
    "    model_name = 'Trained_model/less_filter_resent50_' + str(fold) + '.db'\n",
    "    # testing snap shot for essemble\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "    \n",
    "    tr = Trainer(\n",
    "            model,\n",
    "            optimizer,\n",
    "            epochs=1800,\n",
    "            milestones=[300, 1100, 1600],\n",
    "            gamma=0.2,\n",
    "            batch_size=128, \n",
    "            use_cuda=True, \n",
    "            gpu_idx=0,\n",
    "            best_model_name = model_name,\n",
    "            seed=seed,\n",
    "            verbose=0)\n",
    "\n",
    "    tr.load_checkpoint()\n",
    "\n",
    "    data_augmentation_args = {\n",
    "        'mirror': False, # not useful here\n",
    "        'rotate': True,\n",
    "        'scale': True,\n",
    "        'translation': True\n",
    "    }\n",
    "\n",
    "    predictions = tr.test(df, is_transfer_learning=is_transfer_learning, is_augment=True, data_augmentation_args=data_augmentation_args)\n",
    "    \n",
    "    del model, tr, optimizer\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C588A3E80>, <torchvision.transforms.transforms.Lambda object at 0x0000020C588A3FD0>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C588A3940>]\n",
      "(1604, 18433)\n",
      "False    17622\n",
      "True       811\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.18467656],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.12919928],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.19141054],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.14403118],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.17061992],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.10167369]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = get_prediction(train_df)\n",
    "print(predictions.shape)\n",
    "print(pd.Series(predictions[0] != 0.0).value_counts())\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test augmentation's effect on the network output (features response before avg. pooling layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C2F4774E0>, <torchvision.transforms.transforms.Lambda object at 0x0000020C2F3B4278>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C53D52860>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C53D52080>, <torchvision.transforms.transforms.Lambda object at 0x0000020C2B55FE48>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C2B55F400>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C2F47E860>, <torchvision.transforms.transforms.Lambda object at 0x0000020C2F47E278>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C2F47EA20>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C2F47E278>, <torchvision.transforms.transforms.Lambda object at 0x0000020C2F47E4A8>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C2F47EA20>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C2F47E278>, <torchvision.transforms.transforms.Lambda object at 0x0000020C2F47E4A8>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C2F47E860>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C2F3AF198>, <torchvision.transforms.transforms.Lambda object at 0x0000020C2F4810B8>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C2F481128>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C2F481A90>, <torchvision.transforms.transforms.Lambda object at 0x0000020C2F481C88>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C2F481B00>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C2F487EB8>, <torchvision.transforms.transforms.Lambda object at 0x0000020C2A42D3C8>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C2A42D128>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C2B55F400>, <torchvision.transforms.transforms.Lambda object at 0x0000020C2B55F2E8>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C2B55FAC8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x0000020C2F484278>, <torchvision.transforms.transforms.Lambda object at 0x0000020C2F4849E8>, <torchvision.transforms.transforms.ToTensor object at 0x0000020C2F484B38>]\n"
     ]
    }
   ],
   "source": [
    "predictions = [get_prediction(train_df, seed=i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1604, 18433)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(predictions).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...,  0.          0.         -0.18467654]\n",
      " [ 0.          0.          0.         ...,  0.          0.         -0.12919928]\n",
      " [ 0.          0.          0.         ...,  0.          0.         -0.19141054]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.         -0.14403118]\n",
      " [ 0.          0.          0.         ...,  0.          0.         -0.17061993]\n",
      " [ 0.          0.          0.         ...,  0.          0.         -0.10167368]]\n",
      "[[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.49011612e-08]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   1.49011612e-08]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   7.45058060e-09]]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(predictions)\n",
    "avg_predictions = predictions.mean(axis=0)\n",
    "std_predictions = predictions.std(axis=0)\n",
    "\n",
    "print(avg_predictions)\n",
    "print(std_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_dev(index):\n",
    "    large_dev_count = 0\n",
    "    for i in range(1604):\n",
    "        large_dev_count += pd.Series(std_predictions[index] > 1e-3).value_counts()\n",
    "\n",
    "    print(large_dev_count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_count= 29566532\n",
      "False    28195112\n",
      "True      1371420\n",
      "dtype: int64\n",
      "False    28243232\n",
      "True      1323300\n",
      "dtype: int64\n",
      "False    28291352\n",
      "True      1275180\n",
      "dtype: int64\n",
      "False    28164636\n",
      "True      1401896\n",
      "dtype: int64\n",
      "False    28283332\n",
      "True      1283200\n",
      "dtype: int64\n",
      "False    29013152\n",
      "True       553380\n",
      "dtype: int64\n",
      "False    28196716\n",
      "True      1369816\n",
      "dtype: int64\n",
      "False    28884832\n",
      "True       681700\n",
      "dtype: int64\n",
      "False    28357116\n",
      "True      1209416\n",
      "dtype: int64\n",
      "False    28926536\n",
      "True       639996\n",
      "dtype: int64\n",
      "False    28252856\n",
      "True      1313676\n",
      "dtype: int64\n",
      "False    28143784\n",
      "True      1422748\n",
      "dtype: int64\n",
      "False    28223984\n",
      "True      1342548\n",
      "dtype: int64\n",
      "False    28398820\n",
      "True      1167712\n",
      "dtype: int64\n",
      "False    28235212\n",
      "True      1331320\n",
      "dtype: int64\n",
      "False    29027588\n",
      "True       538944\n",
      "dtype: int64\n",
      "False    28835108\n",
      "True       731424\n",
      "dtype: int64\n",
      "False    29019568\n",
      "True       546964\n",
      "dtype: int64\n",
      "False    28278520\n",
      "True      1288012\n",
      "dtype: int64\n",
      "False    28872000\n",
      "True       694532\n",
      "dtype: int64\n",
      "False    28501476\n",
      "True      1065056\n",
      "dtype: int64\n",
      "False    28127744\n",
      "True      1438788\n",
      "dtype: int64\n",
      "False    28222380\n",
      "True      1344152\n",
      "dtype: int64\n",
      "False    28989092\n",
      "True       577440\n",
      "dtype: int64\n",
      "False    28219172\n",
      "True      1347360\n",
      "dtype: int64\n",
      "False    29058064\n",
      "True       508468\n",
      "dtype: int64\n",
      "False    28833504\n",
      "True       733028\n",
      "dtype: int64\n",
      "False    28180676\n",
      "True      1385856\n",
      "dtype: int64\n",
      "False    28677916\n",
      "True       888616\n",
      "dtype: int64\n",
      "False    28957012\n",
      "True       609520\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('total_count=', 1604*18433)\n",
    "for i in range(30):\n",
    "    check_dev(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems that the network output is affected by the data augmentation, we'll average the feature response with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD128>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD1D0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD240>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED04349160>, <torchvision.transforms.transforms.Lambda object at 0x000001ED04321B38>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED04321CC0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2748>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2240>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2668>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD6D8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD780>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD5C0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6DA0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9E48>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9BA8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6F51D0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2C18>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2F28>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26B0BF60>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDC88>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD128>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6CC0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED7897E320>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1E6E2860>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DDE80>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDCC0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD588>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD0B8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD080>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD588>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64908>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1E752DA0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26C4D7F0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EB62E8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EB6128>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED7897E320>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6F5EF0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1F6F51D0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E575748>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F93C8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9D30>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD470>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD320>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD9B0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2CF8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC29E8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDD30>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6FD5F8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2EF0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2B38>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6CC0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD630>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDDD8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DDE80>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD978>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDFD0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6F51D0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2908>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC24E0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E92EF0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26E92F28>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F96A0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD240>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDF98>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDE80>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2D68>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC24E0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F99B0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9E80>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9D68>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBDBA8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD2B0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDBE0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD748>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD400>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD048>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9F60>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9CC0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9518>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD2E8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDB00>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDBE0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64908>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26E49208>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26B0BF60>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9860>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9940>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9F98>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD5C0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD470>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDAC8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED223A94A8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2D68>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2550>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DDCC0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDC88>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD198>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D7F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6F5C50>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26E64940>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2F98>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2EB8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2A20>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F42B0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4240>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F44A8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F48D0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4A20>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4748>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4240>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F49B0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4550>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DDEF0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDB70>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDFD0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED223A94A8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2550>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2470>]\n",
      "(1604, 18433)\n",
      "   f_1_0  f_1_1  f_1_2  f_1_3  f_1_4  f_1_5  f_1_6  f_1_7  f_1_8  f_1_9  \\\n",
      "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "     ...      f_1_18423  f_1_18424  f_1_18425  f_1_18426  f_1_18427  \\\n",
      "0    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "1    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "2    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   f_1_18428  f_1_18429  f_1_18430  f_1_18431  f_1_18432  \n",
      "0        0.0        0.0        0.0        0.0  -0.184677  \n",
      "1        0.0        0.0        0.0        0.0  -0.129199  \n",
      "2        0.0        0.0        0.0        0.0  -0.191411  \n",
      "\n",
      "[3 rows x 18433 columns]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64940>, <torchvision.transforms.transforms.Lambda object at 0x000001ED7897E358>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED7897E320>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6F5EF0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED7897E358>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED7897E320>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4FD0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F44A8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F49B0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBDBA8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDC50>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDBE0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DDEF0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD518>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD1D0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6FD240>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9630>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9D30>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6F51D0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6F5C50>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1E752DA0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DDF28>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDB38>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD208>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D7F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26E49208>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED7897E0F0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED7897E0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC22E8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2438>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9F98>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9CF8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9908>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9198>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9780>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9710>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD8D0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD518>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDBA8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC26A0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2048>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC29E8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E575748>, <torchvision.transforms.transforms.Lambda object at 0x000001ED222F6CC0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1E752DA0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E49208>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26C4D7F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1E6E2860>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC22E8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2B70>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC27F0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD2E8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1E752DA0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4860>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD668>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDAC8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD198>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9B38>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9630>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F95F8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4278>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F43C8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F41D0>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DDC88>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD978>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDF28>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED7897E320>, <torchvision.transforms.transforms.Lambda object at 0x000001ED7897E358>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9E80>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4400>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F43C8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F42B0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBDA58>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDFD0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDE48>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64940>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26E49208>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2630>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1E752DA0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDA58>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D7F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDB70>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDC18>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2470>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC26D8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC24A8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DDE10>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD780>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDEB8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4898>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4470>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F44E0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2208>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2E80>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2A20>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6CC0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDB70>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD588>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6DA0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD470>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD048>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6F5EF0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26E49208>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED7897E320>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD3C8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD400>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD8D0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6FD5F8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED222F6DA0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD470>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2E48>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2A90>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2DA0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED223A94A8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9908>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F92B0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED0433EF60>, <torchvision.transforms.transforms.Lambda object at 0x000001ED0433EEB8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED0433EDD8>]\n",
      "(1604, 18433)\n",
      "   f_2_0  f_2_1  f_2_2  f_2_3  f_2_4  f_2_5  f_2_6  f_2_7  f_2_8  f_2_9  \\\n",
      "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "     ...      f_2_18423  f_2_18424  f_2_18425  f_2_18426  f_2_18427  \\\n",
      "0    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "1    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "2    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   f_2_18428  f_2_18429  f_2_18430  f_2_18431  f_2_18432  \n",
      "0        0.0        0.0        0.0        0.0   0.339935  \n",
      "1        0.0        0.0        0.0        0.0  -0.124696  \n",
      "2        0.0        0.0        0.0        0.0   0.396333  \n",
      "\n",
      "[3 rows x 18433 columns]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9AC8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9A20>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F95F8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9828>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9A58>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9048>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD860>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDB38>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDDD8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4860>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4BA8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4630>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD550>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD6A0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDC18>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6FD5F8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDEB8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDA20>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6DA0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED7897E390>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1F6FD5F8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E752DA0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD438>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD2B0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9CC0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9668>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9E80>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4DA0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F45F8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2358>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4F98>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4358>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F48D0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6F5EF0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD828>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD668>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E752DA0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26C4D7F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD080>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDD30>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD0B8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD240>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDF28>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDA90>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64940>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F95C0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4F98>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F47B8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4630>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4E80>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2128>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2320>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2B38>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6FD358>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9A20>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9860>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4A90>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4940>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F45C0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC23C8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2C88>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2F28>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBDD30>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD2E8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD0B8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD518>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD240>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD6D8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6DA0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26C4D7F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26E49208>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD048>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDCC0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDB70>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F99B0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9F28>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9CF8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD8D0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDC50>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDB70>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2C88>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2F98>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2D30>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6CC0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9B38>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26C4D0F0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9860>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9CF8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9630>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6F51D0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2F60>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2C88>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED7897E358>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDF28>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD7F0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E6F10B8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2C18>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC22B0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E6F10B8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2240>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2860>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64908>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4BA8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4828>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED0430FE48>, <torchvision.transforms.transforms.Lambda object at 0x000001ED0430FDA0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED0430FCC0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6DA0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6F51D0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1F6F5C50>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6F5C50>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9CF8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9860>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64940>, <torchvision.transforms.transforms.Lambda object at 0x000001ED223A94A8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1F6FD240>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F41D0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4978>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F43C8>]\n",
      "(1604, 18433)\n",
      "   f_3_0  f_3_1  f_3_2  f_3_3  f_3_4  f_3_5  f_3_6  f_3_7  f_3_8  f_3_9  \\\n",
      "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "     ...      f_3_18423  f_3_18424  f_3_18425  f_3_18426  f_3_18427  \\\n",
      "0    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "1    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "2    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   f_3_18428  f_3_18429  f_3_18430  f_3_18431  f_3_18432  \n",
      "0        0.0        0.0        0.0        0.0  -0.077593  \n",
      "1        0.0        0.0        0.0        0.0  -0.104506  \n",
      "2        0.0        0.0        0.0        0.0  -0.074326  \n",
      "\n",
      "[3 rows x 18433 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DDCF8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD390>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD828>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD278>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD0B8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDD68>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED223A94A8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD588>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDFD0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E575748>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26E64940>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26B0BF60>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDB00>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD668>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD860>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDEB8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED223A94A8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9B38>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9668>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E752DA0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2668>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2438>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6FD5F8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD358>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD198>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9CC0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9A90>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9C88>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2908>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2CF8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC29E8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E49208>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD048>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD208>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4438>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F46D8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4908>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E575748>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26B0BF60>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1F6F5C50>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DDCC0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD908>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDB00>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED223A94A8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED222F6DA0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDB00>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E49208>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26E64940>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2D68>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD4E0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD908>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDC18>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBDBA8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDD68>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD3C8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2F60>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2E48>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC24A8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E49208>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD080>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD2E8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD2E8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD630>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDB00>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9978>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9BE0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9828>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD1D0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD6A0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDF60>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2438>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2C18>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2550>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED0B117128>, <torchvision.transforms.transforms.Lambda object at 0x000001ED0B1170F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED0B117518>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED7897E358>, <torchvision.transforms.transforms.Lambda object at 0x000001ED222F6CC0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26B0BF60>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED7897E390>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26B0BF60>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4CF8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64940>, <torchvision.transforms.transforms.Lambda object at 0x000001ED7897E390>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED222F6CC0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2828>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2DD8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2780>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBDE10>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBDBA8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDD68>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6DA0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F45F8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4B38>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC20F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2860>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC27B8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2B38>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2F60>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC22B0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E575748>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6F51D0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1F6F5C50>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4AC8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F48D0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F41D0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC23C8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2160>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2710>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2470>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2048>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2198>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD630>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD2E8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDCC0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4160>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4E48>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4550>]\n",
      "(1604, 18433)\n",
      "   f_4_0  f_4_1  f_4_2  f_4_3  f_4_4  f_4_5  f_4_6  f_4_7  f_4_8  f_4_9  \\\n",
      "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "     ...      f_4_18423  f_4_18424  f_4_18425  f_4_18426  f_4_18427  \\\n",
      "0    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "1    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "2    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   f_4_18428  f_4_18429  f_4_18430  f_4_18431  f_4_18432  \n",
      "0        0.0        0.0        0.0        0.0  -0.036336  \n",
      "1        0.0        0.0        0.0        0.0  -0.092838  \n",
      "2        0.0        0.0        0.0        0.0  -0.029478  \n",
      "\n",
      "[3 rows x 18433 columns]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9780>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9860>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F92E8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9160>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9BE0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9978>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED7897E390>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2E48>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2CF8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBDCF8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD278>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD3C8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E6E2860>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F90F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9320>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64908>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD358>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD978>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4F98>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4390>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4400>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2710>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2C50>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC29B0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6FD358>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6FD7F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1F6FD5F8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4B70>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4588>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F46A0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD4A8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDD30>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDB70>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64908>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F94E0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9F60>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E6F10B8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6FD7F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4F28>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1E6F10B8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6FD7F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4E10>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D7F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2F60>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2B70>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC20B8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC29B0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED223A94A8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDE80>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD208>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD198>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DDBA8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD588>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2A20>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2550>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2A90>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6FD7F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6F5C50>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4940>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD358>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD588>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD400>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED7897E320>, <torchvision.transforms.transforms.Lambda object at 0x000001ED7897E0F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED7897E358>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4550>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4E10>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F4EF0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6FD358>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6FD7F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F96D8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26EBD0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26EBD198>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBD780>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F48D0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4160>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F45C0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED1F6FD358>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2320>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2668>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E64940>, <torchvision.transforms.transforms.Lambda object at 0x000001ED223A94A8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1E6E2860>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F9F28>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F9240>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F9860>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2240>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2E10>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC26D8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED222F6CC0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1E752DA0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26EBDDA0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5DD6D8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD6A0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DDC88>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2438>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2390>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2EB8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED7897E390>, <torchvision.transforms.transforms.Lambda object at 0x000001ED7897E0F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED7897E320>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26B0BF60>, <torchvision.transforms.transforms.Lambda object at 0x000001ED26C4D0F0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED26C4D7F0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED78AC2B38>, <torchvision.transforms.transforms.Lambda object at 0x000001ED78AC2DD8>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED78AC2DA0>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26E49208>, <torchvision.transforms.transforms.Lambda object at 0x000001ED1F6FD240>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED1F6FD5F8>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED26C4D0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5DD2B0>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5DD978>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED7897E0F0>, <torchvision.transforms.transforms.Lambda object at 0x000001ED7897E390>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED7897E358>]\n",
      "gpu: 0  available: True\n",
      "Using:\n",
      " [<torchvision.transforms.transforms.ToPILImage object at 0x000001ED2B5F4EB8>, <torchvision.transforms.transforms.Lambda object at 0x000001ED2B5F4668>, <torchvision.transforms.transforms.ToTensor object at 0x000001ED2B5F47F0>]\n",
      "(1604, 18433)\n",
      "   f_5_0  f_5_1  f_5_2  f_5_3  f_5_4  f_5_5  f_5_6  f_5_7  f_5_8  f_5_9  \\\n",
      "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "     ...      f_5_18423  f_5_18424  f_5_18425  f_5_18426  f_5_18427  \\\n",
      "0    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "1    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "2    ...            0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   f_5_18428  f_5_18429  f_5_18430  f_5_18431  f_5_18432  \n",
      "0        0.0        0.0        0.0        0.0  -0.114819  \n",
      "1        0.0        0.0        0.0        0.0  -0.000543  \n",
      "2        0.0        0.0        0.0        0.0  -0.128690  \n",
      "\n",
      "[3 rows x 18433 columns]\n"
     ]
    }
   ],
   "source": [
    "n_models = 5\n",
    "repeat_count = 40\n",
    "\n",
    "for nm in range(n_models):\n",
    "    prediction = get_prediction(train_df, fold=nm+1, seed=0)\n",
    "    for i in range(repeat_count-1):\n",
    "        next_prediction = get_prediction(train_df, fold=nm+1, seed=i+1)\n",
    "        prediction += next_prediction\n",
    "        del next_prediction\n",
    "        gc.collect()\n",
    "        \n",
    "    prediction = np.array(prediction, dtype=np.float32) / (repeat_count*1.0)\n",
    "    \n",
    "    print(prediction.shape)\n",
    "    columns = ['f_{}_{}'.format(nm+1, i) for i in range(prediction.shape[1])]\n",
    "    df = pd.DataFrame(data=prediction,    # values\n",
    "              columns=columns)  # 1st row as the column names\n",
    "    print(df.head(3))\n",
    "    df.to_csv('Data/resnet_extract_features_fold_{}_{}_avg_train.csv'.format(nm+1, repeat_count), float_format=\"%.6f\", index=False)\n",
    "    \n",
    "    del df, prediction, columns\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([pd.read_csv('Data/resnet_extract_features_fold_{}_40_avg_train.csv'.format(i+1)) for i in range(5)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 92165)\n"
     ]
    }
   ],
   "source": [
    "print(all_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import decomposition\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(whiten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"500\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated components:  92165\n",
      "Explained variances:  [  2.29538335e+02   1.83189510e+01   4.04709220e+00 ...,   1.04882427e-08\n",
      "   1.01368143e-08   4.52613145e-29]\n",
      "False    1461\n",
      "True      143\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(1,figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_xlabel('n_components')\n",
    "ax.set_ylabel('explained variance')\n",
    "ax.set_ylim(0,1.0)\n",
    "ax.set_xlim(0,100)\n",
    "ax.plot(pca.explained_variance_)\n",
    "print(\"Evaluated components: \", pca.n_components_ )\n",
    "print(\"Explained variances: \", pca.explained_variance_)\n",
    "print(pd.Series(pca.explained_variance_ >= 1e-3).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### according to our threshold for explained variances, we kept only 143 features in the end (from 92165->143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(whiten=True, n_components=143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=143, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the pca into binary for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pca.pickle', 'wb') as f:\n",
    "    pickle.dump(pca, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pickle\\n\\nwith open('data.pickle', 'rb') as f:\\n    # The protocol version used is detected automatically, so we do not\\n    # have to specify it.\\n    data = pickle.load(f)\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to load\n",
    "'''\n",
    "import pickle\n",
    "\n",
    "with open('data.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    data = pickle.load(f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 143)\n",
      "[[ -1.07930593e+00   3.61811937e-01  -1.93310938e-01 ...,   1.61987243e-01\n",
      "    8.24893281e-02   8.60207560e-01]\n",
      " [ -1.27513124e+00   1.09285516e+00  -1.76740196e+00 ...,   1.13151393e+00\n",
      "   -4.96053238e-01   2.57424762e-01]\n",
      " [  1.51560974e-01  -1.42116007e+00  -7.14913200e-01 ...,  -2.71009651e-01\n",
      "   -2.35507495e-01   5.26263103e-01]\n",
      " ..., \n",
      " [ -9.57784791e-01   3.44685590e-02  -3.91137321e-03 ...,  -1.20089888e+00\n",
      "   -1.18921486e+00  -1.60103576e+00]\n",
      " [ -9.57813819e-01   2.71765516e-01   3.44904777e+00 ...,  -7.78936505e-01\n",
      "    1.05206471e+00   1.04258188e+00]\n",
      " [  1.25145321e+00   8.08568233e-01  -3.49437291e-02 ...,  -2.48148603e-03\n",
      "   -2.27018605e-01  -6.68810969e-01]]\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array(pca.transform(all_df))\n",
    "print(new_data.shape)\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the new transformed data into training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
      "0 -1.079306  0.361812 -0.193311 -0.334287  1.333680  0.191776 -0.014934   \n",
      "1 -1.275131  1.092855 -1.767402 -1.288512  0.030449  0.210168  0.076340   \n",
      "2  0.151561 -1.421160 -0.714913  0.510925 -0.355384  0.449164 -0.792646   \n",
      "3 -1.224287  0.939124  2.392260 -0.464758 -0.621168  1.027984 -0.101303   \n",
      "4 -0.193139 -1.781757  0.492136  0.837812  0.778158  0.949492  0.388729   \n",
      "\n",
      "        f_7       f_8       f_9     ...         f_134     f_135     f_136  \\\n",
      "0 -0.761672 -0.615338  0.077872     ...      0.259044 -0.628371 -0.552066   \n",
      "1 -0.432053  1.077584 -0.837257     ...      1.024538 -1.077335 -0.202930   \n",
      "2 -0.177485  2.652131  2.433116     ...      1.138539  0.368692 -0.138988   \n",
      "3  0.999282 -0.426461 -0.372872     ...      0.538603  0.337439  0.027309   \n",
      "4 -0.025536  0.939708 -2.627514     ...     -0.427708  0.703106  0.710379   \n",
      "\n",
      "      f_137     f_138     f_139     f_140     f_141     f_142  is_iceberg  \n",
      "0  0.636624  0.200980  0.161970  0.161987  0.082489  0.860208           0  \n",
      "1  0.640657 -1.149087  1.109839  1.131514 -0.496053  0.257425           0  \n",
      "2  0.435529  0.231634  0.108105 -0.271010 -0.235507  0.526263           1  \n",
      "3 -1.344215  1.011958  1.106248 -0.612353  0.012176  0.156628           0  \n",
      "4  1.778261 -0.858479 -0.885096 -0.512088  1.043374 -0.994539           0  \n",
      "\n",
      "[5 rows x 144 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = ['f_{}'.format(i) for i in range(new_data.shape[1])]\n",
    "df = pd.DataFrame(data=new_data,    # values\n",
    "              columns=columns)  # 1st row as the column names\n",
    "old_train = pd.read_json('Data/train.json')\n",
    "df['is_iceberg'] = old_train['is_iceberg']\n",
    "print(df.head(5))\n",
    "df.to_csv('Data/pca_projected_143_from_resnet_train.csv', float_format=\"%.6f\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
