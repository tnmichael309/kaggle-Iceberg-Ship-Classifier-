{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, SparsePCA, MiniBatchSparsePCA, KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "import copy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kfold = KFold(5, shuffle=True, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from meta_featured_trainer import MetaFeatureTrainer\n",
    "from resnet import fineTuneResNet50,lessFilterResNet50, paperResNet18, nnResNet, get_ensemble_resnet\n",
    "from senet import senetXX_generic\n",
    "from swwae_trainer import SWWAETrainer\n",
    "from swwae import get_swwae\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class base_tuner():\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.default_params = {}\n",
    "        \n",
    "    def fit_and_update_params(self, params, update=True):\n",
    "        clf = self.get_clf()\n",
    "\n",
    "        gs = GridSearchCV(clf, params, scoring='neg_log_loss', cv=kfold, return_train_score=False )\n",
    "        gs.fit(self.X, self.y)\n",
    "        \n",
    "        cv_df = pd.DataFrame().from_dict(gs.cv_results_)\n",
    "        cv_df = cv_df[['mean_test_score', 'std_test_score', 'params', 'rank_test_score']]\n",
    "        cv_df = cv_df.sort_values(by=['rank_test_score', 'std_test_score']).reset_index(drop=True)\n",
    "        best_params = cv_df.loc[0, 'params']\n",
    "        \n",
    "        if update is True:\n",
    "            self.default_params.update(best_params)\n",
    "        \n",
    "        print('Selected hyper-params:', best_params)\n",
    "        print('==============================> cv score: {:.4f}'.format(cv_df.loc[0, 'mean_test_score']))\n",
    "        return best_params\n",
    "    \n",
    "    def tune(self):\n",
    "        pass\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class lgbm_tuner(base_tuner):\n",
    "    def __init__(self, X, y):\n",
    "        super(lgbm_tuner, self).__init__(X, y)\n",
    "        self.default_params = {\n",
    "            'n_jobs': 4,\n",
    "            'objective': 'binary',\n",
    "            'random_state': 0,\n",
    "            'boosting_type': 'dart'\n",
    "        }\n",
    "    \n",
    "    def tune_est_num_and_lr(self):\n",
    "        params = {\n",
    "            'n_estimators': [100, 200, 400, 800],\n",
    "            'learning_rate': [0.1, 0.05, 0.01, 0.005]\n",
    "        }\n",
    "\n",
    "        self.fit_and_update_params(params)\n",
    "   \n",
    "    def tune_leaves_num_and_gamma(self):\n",
    "        params = {\n",
    "            'num_leaves': [2, 3, 7, 15, 31, 63],\n",
    "            'min_split_gain': [.0, .1, .2]\n",
    "        }\n",
    "        self.fit_and_update_params(params)\n",
    "     \n",
    "    def tune_sampling(self):\n",
    "        params = {\n",
    "            'subsample': [1., .8, .6, .4, .2],\n",
    "            'colsample_bytree': [1., .8, .6, .4, .2]\n",
    "        }\n",
    "        best_parmas = self.fit_and_update_params(params, update=False)\n",
    "        \n",
    "        next_params = {}\n",
    "        for k,v in best_parmas.items():\n",
    "            if v == 1.:\n",
    "                next_params[k] = [1., .95, .9, .85]\n",
    "            else:\n",
    "                next_params[k] = [v+.15, v+.1, v+.05, v, v-.05, v-.1, v-.15]\n",
    " \n",
    "        self.fit_and_update_params(next_params)\n",
    "        \n",
    "    def tune_regularization(self):\n",
    "        params = {\n",
    "            'reg_alpha': [1., .8, .6, .4, .2, .0],\n",
    "            'reg_lambda': [1., .8, .6, .4, .2, .0]\n",
    "        }\n",
    "        \n",
    "        best_parmas = self.fit_and_update_params(params, update=False)\n",
    "        \n",
    "        next_params = {}\n",
    "        for k,v in best_parmas.items():\n",
    "            if v == 1.:\n",
    "                next_params[k] = [1., .95, .9, .85]\n",
    "            elif v == 0.:\n",
    "                next_params[k] = [.0, .05, .1, .15]\n",
    "            else:\n",
    "                next_params[k] = [v+.15, v+.1, v+.05, v, v-.05, v-.1, v-.15]\n",
    " \n",
    "        self.fit_and_update_params(next_params)\n",
    "    \n",
    "    def tune(self):\n",
    "        print('lgb tuner start tuning')\n",
    "        self.tune_est_num_and_lr()\n",
    "        self.tune_leaves_num_and_gamma()\n",
    "        self.tune_sampling()\n",
    "        self.tune_regularization()\n",
    "        \n",
    "        return self.get_clf()\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return lightgbm.LGBMClassifier(**self.default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class xgb_tuner(base_tuner):\n",
    "    def __init__(self, X, y):\n",
    "        super(xgb_tuner, self).__init__(X, y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.default_params = {\n",
    "            'n_jobs': 4,\n",
    "            'objective': 'binary:logistic',\n",
    "            'seed': 0,\n",
    "            'eval_metric': 'logloss'\n",
    "        }\n",
    "    \n",
    "    def tune_booster(self):\n",
    "        params = {\n",
    "            'booster': ['dart', 'gbtree']\n",
    "        }\n",
    "        self.fit_and_update_params(params)\n",
    "        \n",
    "    def tune_est_num_and_lr(self):\n",
    "        params = {\n",
    "            'n_estimators': [100, 200, 400, 800],\n",
    "            'learning_rate': [0.1, 0.05, 0.01, 0.005]\n",
    "        }\n",
    "\n",
    "        self.fit_and_update_params(params)\n",
    "   \n",
    "    def tune_max_depth(self):\n",
    "        params = {\n",
    "            'max_depth': [1, 3, 5, 7, 9]\n",
    "        }\n",
    "        self.fit_and_update_params(params)\n",
    "        \n",
    "    def tune_child_w_and_gamma(self):\n",
    "        params = {\n",
    "            'min_child_weight': [1, 2, 4, 6, 8, 10],\n",
    "            'gamma': [0, 0.1, 0.2]\n",
    "        }\n",
    "        self.fit_and_update_params(params)\n",
    "     \n",
    "    def tune_sampling(self):\n",
    "        params = {\n",
    "            'subsample': [1., .8, .6, .4, .2],\n",
    "            'colsample_bytree': [1., .8, .6, .4, .2]\n",
    "        }\n",
    "        best_parmas = self.fit_and_update_params(params, update=False)\n",
    "        \n",
    "        next_params = {}\n",
    "        for k,v in best_parmas.items():\n",
    "            if v == 1.:\n",
    "                next_params[k] = [1., .95, .9, .85]\n",
    "            else:\n",
    "                next_params[k] = [v+.15, v+.1, v+.05, v, v-.05, v-.1, v-.15]\n",
    " \n",
    "        self.fit_and_update_params(next_params)\n",
    "        \n",
    "    def tune_regularization(self):\n",
    "        params = {\n",
    "            'reg_alpha': [1., .8, .6, .4, .2, .0],\n",
    "            'reg_lambda': [1., .8, .6, .4, .2, .0]\n",
    "        }\n",
    "        \n",
    "        best_parmas = self.fit_and_update_params(params, update=False)\n",
    "        \n",
    "        next_params = {}\n",
    "        for k,v in best_parmas.items():\n",
    "            if v == 1.:\n",
    "                next_params[k] = [1., .95, .9, .85]\n",
    "            elif v == 0.:\n",
    "                next_params[k] = [.0, .05, .1, .15]\n",
    "            else:\n",
    "                next_params[k] = [v+.15, v+.1, v+.05, v, v-.05, v-.1, v-.15]\n",
    " \n",
    "        self.fit_and_update_params(next_params)\n",
    "    \n",
    "    def tune(self):\n",
    "        print('xgb tuner start tuning')\n",
    "        self.tune_booster()\n",
    "        self.tune_est_num_and_lr()\n",
    "        self.tune_max_depth()\n",
    "        self.tune_child_w_and_gamma()\n",
    "        self.tune_sampling()\n",
    "        self.tune_regularization()\n",
    "        \n",
    "        return self.get_clf()\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return xgboost.XGBClassifier(**self.default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class lr_tuner(base_tuner):\n",
    "    def __init__(self, X, y):\n",
    "        super(lr_tuner, self).__init__(X, y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.default_params = {\n",
    "            'penalty': 'l2',\n",
    "            'max_iter': 2000\n",
    "        }\n",
    "\n",
    "    def tune(self):\n",
    "        print('logistic regression tuner start tuning')\n",
    "        params = {\n",
    "            'solver': ['lbfgs', 'sag']\n",
    "        }\n",
    "        \n",
    "        self.fit_and_update_params(params)\n",
    "        \n",
    "        return self.get_clf()\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return LogisticRegression(**self.default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class mlp_tuner(base_tuner):\n",
    "    def __init__(self, X, y):\n",
    "        super(mlp_tuner, self).__init__(X, y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.default_params = {\n",
    "            'learning_rate': 'adaptive',\n",
    "            'learning_rate_init': 0.005,\n",
    "            'max_iter': 2000,\n",
    "            'random_state':0\n",
    "        }\n",
    "\n",
    "    def tune(self):\n",
    "        print('mlp tuner start tuning')\n",
    "        params = {\n",
    "            'solver':['lbfgs', 'sgd', 'adam'],\n",
    "            'hidden_layer_sizes': [(100,), (150,), (100, 100,)],\n",
    "        }\n",
    "        \n",
    "        self.fit_and_update_params(params)\n",
    "        \n",
    "        params = {\n",
    "            'alpha': [10., 5., 2., 1., .8, .5, .2, .1],\n",
    "        }\n",
    "        \n",
    "        self.fit_and_update_params(params)\n",
    "        \n",
    "        return self.get_clf()\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return MLPClassifier(**self.default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class adb_tuner(base_tuner):\n",
    "    def __init__(self, X, y):\n",
    "        super(adb_tuner, self).__init__(X, y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.default_params = {\n",
    "            'algorithm': 'SAMME.R',\n",
    "            'random_state':0\n",
    "        }\n",
    "\n",
    "    def tune(self):\n",
    "        print('adaboost tuner start tuning')\n",
    "        params = {\n",
    "            'n_estimators': [100, 200, 400, 800],\n",
    "            'learning_rate': [0.1, 0.05, 0.01, 0.005]\n",
    "        }\n",
    "        \n",
    "        self.fit_and_update_params(params)\n",
    "\n",
    "        return self.get_clf()\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return AdaBoostClassifier(**self.default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class bg_tuner(base_tuner):\n",
    "    def __init__(self, X, y):\n",
    "        super(bg_tuner, self).__init__(X, y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.default_params = {\n",
    "            'random_state':0,\n",
    "            'bootstrap_features':True\n",
    "        }\n",
    "        \n",
    "    def tune_est_num(self):\n",
    "        params = {\n",
    "            'n_estimators': [100, 200, 400, 800]\n",
    "        }\n",
    "\n",
    "        self.fit_and_update_params(params)\n",
    "     \n",
    "    def tune_sampling(self):\n",
    "        params = {\n",
    "            'max_samples': [1., .8, .6, .4, .2],\n",
    "            'max_features': [1., .8, .6, .4, .2]\n",
    "        }\n",
    "        best_parmas = self.fit_and_update_params(params, update=False)\n",
    "        \n",
    "        next_params = {}\n",
    "        for k,v in best_parmas.items():\n",
    "            if v == 1.:\n",
    "                next_params[k] = [1., .95, .9, .85]\n",
    "            else:\n",
    "                next_params[k] = [v+.15, v+.1, v+.05, v, v-.05, v-.1, v-.15]\n",
    " \n",
    "        self.fit_and_update_params(next_params)\n",
    "    \n",
    "    def tune(self):\n",
    "        print('bagging tuner start tuning')\n",
    "        self.tune_est_num()\n",
    "        self.tune_sampling()\n",
    "\n",
    "        return self.get_clf()\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return BaggingClassifier(**self.default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class gb_tuner(base_tuner):\n",
    "    def __init__(self, X, y):\n",
    "        super(gb_tuner, self).__init__(X, y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.default_params = {\n",
    "            'random_state':0\n",
    "        }\n",
    "        \n",
    "    def tune_loss_criterion(self):\n",
    "        params = {\n",
    "            'loss': ['deviance', 'exponential'],\n",
    "            'criterion': ['friedman_mse', 'mse']\n",
    "        }\n",
    "\n",
    "        self.fit_and_update_params(params)\n",
    "        \n",
    "    def tune_est_num_and_lr(self):\n",
    "        params = {\n",
    "            'n_estimators': [100, 200, 400, 800],\n",
    "            'learning_rate': [0.1, 0.05, 0.01, 0.005]\n",
    "        }\n",
    "\n",
    "        self.fit_and_update_params(params)\n",
    "   \n",
    "    def tune_max_depth(self):\n",
    "        params = {\n",
    "            'max_depth': [1, 3, 5, 7, 9]\n",
    "        }\n",
    "        self.fit_and_update_params(params)\n",
    "        \n",
    "    def tune_child(self):\n",
    "        params = {\n",
    "            'min_samples_split': [2, 3, 7, 15,31],\n",
    "            'min_impurity_decrease': [0, 0.1, 0.2]\n",
    "        }\n",
    "        self.fit_and_update_params(params)\n",
    "     \n",
    "    def tune_sampling(self):\n",
    "        params = {\n",
    "            'subsample': [1., .8, .6, .4, .2],\n",
    "            'max_features': [1., .8, .6, .4, .2]\n",
    "        }\n",
    "        best_parmas = self.fit_and_update_params(params, update=False)\n",
    "        \n",
    "        next_params = {}\n",
    "        for k,v in best_parmas.items():\n",
    "            if v == 1.:\n",
    "                next_params[k] = [1., .95, .9, .85]\n",
    "            else:\n",
    "                next_params[k] = [v+.15, v+.1, v+.05, v, v-.05, v-.1, v-.15]\n",
    " \n",
    "        self.fit_and_update_params(next_params)\n",
    "      \n",
    "    def tune(self):\n",
    "        print('gradient boosting tuner start tuning')\n",
    "        self.tune_loss_criterion()\n",
    "        self.tune_est_num_and_lr()\n",
    "        self.tune_max_depth()\n",
    "        self.tune_child()\n",
    "        self.tune_sampling()\n",
    "        \n",
    "        return self.get_clf()\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return GradientBoostingClassifier(**self.default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class rf_tuner(base_tuner):\n",
    "    def __init__(self, X, y):\n",
    "        super(rf_tuner, self).__init__(X, y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.default_params = {\n",
    "            'random_state':0,\n",
    "            'n_jobs': 4\n",
    "        }\n",
    "        \n",
    "    def tune_loss_criterion(self):\n",
    "        params = {\n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        }\n",
    "\n",
    "        self.fit_and_update_params(params)\n",
    "        \n",
    "    def tune_est_num(self):\n",
    "        params = {\n",
    "            'n_estimators': [100, 200, 400, 800]\n",
    "        }\n",
    "\n",
    "        self.fit_and_update_params(params)\n",
    "   \n",
    "    def tune_max_depth(self):\n",
    "        params = {\n",
    "            'max_depth': [1, 3, 5, 7, 9]\n",
    "        }\n",
    "        self.fit_and_update_params(params)\n",
    "        \n",
    "    def tune_child(self):\n",
    "        params = {\n",
    "            'min_samples_split': [2, 3, 7, 15,31],\n",
    "            'min_impurity_decrease': [0, 0.1, 0.2]\n",
    "        }\n",
    "        self.fit_and_update_params(params)\n",
    "     \n",
    "    def tune_sampling(self):\n",
    "        params = {\n",
    "            'max_features': [1., .8, .6, .4, .2]\n",
    "        }\n",
    "        best_parmas = self.fit_and_update_params(params, update=False)\n",
    "        \n",
    "        next_params = {}\n",
    "        for k,v in best_parmas.items():\n",
    "            if v == 1.:\n",
    "                next_params[k] = [1., .95, .9, .85]\n",
    "            else:\n",
    "                next_params[k] = [v+.15, v+.1, v+.05, v, v-.05, v-.1, v-.15]\n",
    " \n",
    "        self.fit_and_update_params(next_params)\n",
    "      \n",
    "    def tune(self):\n",
    "        print('random forest tuner start tuning')\n",
    "        self.tune_loss_criterion()\n",
    "        self.tune_est_num()\n",
    "        self.tune_max_depth()\n",
    "        self.tune_child()\n",
    "        self.tune_sampling()\n",
    "        \n",
    "        return self.get_clf()\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return RandomForestClassifier(**self.default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class et_tuner(rf_tuner):\n",
    "    def __init__(self, X, y):\n",
    "        super(et_tuner, self).__init__(X, y)\n",
    "\n",
    "    def tune(self):\n",
    "        print('extra tree tuner start tuning')\n",
    "        self.tune_loss_criterion()\n",
    "        self.tune_est_num()\n",
    "        self.tune_max_depth()\n",
    "        self.tune_child()\n",
    "        self.tune_sampling()\n",
    "        \n",
    "        return self.get_clf()\n",
    "    \n",
    "    def get_clf(self):\n",
    "        return ExtraTreesClassifier(**self.default_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stacking_models_api import StackingAveragedModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(fold, train, test,seed=0):\n",
    "    is_transfer_learning = False\n",
    "    model = lessFilterResNet50(fc_output=True)\n",
    "    model_name= 'Trained_model/resnet_origin_09_soft_pseudo_label_n_valid_' + str(fold) + '.db'\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "\n",
    "    tr = Trainer(\n",
    "            model,\n",
    "            optimizer,\n",
    "            epochs=1800,\n",
    "            milestones=[300, 1100, 1600],\n",
    "            gamma=0.2,\n",
    "            batch_size=128, \n",
    "            use_cuda=True, \n",
    "            gpu_idx=0,\n",
    "            best_model_name = model_name,\n",
    "            seed=seed,\n",
    "            verbose=0)\n",
    "\n",
    "    tr.load_checkpoint()\n",
    "\n",
    "    data_augmentation_args = {\n",
    "        'mirror': False, # not useful here\n",
    "        'rotate': True,\n",
    "        'scale': True,\n",
    "        'translation': True\n",
    "    }\n",
    "\n",
    "    new_train = tr.test(train, is_transfer_learning=is_transfer_learning, is_augment=True, data_augmentation_args=data_augmentation_args)\n",
    "    new_test = tr.test(test, is_transfer_learning=is_transfer_learning, is_augment=True, data_augmentation_args=data_augmentation_args)\n",
    "\n",
    "    del model, optimizer, tr\n",
    "    \n",
    "    columns = ['f_{}'.format(i) for i in range(new_train.shape[1])]\n",
    "    new_train_df = pd.DataFrame(data=new_train,    # values\n",
    "                  index=[i for i in range(new_train.shape[0])],\n",
    "                  columns=columns)  # 1st row as the column names\n",
    "    new_test_df = pd.DataFrame(data=new_test,    # values\n",
    "                  index=[i for i in range(new_test.shape[0])],\n",
    "                  columns=columns)  # 1st row as the column names\n",
    "    \n",
    "    return new_train_df, new_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (8424, 4)\n",
      "=================================================\n",
      "Processing fold  1\n",
      "=================================================\n",
      "gpu: 0  available: True\n",
      "epoch= 252 best_loss= 0.1741405725479126\n",
      "(4590, 2049) (8424, 2049)\n",
      "logistic regression tuner start tuning\n",
      "Selected hyper-params: {'solver': 'lbfgs'}\n",
      "==============================> cv score: -0.0414\n",
      "lgb tuner start tuning\n",
      "Selected hyper-params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "==============================> cv score: -0.0462\n",
      "Selected hyper-params: {'min_split_gain': 0.0, 'num_leaves': 7}\n",
      "==============================> cv score: -0.0458\n",
      "Selected hyper-params: {'colsample_bytree': 0.6, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0452\n",
      "Selected hyper-params: {'colsample_bytree': 0.5499999999999999, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0450\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0450\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0450\n",
      "Fold 1, lgb tuner predictions\n",
      " [ 0.00341267  0.11423964  0.00287673 ...,  0.00343424  0.99688222\n",
      "  0.00343424]\n",
      "\n",
      "*** Start to train meta model for stacking averaged model ***\n",
      "\n",
      "\n",
      "==================\n",
      " clf_1\n",
      "score= 0.0429539140283\n",
      "score= 0.0309537057287\n",
      "score= 0.0292276034853\n",
      "score= 0.057013355122\n",
      "score= 0.0470402668193\n",
      "Avg score =  0.0414377690367\n",
      "\n",
      "==================\n",
      " clf_2\n",
      "score= 0.0455429391202\n",
      "score= 0.0343303632505\n",
      "score= 0.0367821804731\n",
      "score= 0.05609170077\n",
      "score= 0.0520934029312\n",
      "Avg score =  0.044968117309\n",
      "\n",
      "==================\n",
      " knn_8\n",
      "score= 0.17359201063\n",
      "score= 0.16864745719\n",
      "score= 0.0281691613386\n",
      "score= 0.247415628086\n",
      "score= 0.177560659968\n",
      "Avg score =  0.159076983443\n",
      "\n",
      "==================\n",
      " knn_16\n",
      "score= 0.103051028886\n",
      "score= 0.13317164406\n",
      "score= 0.0274627459326\n",
      "score= 0.246898904086\n",
      "score= 0.108265426077\n",
      "Avg score =  0.123769949808\n",
      "\n",
      "==================\n",
      " knn_32\n",
      "score= 0.104959671749\n",
      "score= 0.0976751619311\n",
      "score= 0.0282177625728\n",
      "score= 0.179095284572\n",
      "score= 0.110495455814\n",
      "Avg score =  0.104088667328\n",
      "\n",
      "==================\n",
      " knn_64\n",
      "score= 0.104769856238\n",
      "score= 0.0615220458671\n",
      "score= 0.0281123620846\n",
      "score= 0.178016303515\n",
      "score= 0.11019331879\n",
      "Avg score =  0.0965227772988\n",
      "\n",
      "==================\n",
      " kmean_2\n",
      "\n",
      "==================\n",
      " kmean_3\n",
      "\n",
      "==================\n",
      " kmean_4\n",
      "feature correlations\n",
      "                clf_1     clf_2  is_iceberg     knn_8  knn_8_dist    knn_16  \\\n",
      "clf_1        1.000000  0.997639    0.979258  0.997224    0.046110  0.998507   \n",
      "clf_2        0.997639  1.000000    0.977377  0.995784    0.052593  0.996552   \n",
      "is_iceberg   0.979258  0.977377    1.000000  0.977030    0.042453  0.978655   \n",
      "knn_8        0.997224  0.995784    0.977030  1.000000    0.048033  0.998656   \n",
      "knn_8_dist   0.046110  0.052593    0.042453  0.048033    1.000000  0.049207   \n",
      "knn_16       0.998507  0.996552    0.978655  0.998656    0.049207  1.000000   \n",
      "knn_16_dist  0.002579  0.012222   -0.000995  0.003014    0.968601  0.004138   \n",
      "knn_32       0.998964  0.996581    0.978798  0.997945    0.049302  0.999328   \n",
      "knn_32_dist -0.055063 -0.043188   -0.057499 -0.055541    0.872472 -0.054883   \n",
      "knn_64       0.999401  0.996808    0.979585  0.997570    0.049941  0.999017   \n",
      "knn_64_dist -0.110119 -0.097267   -0.110913 -0.110972    0.729842 -0.110749   \n",
      "kmean_2_0   -0.984256 -0.983718   -0.962276 -0.980170   -0.095889 -0.982537   \n",
      "kmean_2_1    0.984256  0.983718    0.962276  0.980170    0.095889  0.982537   \n",
      "kmean_3_0   -0.653015 -0.650147   -0.636278 -0.649798   -0.102464 -0.650502   \n",
      "kmean_3_1    0.951175  0.949185    0.927090  0.944535   -0.027495  0.945019   \n",
      "kmean_3_2   -0.359874 -0.360763   -0.350981 -0.355896    0.143042 -0.355672   \n",
      "kmean_4_0   -0.627455 -0.625009   -0.611828 -0.624827   -0.259846 -0.625514   \n",
      "kmean_4_1    0.911605  0.909279    0.888903  0.904820   -0.047442  0.906100   \n",
      "kmean_4_2   -0.299918 -0.298552   -0.292596 -0.298811    0.197379 -0.299054   \n",
      "kmean_4_3   -0.149072 -0.150153   -0.145250 -0.144677    0.217685 -0.145253   \n",
      "\n",
      "             knn_16_dist    knn_32  knn_32_dist    knn_64  knn_64_dist  \\\n",
      "clf_1           0.002579  0.998964    -0.055063  0.999401    -0.110119   \n",
      "clf_2           0.012222  0.996581    -0.043188  0.996808    -0.097267   \n",
      "is_iceberg     -0.000995  0.978798    -0.057499  0.979585    -0.110913   \n",
      "knn_8           0.003014  0.997945    -0.055541  0.997570    -0.110972   \n",
      "knn_8_dist      0.968601  0.049302     0.872472  0.049941     0.729842   \n",
      "knn_16          0.004138  0.999328    -0.054883  0.999017    -0.110749   \n",
      "knn_16_dist     1.000000  0.004230     0.961367  0.004803     0.857770   \n",
      "knn_32          0.004230  1.000000    -0.054916  0.999600    -0.111013   \n",
      "knn_32_dist     0.961367 -0.054916     1.000000 -0.054546     0.960890   \n",
      "knn_64          0.004803  0.999600    -0.054546  1.000000    -0.110910   \n",
      "knn_64_dist     0.857770 -0.111013     0.960890 -0.110910     1.000000   \n",
      "kmean_2_0      -0.061472 -0.982983    -0.008148 -0.984157     0.048680   \n",
      "kmean_2_1       0.061472  0.982983     0.008148  0.984157    -0.048680   \n",
      "kmean_3_0      -0.080722 -0.650401    -0.047977 -0.650555    -0.030338   \n",
      "kmean_3_1      -0.072103  0.945992    -0.123954  0.947279    -0.166931   \n",
      "kmean_3_2       0.169631 -0.356881     0.192366 -0.358165     0.221598   \n",
      "kmean_4_0      -0.250766 -0.625292    -0.222274 -0.625429    -0.187990   \n",
      "kmean_4_1      -0.090954  0.907212    -0.140026  0.908512    -0.179580   \n",
      "kmean_4_2       0.225322 -0.299048     0.238232 -0.299228     0.225591   \n",
      "kmean_4_3       0.239279 -0.146892     0.256046 -0.148195     0.273602   \n",
      "\n",
      "             kmean_2_0  kmean_2_1  kmean_3_0  kmean_3_1  kmean_3_2  kmean_4_0  \\\n",
      "clf_1        -0.984256   0.984256  -0.653015   0.951175  -0.359874  -0.627455   \n",
      "clf_2        -0.983718   0.983718  -0.650147   0.949185  -0.360763  -0.625009   \n",
      "is_iceberg   -0.962276   0.962276  -0.636278   0.927090  -0.350981  -0.611828   \n",
      "knn_8        -0.980170   0.980170  -0.649798   0.944535  -0.355896  -0.624827   \n",
      "knn_8_dist   -0.095889   0.095889  -0.102464  -0.027495   0.143042  -0.259846   \n",
      "knn_16       -0.982537   0.982537  -0.650502   0.945019  -0.355672  -0.625514   \n",
      "knn_16_dist  -0.061472   0.061472  -0.080722  -0.072103   0.169631  -0.250766   \n",
      "knn_32       -0.982983   0.982983  -0.650401   0.945992  -0.356881  -0.625292   \n",
      "knn_32_dist  -0.008148   0.008148  -0.047977  -0.123954   0.192366  -0.222274   \n",
      "knn_64       -0.984157   0.984157  -0.650555   0.947279  -0.358165  -0.625429   \n",
      "knn_64_dist   0.048680  -0.048680  -0.030338  -0.166931   0.221598  -0.187990   \n",
      "kmean_2_0     1.000000  -1.000000   0.652008  -0.913041   0.317929   0.627001   \n",
      "kmean_2_1    -1.000000   1.000000  -0.652008   0.913041  -0.317929  -0.627001   \n",
      "kmean_3_0     0.652008  -0.652008   1.000000  -0.595310  -0.421131   0.592960   \n",
      "kmean_3_1    -0.913041   0.913041  -0.595310   1.000000  -0.478067  -0.572478   \n",
      "kmean_3_2     0.317929  -0.317929  -0.421131  -0.478067   1.000000  -0.001959   \n",
      "kmean_4_0     0.627001  -0.627001   0.592960  -0.572478  -0.001959   1.000000   \n",
      "kmean_4_1    -0.872255   0.872255  -0.568717   0.955329  -0.456712  -0.546905   \n",
      "kmean_4_2     0.299393  -0.299393   0.459187  -0.273359  -0.193378  -0.231567   \n",
      "kmean_4_3     0.101517  -0.101517  -0.353431  -0.288541   0.712054  -0.339876   \n",
      "\n",
      "             kmean_4_1  kmean_4_2  kmean_4_3  \n",
      "clf_1         0.911605  -0.299918  -0.149072  \n",
      "clf_2         0.909279  -0.298552  -0.150153  \n",
      "is_iceberg    0.888903  -0.292596  -0.145250  \n",
      "knn_8         0.904820  -0.298811  -0.144677  \n",
      "knn_8_dist   -0.047442   0.197379   0.217685  \n",
      "knn_16        0.906100  -0.299054  -0.145253  \n",
      "knn_16_dist  -0.090954   0.225322   0.239279  \n",
      "knn_32        0.907212  -0.299048  -0.146892  \n",
      "knn_32_dist  -0.140026   0.238232   0.256046  \n",
      "knn_64        0.908512  -0.299228  -0.148195  \n",
      "knn_64_dist  -0.179580   0.225591   0.273602  \n",
      "kmean_2_0    -0.872255   0.299393   0.101517  \n",
      "kmean_2_1     0.872255  -0.299393  -0.101517  \n",
      "kmean_3_0    -0.568717   0.459187  -0.353431  \n",
      "kmean_3_1     0.955329  -0.273359  -0.288541  \n",
      "kmean_3_2    -0.456712  -0.193378   0.712054  \n",
      "kmean_4_0    -0.546905  -0.231567  -0.339876  \n",
      "kmean_4_1     1.000000  -0.261147  -0.383292  \n",
      "kmean_4_2    -0.261147   1.000000  -0.162291  \n",
      "kmean_4_3    -0.383292  -0.162291   1.000000  \n",
      "meta size:  (4590, 19) (4590, 19)\n",
      "lgb tuner start tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected hyper-params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "==============================> cv score: -0.0454\n",
      "Selected hyper-params: {'min_split_gain': 0.0, 'num_leaves': 31}\n",
      "==============================> cv score: -0.0454\n",
      "Selected hyper-params: {'colsample_bytree': 0.6, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0445\n",
      "Selected hyper-params: {'colsample_bytree': 0.75, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0445\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0445\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0445\n",
      "xgb tuner start tuning\n",
      "Selected hyper-params: {'booster': 'dart'}\n",
      "==============================> cv score: -0.0471\n",
      "Selected hyper-params: {'learning_rate': 0.01, 'n_estimators': 800}\n",
      "==============================> cv score: -0.0460\n",
      "Selected hyper-params: {'max_depth': 1}\n",
      "==============================> cv score: -0.0445\n",
      "Selected hyper-params: {'gamma': 0, 'min_child_weight': 1}\n",
      "==============================> cv score: -0.0445\n",
      "Selected hyper-params: {'colsample_bytree': 0.4, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0442\n",
      "Selected hyper-params: {'colsample_bytree': 0.45, 'subsample': 0.75}\n",
      "==============================> cv score: -0.0441\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0440\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle Competitions\\kaggle-Iceberg-Ship-Classifier-\\stacking_models_api.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  out_of_fold_predictions[self.target_col] = self.out_of_fold_predictions[self.target_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.0309244699783 \n",
      "\n",
      "Fold 1, meta model (lgb tuner) predictions\n",
      " [ 0.00333329  0.09623024  0.00261212 ...,  0.00251963  0.99699215\n",
      "  0.00284684]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle Competitions\\kaggle-Iceberg-Ship-Classifier-\\stacking_models_api.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  out_of_fold_predictions[self.target_col] = self.out_of_fold_predictions[self.target_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.0378541702311 \n",
      "\n",
      "Fold 1, meta model (xgb tuner) predictions\n",
      " [ 0.00258018  0.04832762  0.00181707 ...,  0.00236612  0.99710077\n",
      "  0.00203023]\n",
      "=================================================\n",
      "Processing fold  2\n",
      "=================================================\n",
      "gpu: 0  available: True\n",
      "epoch= 82 best_loss= 0.16970072189966837\n",
      "(4590, 2049) (8424, 2049)\n",
      "logistic regression tuner start tuning\n",
      "Selected hyper-params: {'solver': 'lbfgs'}\n",
      "==============================> cv score: -0.0648\n",
      "lgb tuner start tuning\n",
      "Selected hyper-params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "==============================> cv score: -0.0714\n",
      "Selected hyper-params: {'min_split_gain': 0.2, 'num_leaves': 7}\n",
      "==============================> cv score: -0.0691\n",
      "Selected hyper-params: {'colsample_bytree': 1.0, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0683\n",
      "Selected hyper-params: {'colsample_bytree': 1.0, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0683\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0683\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0683\n",
      "Fold 2, lgb tuner predictions\n",
      " [ 0.02831142  0.02907418  0.0031012  ...,  0.00417901  0.99596336\n",
      "  0.00310245]\n",
      "\n",
      "*** Start to train meta model for stacking averaged model ***\n",
      "\n",
      "\n",
      "==================\n",
      " clf_1\n",
      "score= 0.0626761723562\n",
      "score= 0.0495507040927\n",
      "score= 0.0617867697617\n",
      "score= 0.0735584794045\n",
      "score= 0.0766526614829\n",
      "Avg score =  0.0648449574196\n",
      "\n",
      "==================\n",
      " clf_2\n",
      "score= 0.0651566746203\n",
      "score= 0.0530819170515\n",
      "score= 0.0649559263276\n",
      "score= 0.0744578678842\n",
      "score= 0.0839519614648\n",
      "Avg score =  0.0683208694697\n",
      "\n",
      "==================\n",
      " knn_8\n",
      "score= 0.264860846546\n",
      "score= 0.186121394596\n",
      "score= 0.193471946474\n",
      "score= 0.303910657763\n",
      "score= 0.382441666232\n",
      "Avg score =  0.266161302322\n",
      "\n",
      "==================\n",
      " knn_16\n",
      "score= 0.161399845272\n",
      "score= 0.151015793238\n",
      "score= 0.194219454741\n",
      "score= 0.233916122657\n",
      "score= 0.241735071172\n",
      "Avg score =  0.196457257416\n",
      "\n",
      "==================\n",
      " knn_32\n",
      "score= 0.0943585763803\n",
      "score= 0.117139552766\n",
      "score= 0.091922165993\n",
      "score= 0.233078376758\n",
      "score= 0.207238450276\n",
      "Avg score =  0.148747424435\n",
      "\n",
      "==================\n",
      " knn_64\n",
      "score= 0.0940528169461\n",
      "score= 0.0843343481485\n",
      "score= 0.0931187776912\n",
      "score= 0.0968642061094\n",
      "score= 0.141526816693\n",
      "Avg score =  0.101979393118\n",
      "\n",
      "==================\n",
      " kmean_2\n",
      "\n",
      "==================\n",
      " kmean_3\n",
      "\n",
      "==================\n",
      " kmean_4\n",
      "feature correlations\n",
      "                clf_1     clf_2  is_iceberg     knn_8  knn_8_dist    knn_16  \\\n",
      "clf_1        1.000000  0.994984    0.964128  0.994321   -0.370473  0.997348   \n",
      "clf_2        0.994984  1.000000    0.963304  0.992771   -0.376664  0.994875   \n",
      "is_iceberg   0.964128  0.963304    1.000000  0.960798   -0.365834  0.962971   \n",
      "knn_8        0.994321  0.992771    0.960798  1.000000   -0.373497  0.997151   \n",
      "knn_8_dist  -0.370473 -0.376664   -0.365834 -0.373497    1.000000 -0.373501   \n",
      "knn_16       0.997348  0.994875    0.962971  0.997151   -0.373501  1.000000   \n",
      "knn_16_dist -0.370883 -0.375639   -0.366593 -0.375089    0.984700 -0.374688   \n",
      "knn_32       0.998638  0.994735    0.963130  0.995315   -0.370288  0.998610   \n",
      "knn_32_dist -0.366623 -0.368362   -0.362144 -0.371216    0.935272 -0.370848   \n",
      "knn_64       0.998950  0.994004    0.963250  0.994160   -0.368671  0.997554   \n",
      "knn_64_dist -0.351336 -0.347926   -0.346339 -0.355619    0.836947 -0.355612   \n",
      "kmean_2_0    0.940659  0.938738    0.906816  0.935781   -0.279517  0.939086   \n",
      "kmean_2_1   -0.940659 -0.938738   -0.906816 -0.935781    0.279517 -0.939086   \n",
      "kmean_3_0    0.983079  0.976920    0.943303  0.973486   -0.347715  0.977705   \n",
      "kmean_3_1   -0.770377 -0.765113   -0.738696 -0.761816    0.124534 -0.765261   \n",
      "kmean_3_2   -0.328013 -0.326642   -0.315541 -0.326444    0.347668 -0.327635   \n",
      "kmean_4_0   -0.228597 -0.230184   -0.222446 -0.227941    0.232245 -0.226903   \n",
      "kmean_4_1    0.943913  0.942392    0.909778  0.939093   -0.411119  0.941467   \n",
      "kmean_4_2   -0.291811 -0.290583   -0.280715 -0.290415    0.326843 -0.291474   \n",
      "kmean_4_3   -0.618111 -0.615916   -0.594288 -0.614458    0.031181 -0.617189   \n",
      "\n",
      "             knn_16_dist    knn_32  knn_32_dist    knn_64  knn_64_dist  \\\n",
      "clf_1          -0.370883  0.998638    -0.366623  0.998950    -0.351336   \n",
      "clf_2          -0.375639  0.994735    -0.368362  0.994004    -0.347926   \n",
      "is_iceberg     -0.366593  0.963130    -0.362144  0.963250    -0.346339   \n",
      "knn_8          -0.375089  0.995315    -0.371216  0.994160    -0.355619   \n",
      "knn_8_dist      0.984700 -0.370288     0.935272 -0.368671     0.836947   \n",
      "knn_16         -0.374688  0.998610    -0.370848  0.997554    -0.355612   \n",
      "knn_16_dist     1.000000 -0.371264     0.979241 -0.369362     0.905575   \n",
      "knn_32         -0.371264  1.000000    -0.367650  0.999196    -0.353293   \n",
      "knn_32_dist     0.979241 -0.367650     1.000000 -0.365844     0.969583   \n",
      "knn_64         -0.369362  0.999196    -0.365844  1.000000    -0.352009   \n",
      "knn_64_dist     0.905575 -0.353293     0.969583 -0.352009     1.000000   \n",
      "kmean_2_0      -0.271872  0.941277    -0.261539  0.941481    -0.239043   \n",
      "kmean_2_1       0.271872 -0.941277     0.261539 -0.941481     0.239043   \n",
      "kmean_3_0      -0.344058  0.979927    -0.337243  0.982019    -0.320248   \n",
      "kmean_3_1       0.103294 -0.766877     0.084192 -0.768930     0.071658   \n",
      "kmean_3_2       0.375216 -0.328573     0.394489 -0.328623     0.387592   \n",
      "kmean_4_0       0.238656 -0.225157     0.244496 -0.226431     0.252085   \n",
      "kmean_4_1      -0.414441  0.942253    -0.409521  0.943327    -0.387722   \n",
      "kmean_4_2       0.358898 -0.292309     0.383596 -0.292353     0.383660   \n",
      "kmean_4_3       0.009206 -0.618989    -0.016385 -0.619005    -0.045904   \n",
      "\n",
      "             kmean_2_0  kmean_2_1  kmean_3_0  kmean_3_1  kmean_3_2  kmean_4_0  \\\n",
      "clf_1         0.940659  -0.940659   0.983079  -0.770377  -0.328013  -0.228597   \n",
      "clf_2         0.938738  -0.938738   0.976920  -0.765113  -0.326642  -0.230184   \n",
      "is_iceberg    0.906816  -0.906816   0.943303  -0.738696  -0.315541  -0.222446   \n",
      "knn_8         0.935781  -0.935781   0.973486  -0.761816  -0.326444  -0.227941   \n",
      "knn_8_dist   -0.279517   0.279517  -0.347715   0.124534   0.347668   0.232245   \n",
      "knn_16        0.939086  -0.939086   0.977705  -0.765261  -0.327635  -0.226903   \n",
      "knn_16_dist  -0.271872   0.271872  -0.344058   0.103294   0.375216   0.238656   \n",
      "knn_32        0.941277  -0.941277   0.979927  -0.766877  -0.328573  -0.225157   \n",
      "knn_32_dist  -0.261539   0.261539  -0.337243   0.084192   0.394489   0.244496   \n",
      "knn_64        0.941481  -0.941481   0.982019  -0.768930  -0.328623  -0.226431   \n",
      "knn_64_dist  -0.239043   0.239043  -0.320248   0.071658   0.387592   0.252085   \n",
      "kmean_2_0     1.000000  -1.000000   0.913919  -0.690622  -0.344956  -0.057806   \n",
      "kmean_2_1    -1.000000   1.000000  -0.913919   0.690622   0.344956   0.057806   \n",
      "kmean_3_0     0.913919  -0.913919   1.000000  -0.795386  -0.315262  -0.240866   \n",
      "kmean_3_1    -0.690622   0.690622  -0.795386   1.000000  -0.324440   0.353033   \n",
      "kmean_3_2    -0.344956   0.344956  -0.315262  -0.324440   1.000000  -0.176857   \n",
      "kmean_4_0    -0.057806   0.057806  -0.240866   0.353033  -0.176857   1.000000   \n",
      "kmean_4_1     0.845336  -0.845336   0.924957  -0.735698  -0.291603  -0.401039   \n",
      "kmean_4_2    -0.306883   0.306883  -0.280466  -0.288632   0.889630  -0.157337   \n",
      "kmean_4_3    -0.650722   0.650722  -0.594707   0.654281  -0.096317  -0.333621   \n",
      "\n",
      "             kmean_4_1  kmean_4_2  kmean_4_3  \n",
      "clf_1         0.943913  -0.291811  -0.618111  \n",
      "clf_2         0.942392  -0.290583  -0.615916  \n",
      "is_iceberg    0.909778  -0.280715  -0.594288  \n",
      "knn_8         0.939093  -0.290415  -0.614458  \n",
      "knn_8_dist   -0.411119   0.326843   0.031181  \n",
      "knn_16        0.941467  -0.291474  -0.617189  \n",
      "knn_16_dist  -0.414441   0.358898   0.009206  \n",
      "knn_32        0.942253  -0.292309  -0.618989  \n",
      "knn_32_dist  -0.409521   0.383596  -0.016385  \n",
      "knn_64        0.943327  -0.292353  -0.619005  \n",
      "knn_64_dist  -0.387722   0.383660  -0.045904  \n",
      "kmean_2_0     0.845336  -0.306883  -0.650722  \n",
      "kmean_2_1    -0.845336   0.306883   0.650722  \n",
      "kmean_3_0     0.924957  -0.280466  -0.594707  \n",
      "kmean_3_1    -0.735698  -0.288632   0.654281  \n",
      "kmean_3_2    -0.291603   0.889630  -0.096317  \n",
      "kmean_4_0    -0.401039  -0.157337  -0.333621  \n",
      "kmean_4_1     1.000000  -0.259419  -0.550078  \n",
      "kmean_4_2    -0.259419   1.000000  -0.215809  \n",
      "kmean_4_3    -0.550078  -0.215809   1.000000  \n",
      "meta size:  (4590, 19) (4590, 19)\n",
      "lgb tuner start tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected hyper-params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "==============================> cv score: -0.0686\n",
      "Selected hyper-params: {'min_split_gain': 0.0, 'num_leaves': 3}\n",
      "==============================> cv score: -0.0667\n",
      "Selected hyper-params: {'colsample_bytree': 1.0, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0666\n",
      "Selected hyper-params: {'colsample_bytree': 1.0, 'subsample': 0.8500000000000001}\n",
      "==============================> cv score: -0.0666\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0666\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0666\n",
      "xgb tuner start tuning\n",
      "Selected hyper-params: {'booster': 'dart'}\n",
      "==============================> cv score: -0.0657\n",
      "Selected hyper-params: {'learning_rate': 0.01, 'n_estimators': 800}\n",
      "==============================> cv score: -0.0654\n",
      "Selected hyper-params: {'max_depth': 1}\n",
      "==============================> cv score: -0.0652\n",
      "Selected hyper-params: {'gamma': 0, 'min_child_weight': 6}\n",
      "==============================> cv score: -0.0652\n",
      "Selected hyper-params: {'colsample_bytree': 1.0, 'subsample': 1.0}\n",
      "==============================> cv score: -0.0652\n",
      "Selected hyper-params: {'colsample_bytree': 0.9, 'subsample': 1.0}\n",
      "==============================> cv score: -0.0652\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0651\n",
      "Selected hyper-params: {'reg_alpha': 0.05, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle Competitions\\kaggle-Iceberg-Ship-Classifier-\\stacking_models_api.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  out_of_fold_predictions[self.target_col] = self.out_of_fold_predictions[self.target_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.0613208766451 \n",
      "\n",
      "Fold 2, meta model (lgb tuner) predictions\n",
      " [ 0.01482597  0.01290676  0.00377235 ...,  0.00402632  0.99385634\n",
      "  0.00377235]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle Competitions\\kaggle-Iceberg-Ship-Classifier-\\stacking_models_api.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  out_of_fold_predictions[self.target_col] = self.out_of_fold_predictions[self.target_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.0589263816295 \n",
      "\n",
      "Fold 2, meta model (xgb tuner) predictions\n",
      " [ 0.01470658  0.01535854  0.00220421 ...,  0.00236653  0.99574465\n",
      "  0.00220421]\n",
      "=================================================\n",
      "Processing fold  3\n",
      "=================================================\n",
      "gpu: 0  available: True\n",
      "epoch= 300 best_loss= 0.16262948016325632\n",
      "(4590, 2049) (8424, 2049)\n",
      "logistic regression tuner start tuning\n",
      "Selected hyper-params: {'solver': 'lbfgs'}\n",
      "==============================> cv score: -0.0393\n",
      "lgb tuner start tuning\n",
      "Selected hyper-params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "==============================> cv score: -0.0458\n",
      "Selected hyper-params: {'min_split_gain': 0.0, 'num_leaves': 3}\n",
      "==============================> cv score: -0.0452\n",
      "Selected hyper-params: {'colsample_bytree': 0.6, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0447\n",
      "Selected hyper-params: {'colsample_bytree': 0.44999999999999996, 'subsample': 0.8500000000000001}\n",
      "==============================> cv score: -0.0446\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0446\n",
      "Selected hyper-params: {'reg_alpha': 0.1, 'reg_lambda': 0.05}\n",
      "==============================> cv score: -0.0446\n",
      "Fold 3, lgb tuner predictions\n",
      " [ 0.00368071  0.05762772  0.00368071 ...,  0.00368071  0.99576115\n",
      "  0.01216079]\n",
      "\n",
      "*** Start to train meta model for stacking averaged model ***\n",
      "\n",
      "\n",
      "==================\n",
      " clf_1\n",
      "score= 0.0354535708978\n",
      "score= 0.0362958400873\n",
      "score= 0.0272480943282\n",
      "score= 0.0549727534727\n",
      "score= 0.0426072098853\n",
      "Avg score =  0.0393154937343\n",
      "\n",
      "==================\n",
      " clf_2\n",
      "score= 0.0430753877195\n",
      "score= 0.0411160640556\n",
      "score= 0.0325532868693\n",
      "score= 0.0557900402462\n",
      "score= 0.0502662699849\n",
      "Avg score =  0.0445602097751\n",
      "\n",
      "==================\n",
      " knn_8\n",
      "score= 0.168787456677\n",
      "score= 0.208489575641\n",
      "score= 0.0288483651857\n",
      "score= 0.316582938676\n",
      "score= 0.176508275924\n",
      "Avg score =  0.179843322421\n",
      "\n",
      "==================\n",
      " knn_16\n",
      "score= 0.133158282988\n",
      "score= 0.175962062717\n",
      "score= 0.0295471154993\n",
      "score= 0.283093423361\n",
      "score= 0.141737271778\n",
      "Avg score =  0.152699631269\n",
      "\n",
      "==================\n",
      " knn_32\n",
      "score= 0.134523401213\n",
      "score= 0.0727466790078\n",
      "score= 0.0287477571398\n",
      "score= 0.11209345968\n",
      "score= 0.107547813212\n",
      "Avg score =  0.0911318220505\n",
      "\n",
      "==================\n",
      " knn_64\n",
      "score= 0.0345899954445\n",
      "score= 0.0368036408241\n",
      "score= 0.0268073193032\n",
      "score= 0.114947972594\n",
      "score= 0.108033185738\n",
      "Avg score =  0.0642364227807\n",
      "\n",
      "==================\n",
      " kmean_2\n",
      "\n",
      "==================\n",
      " kmean_3\n",
      "\n",
      "==================\n",
      " kmean_4\n",
      "feature correlations\n",
      "                clf_1     clf_2  is_iceberg     knn_8  knn_8_dist    knn_16  \\\n",
      "clf_1        1.000000  0.998802    0.979471  0.997580   -0.217147  0.998603   \n",
      "clf_2        0.998802  1.000000    0.977738  0.996548   -0.208134  0.997513   \n",
      "is_iceberg   0.979471  0.977738    1.000000  0.977596   -0.224166  0.977989   \n",
      "knn_8        0.997580  0.996548    0.977596  1.000000   -0.223658  0.998679   \n",
      "knn_8_dist  -0.217147 -0.208134   -0.224166 -0.223658    1.000000 -0.224488   \n",
      "knn_16       0.998603  0.997513    0.977989  0.998679   -0.224488  1.000000   \n",
      "knn_16_dist -0.216774 -0.206032   -0.222747 -0.222949    0.980028 -0.224041   \n",
      "knn_32       0.999110  0.997806    0.978661  0.998075   -0.223337  0.999339   \n",
      "knn_32_dist -0.221747 -0.209443   -0.225851 -0.226992    0.900464 -0.228178   \n",
      "knn_64       0.999573  0.998520    0.979422  0.997968   -0.218424  0.999054   \n",
      "knn_64_dist -0.228315 -0.214348   -0.230523 -0.232591    0.757650 -0.233711   \n",
      "kmean_2_0    0.976751  0.977202    0.955622  0.973405   -0.159342  0.974200   \n",
      "kmean_2_1   -0.976751 -0.977202   -0.955622 -0.973405    0.159342 -0.974200   \n",
      "kmean_3_0   -0.463416 -0.462922   -0.453102 -0.461741    0.171110 -0.462440   \n",
      "kmean_3_1    0.992898  0.994315    0.972989  0.991461   -0.197826  0.992331   \n",
      "kmean_3_2   -0.635709 -0.637600   -0.623832 -0.635644    0.059582 -0.635952   \n",
      "kmean_4_0   -0.280115 -0.280142   -0.274234 -0.279500    0.198639 -0.280604   \n",
      "kmean_4_1    0.963993  0.963555    0.942306  0.960415   -0.261187  0.962456   \n",
      "kmean_4_2   -0.305411 -0.305005   -0.298603 -0.304296    0.293574 -0.304756   \n",
      "kmean_4_3   -0.595458 -0.595235   -0.581669 -0.592881   -0.080374 -0.593839   \n",
      "\n",
      "             knn_16_dist    knn_32  knn_32_dist    knn_64  knn_64_dist  \\\n",
      "clf_1          -0.216774  0.999110    -0.221747  0.999573    -0.228315   \n",
      "clf_2          -0.206032  0.997806    -0.209443  0.998520    -0.214348   \n",
      "is_iceberg     -0.222747  0.978661    -0.225851  0.979422    -0.230523   \n",
      "knn_8          -0.222949  0.998075    -0.226992  0.997968    -0.232591   \n",
      "knn_8_dist      0.980028 -0.223337     0.900464 -0.218424     0.757650   \n",
      "knn_16         -0.224041  0.999339    -0.228178  0.999054    -0.233711   \n",
      "knn_16_dist     1.000000 -0.222990     0.964188 -0.218043     0.855378   \n",
      "knn_32         -0.222990  1.000000    -0.227487  0.999614    -0.233334   \n",
      "knn_32_dist     0.964188 -0.227487     1.000000 -0.223027     0.957035   \n",
      "knn_64         -0.218043  0.999614    -0.223027  1.000000    -0.229701   \n",
      "knn_64_dist     0.855378 -0.233334     0.957035 -0.229701     1.000000   \n",
      "kmean_2_0      -0.151216  0.975001    -0.147910  0.976289    -0.148289   \n",
      "kmean_2_1       0.151216 -0.975001     0.147910 -0.976289     0.148289   \n",
      "kmean_3_0       0.174792 -0.462369     0.170943 -0.462997     0.145560   \n",
      "kmean_3_1      -0.196705  0.992869    -0.202941  0.993556    -0.211664   \n",
      "kmean_3_2       0.055285 -0.636571     0.065032 -0.636748     0.095697   \n",
      "kmean_4_0       0.217882 -0.281058     0.244520 -0.279737     0.280279   \n",
      "kmean_4_1      -0.263476  0.962725    -0.267806  0.962634    -0.268659   \n",
      "kmean_4_2       0.299085 -0.304710     0.285100 -0.305124     0.246136   \n",
      "kmean_4_3      -0.097613 -0.593779    -0.105946 -0.594509    -0.109090   \n",
      "\n",
      "             kmean_2_0  kmean_2_1  kmean_3_0  kmean_3_1  kmean_3_2  kmean_4_0  \\\n",
      "clf_1         0.976751  -0.976751  -0.463416   0.992898  -0.635709  -0.280115   \n",
      "clf_2         0.977202  -0.977202  -0.462922   0.994315  -0.637600  -0.280142   \n",
      "is_iceberg    0.955622  -0.955622  -0.453102   0.972989  -0.623832  -0.274234   \n",
      "knn_8         0.973405  -0.973405  -0.461741   0.991461  -0.635644  -0.279500   \n",
      "knn_8_dist   -0.159342   0.159342   0.171110  -0.197826   0.059582   0.198639   \n",
      "knn_16        0.974200  -0.974200  -0.462440   0.992331  -0.635952  -0.280604   \n",
      "knn_16_dist  -0.151216   0.151216   0.174792  -0.196705   0.055285   0.217882   \n",
      "knn_32        0.975001  -0.975001  -0.462369   0.992869  -0.636571  -0.281058   \n",
      "knn_32_dist  -0.147910   0.147910   0.170943  -0.202941   0.065032   0.244520   \n",
      "knn_64        0.976289  -0.976289  -0.462997   0.993556  -0.636748  -0.279737   \n",
      "knn_64_dist  -0.148289   0.148289   0.145560  -0.211664   0.095697   0.280279   \n",
      "kmean_2_0     1.000000  -1.000000  -0.469377   0.966611  -0.603357  -0.209733   \n",
      "kmean_2_1    -1.000000   1.000000   0.469377  -0.966611   0.603357   0.209733   \n",
      "kmean_3_0    -0.469377   0.469377   1.000000  -0.453705  -0.380669  -0.240867   \n",
      "kmean_3_1     0.966611  -0.966611  -0.453705   1.000000  -0.651347  -0.282815   \n",
      "kmean_3_2    -0.603357   0.603357  -0.380669  -0.651347   1.000000   0.498554   \n",
      "kmean_4_0    -0.209733   0.209733  -0.240867  -0.282815   0.498554   1.000000   \n",
      "kmean_4_1     0.919110  -0.919110  -0.431409   0.950858  -0.619339  -0.391885   \n",
      "kmean_4_2    -0.309328   0.309328   0.659018  -0.299000  -0.250868  -0.158736   \n",
      "kmean_4_3    -0.603550   0.603550   0.226508  -0.583398   0.412505  -0.309720   \n",
      "\n",
      "             kmean_4_1  kmean_4_2  kmean_4_3  \n",
      "clf_1         0.963993  -0.305411  -0.595458  \n",
      "clf_2         0.963555  -0.305005  -0.595235  \n",
      "is_iceberg    0.942306  -0.298603  -0.581669  \n",
      "knn_8         0.960415  -0.304296  -0.592881  \n",
      "knn_8_dist   -0.261187   0.293574  -0.080374  \n",
      "knn_16        0.962456  -0.304756  -0.593839  \n",
      "knn_16_dist  -0.263476   0.299085  -0.097613  \n",
      "knn_32        0.962725  -0.304710  -0.593779  \n",
      "knn_32_dist  -0.267806   0.285100  -0.105946  \n",
      "knn_64        0.962634  -0.305124  -0.594509  \n",
      "knn_64_dist  -0.268659   0.246136  -0.109090  \n",
      "kmean_2_0     0.919110  -0.309328  -0.603550  \n",
      "kmean_2_1    -0.919110   0.309328   0.603550  \n",
      "kmean_3_0    -0.431409   0.659018   0.226508  \n",
      "kmean_3_1     0.950858  -0.299000  -0.583398  \n",
      "kmean_3_2    -0.619339  -0.250868   0.412505  \n",
      "kmean_4_0    -0.391885  -0.158736  -0.309720  \n",
      "kmean_4_1     1.000000  -0.284306  -0.554728  \n",
      "kmean_4_2    -0.284306   1.000000  -0.224697  \n",
      "kmean_4_3    -0.554728  -0.224697   1.000000  \n",
      "meta size:  (4590, 19) (4590, 19)\n",
      "lgb tuner start tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected hyper-params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "==============================> cv score: -0.0448\n",
      "Selected hyper-params: {'min_split_gain': 0.0, 'num_leaves': 3}\n",
      "==============================> cv score: -0.0443\n",
      "Selected hyper-params: {'colsample_bytree': 0.6, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0438\n",
      "Selected hyper-params: {'colsample_bytree': 0.65, 'subsample': 0.75}\n",
      "==============================> cv score: -0.0436\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0436\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0436\n",
      "xgb tuner start tuning\n",
      "Selected hyper-params: {'booster': 'dart'}\n",
      "==============================> cv score: -0.0456\n",
      "Selected hyper-params: {'learning_rate': 0.01, 'n_estimators': 800}\n",
      "==============================> cv score: -0.0450\n",
      "Selected hyper-params: {'max_depth': 1}\n",
      "==============================> cv score: -0.0436\n",
      "Selected hyper-params: {'gamma': 0, 'min_child_weight': 1}\n",
      "==============================> cv score: -0.0436\n",
      "Selected hyper-params: {'colsample_bytree': 0.6, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0434\n",
      "Selected hyper-params: {'colsample_bytree': 0.7, 'subsample': 0.9}\n",
      "==============================> cv score: -0.0433\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.2}\n",
      "==============================> cv score: -0.0432\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.15000000000000002}\n",
      "==============================> cv score: -0.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle Competitions\\kaggle-Iceberg-Ship-Classifier-\\stacking_models_api.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  out_of_fold_predictions[self.target_col] = self.out_of_fold_predictions[self.target_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.0379837196419 \n",
      "\n",
      "Fold 3, meta model (lgb tuner) predictions\n",
      " [ 0.00316157  0.08958538  0.00360967 ...,  0.00316157  0.99649392\n",
      "  0.00422459]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle Competitions\\kaggle-Iceberg-Ship-Classifier-\\stacking_models_api.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  out_of_fold_predictions[self.target_col] = self.out_of_fold_predictions[self.target_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.0362292681531 \n",
      "\n",
      "Fold 3, meta model (xgb tuner) predictions\n",
      " [ 0.0018739   0.06316341  0.00189205 ...,  0.0018739   0.99786359\n",
      "  0.00190981]\n",
      "=================================================\n",
      "Processing fold  4\n",
      "=================================================\n",
      "gpu: 0  available: True\n",
      "epoch= 259 best_loss= 0.17009364068508148\n",
      "(4590, 2049) (8424, 2049)\n",
      "logistic regression tuner start tuning\n",
      "Selected hyper-params: {'solver': 'sag'}\n",
      "==============================> cv score: -0.0398\n",
      "lgb tuner start tuning\n",
      "Selected hyper-params: {'learning_rate': 0.1, 'n_estimators': 400}\n",
      "==============================> cv score: -0.0450\n",
      "Selected hyper-params: {'min_split_gain': 0.0, 'num_leaves': 3}\n",
      "==============================> cv score: -0.0431\n",
      "Selected hyper-params: {'colsample_bytree': 1.0, 'subsample': 1.0}\n",
      "==============================> cv score: -0.0431\n",
      "Selected hyper-params: {'colsample_bytree': 0.95, 'subsample': 0.95}\n",
      "==============================> cv score: -0.0430\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.2}\n",
      "==============================> cv score: -0.0430\n",
      "Selected hyper-params: {'reg_alpha': 0.15, 'reg_lambda': 0.30000000000000004}\n",
      "==============================> cv score: -0.0429\n",
      "Fold 4, lgb tuner predictions\n",
      " [ 0.01330292  0.11762051  0.00142958 ...,  0.0014951   0.9984987\n",
      "  0.00303092]\n",
      "\n",
      "*** Start to train meta model for stacking averaged model ***\n",
      "\n",
      "\n",
      "==================\n",
      " clf_1\n",
      "score= 0.0356096436326\n",
      "score= 0.0336882923921\n",
      "score= 0.0321963256291\n",
      "score= 0.0530444503534\n",
      "score= 0.0443733361549\n",
      "Avg score =  0.0397824096324\n",
      "\n",
      "==================\n",
      " clf_2\n",
      "score= 0.0398586823473\n",
      "score= 0.0346131105254\n",
      "score= 0.0352783404689\n",
      "score= 0.0561577730753\n",
      "score= 0.0487226139418\n",
      "Avg score =  0.0429261040718\n",
      "\n",
      "==================\n",
      " knn_8\n",
      "score= 0.0647319852754\n",
      "score= 0.172638377542\n",
      "score= 0.0622114274903\n",
      "score= 0.214185553762\n",
      "score= 0.173051839754\n",
      "Avg score =  0.137363836765\n",
      "\n",
      "==================\n",
      " knn_16\n",
      "score= 0.063381407935\n",
      "score= 0.0683625642151\n",
      "score= 0.0638357693084\n",
      "score= 0.214183862198\n",
      "score= 0.176905171129\n",
      "Avg score =  0.117333754957\n",
      "\n",
      "==================\n",
      " knn_32\n",
      "score= 0.0655718279711\n",
      "score= 0.0698699154931\n",
      "score= 0.0635766271427\n",
      "score= 0.215008317529\n",
      "score= 0.109667014801\n",
      "Avg score =  0.104738740587\n",
      "\n",
      "==================\n",
      " knn_64\n",
      "score= 0.0338845641689\n",
      "score= 0.0679699033371\n",
      "score= 0.0646975426897\n",
      "score= 0.178944370319\n",
      "score= 0.0754341769413\n",
      "Avg score =  0.0841861114912\n",
      "\n",
      "==================\n",
      " kmean_2\n",
      "\n",
      "==================\n",
      " kmean_3\n",
      "\n",
      "==================\n",
      " kmean_4\n",
      "feature correlations\n",
      "                clf_1     clf_2  is_iceberg     knn_8  knn_8_dist    knn_16  \\\n",
      "clf_1        1.000000  0.998154    0.979070  0.997402   -0.160475  0.998584   \n",
      "clf_2        0.998154  1.000000    0.977466  0.995946   -0.154596  0.996760   \n",
      "is_iceberg   0.979070  0.977466    1.000000  0.977668   -0.156066  0.978434   \n",
      "knn_8        0.997402  0.995946    0.977668  1.000000   -0.159869  0.998560   \n",
      "knn_8_dist  -0.160475 -0.154596   -0.156066 -0.159869    1.000000 -0.161200   \n",
      "knn_16       0.998584  0.996760    0.978434  0.998560   -0.161200  1.000000   \n",
      "knn_16_dist -0.166266 -0.155989   -0.162544 -0.166290    0.973549 -0.167707   \n",
      "knn_32       0.999156  0.997119    0.978542  0.998003   -0.161190  0.999352   \n",
      "knn_32_dist -0.175802 -0.161825   -0.172956 -0.176707    0.893390 -0.177989   \n",
      "knn_64       0.999441  0.997350    0.978871  0.997558   -0.160738  0.998938   \n",
      "knn_64_dist -0.192573 -0.176748   -0.189751 -0.193939    0.776957 -0.195151   \n",
      "kmean_2_0    0.985463  0.988007    0.966717  0.983687   -0.103290  0.985155   \n",
      "kmean_2_1   -0.985463 -0.988007   -0.966717 -0.983687    0.103290 -0.985155   \n",
      "kmean_3_0   -0.768525 -0.769035   -0.751521 -0.767177   -0.032936 -0.767778   \n",
      "kmean_3_1    0.991944  0.991797    0.969917  0.989304   -0.141596  0.990442   \n",
      "kmean_3_2   -0.337596 -0.336606   -0.330006 -0.335646    0.263413 -0.336455   \n",
      "kmean_4_0    0.952084  0.949717    0.931331  0.947565   -0.242978  0.950043   \n",
      "kmean_4_1   -0.639372 -0.638123   -0.624624 -0.635300   -0.142012 -0.636653   \n",
      "kmean_4_2   -0.224388 -0.223504   -0.220672 -0.224858    0.281866 -0.225880   \n",
      "kmean_4_3   -0.284178 -0.283336   -0.277788 -0.282535    0.281915 -0.283216   \n",
      "\n",
      "             knn_16_dist    knn_32  knn_32_dist    knn_64  knn_64_dist  \\\n",
      "clf_1          -0.166266  0.999156    -0.175802  0.999441    -0.192573   \n",
      "clf_2          -0.155989  0.997119    -0.161825  0.997350    -0.176748   \n",
      "is_iceberg     -0.162544  0.978542    -0.172956  0.978871    -0.189751   \n",
      "knn_8          -0.166290  0.998003    -0.176707  0.997558    -0.193939   \n",
      "knn_8_dist      0.973549 -0.161190     0.893390 -0.160738     0.776957   \n",
      "knn_16         -0.167707  0.999352    -0.177989  0.998938    -0.195151   \n",
      "knn_16_dist     1.000000 -0.168222     0.967359 -0.167958     0.883451   \n",
      "knn_32         -0.168222  1.000000    -0.178751  0.999613    -0.196103   \n",
      "knn_32_dist     0.967359 -0.178751     1.000000 -0.178584     0.969151   \n",
      "knn_64         -0.167958  0.999613    -0.178584  1.000000    -0.196047   \n",
      "knn_64_dist     0.883451 -0.196103     0.969151 -0.196047     1.000000   \n",
      "kmean_2_0      -0.099465  0.985548    -0.103777  0.985855    -0.121623   \n",
      "kmean_2_1       0.099465 -0.985548     0.103777 -0.985855     0.121623   \n",
      "kmean_3_0      -0.052470 -0.767817    -0.050229 -0.768010    -0.027512   \n",
      "kmean_3_1      -0.141265  0.990629    -0.147364  0.990981    -0.163755   \n",
      "kmean_3_2       0.292387 -0.336679     0.298212 -0.336919     0.288675   \n",
      "kmean_4_0      -0.255486  0.951792    -0.261604  0.952351    -0.267614   \n",
      "kmean_4_1      -0.166440 -0.637313    -0.176825 -0.637619    -0.178998   \n",
      "kmean_4_2       0.303772 -0.227198     0.318396 -0.227389     0.336103   \n",
      "kmean_4_3       0.314948 -0.283405     0.323442 -0.283607     0.314223   \n",
      "\n",
      "             kmean_2_0  kmean_2_1  kmean_3_0  kmean_3_1  kmean_3_2  kmean_4_0  \\\n",
      "clf_1         0.985463  -0.985463  -0.768525   0.991944  -0.337596   0.952084   \n",
      "clf_2         0.988007  -0.988007  -0.769035   0.991797  -0.336606   0.949717   \n",
      "is_iceberg    0.966717  -0.966717  -0.751521   0.969917  -0.330006   0.931331   \n",
      "knn_8         0.983687  -0.983687  -0.767177   0.989304  -0.335646   0.947565   \n",
      "knn_8_dist   -0.103290   0.103290  -0.032936  -0.141596   0.263413  -0.242978   \n",
      "knn_16        0.985155  -0.985155  -0.767778   0.990442  -0.336455   0.950043   \n",
      "knn_16_dist  -0.099465   0.099465  -0.052470  -0.141265   0.292387  -0.255486   \n",
      "knn_32        0.985548  -0.985548  -0.767817   0.990629  -0.336679   0.951792   \n",
      "knn_32_dist  -0.103777   0.103777  -0.050229  -0.147364   0.298212  -0.261604   \n",
      "knn_64        0.985855  -0.985855  -0.768010   0.990981  -0.336919   0.952351   \n",
      "knn_64_dist  -0.121623   0.121623  -0.027512  -0.163755   0.288675  -0.267614   \n",
      "kmean_2_0     1.000000  -1.000000  -0.757963   0.981633  -0.337970   0.916372   \n",
      "kmean_2_1    -1.000000   1.000000   0.757963  -0.981633   0.337970  -0.916372   \n",
      "kmean_3_0    -0.757963   0.757963   1.000000  -0.780450  -0.330884  -0.728563   \n",
      "kmean_3_1     0.981633  -0.981633  -0.780450   1.000000  -0.331763   0.933518   \n",
      "kmean_3_2    -0.337970   0.337970  -0.330884  -0.331763   1.000000  -0.309707   \n",
      "kmean_4_0     0.916372  -0.916372  -0.728563   0.933518  -0.309707   1.000000   \n",
      "kmean_4_1    -0.640652   0.640652   0.666310  -0.628885  -0.056157  -0.587076   \n",
      "kmean_4_2    -0.175653   0.175653   0.328866  -0.217026  -0.168644  -0.371332   \n",
      "kmean_4_3    -0.284492   0.284492  -0.278526  -0.279267   0.841766  -0.260700   \n",
      "\n",
      "             kmean_4_1  kmean_4_2  kmean_4_3  \n",
      "clf_1        -0.639372  -0.224388  -0.284178  \n",
      "clf_2        -0.638123  -0.223504  -0.283336  \n",
      "is_iceberg   -0.624624  -0.220672  -0.277788  \n",
      "knn_8        -0.635300  -0.224858  -0.282535  \n",
      "knn_8_dist   -0.142012   0.281866   0.281915  \n",
      "knn_16       -0.636653  -0.225880  -0.283216  \n",
      "knn_16_dist  -0.166440   0.303772   0.314948  \n",
      "knn_32       -0.637313  -0.227198  -0.283405  \n",
      "knn_32_dist  -0.176825   0.318396   0.323442  \n",
      "knn_64       -0.637619  -0.227389  -0.283607  \n",
      "knn_64_dist  -0.178998   0.336103   0.314223  \n",
      "kmean_2_0    -0.640652  -0.175653  -0.284492  \n",
      "kmean_2_1     0.640652   0.175653   0.284492  \n",
      "kmean_3_0     0.666310   0.328866  -0.278526  \n",
      "kmean_3_1    -0.628885  -0.217026  -0.279267  \n",
      "kmean_3_2    -0.056157  -0.168644   0.841766  \n",
      "kmean_4_0    -0.587076  -0.371332  -0.260700  \n",
      "kmean_4_1     1.000000  -0.319678  -0.224436  \n",
      "kmean_4_2    -0.319678   1.000000  -0.141958  \n",
      "kmean_4_3    -0.224436  -0.141958   1.000000  \n",
      "meta size:  (4590, 19) (4590, 19)\n",
      "lgb tuner start tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected hyper-params: {'learning_rate': 0.1, 'n_estimators': 200}\n",
      "==============================> cv score: -0.0465\n",
      "Selected hyper-params: {'min_split_gain': 0.0, 'num_leaves': 3}\n",
      "==============================> cv score: -0.0443\n",
      "Selected hyper-params: {'colsample_bytree': 0.4, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0437\n",
      "Selected hyper-params: {'colsample_bytree': 0.30000000000000004, 'subsample': 0.8500000000000001}\n",
      "==============================> cv score: -0.0432\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0432\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0432\n",
      "xgb tuner start tuning\n",
      "Selected hyper-params: {'booster': 'dart'}\n",
      "==============================> cv score: -0.0458\n",
      "Selected hyper-params: {'learning_rate': 0.01, 'n_estimators': 800}\n",
      "==============================> cv score: -0.0446\n",
      "Selected hyper-params: {'max_depth': 1}\n",
      "==============================> cv score: -0.0435\n",
      "Selected hyper-params: {'gamma': 0, 'min_child_weight': 6}\n",
      "==============================> cv score: -0.0433\n",
      "Selected hyper-params: {'colsample_bytree': 0.8, 'subsample': 1.0}\n",
      "==============================> cv score: -0.0433\n",
      "Selected hyper-params: {'colsample_bytree': 0.8, 'subsample': 1.0}\n",
      "==============================> cv score: -0.0433\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.2}\n",
      "==============================> cv score: -0.0432\n",
      "Selected hyper-params: {'reg_alpha': 0.1, 'reg_lambda': 0.15000000000000002}\n",
      "==============================> cv score: -0.0432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle Competitions\\kaggle-Iceberg-Ship-Classifier-\\stacking_models_api.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  out_of_fold_predictions[self.target_col] = self.out_of_fold_predictions[self.target_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.0387350992077 \n",
      "\n",
      "Fold 4, meta model (lgb tuner) predictions\n",
      " [ 0.00685648  0.17429484  0.00516023 ...,  0.00398264  0.99604993\n",
      "  0.00508245]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle Competitions\\kaggle-Iceberg-Ship-Classifier-\\stacking_models_api.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  out_of_fold_predictions[self.target_col] = self.out_of_fold_predictions[self.target_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.0363099994122 \n",
      "\n",
      "Fold 4, meta model (xgb tuner) predictions\n",
      " [ 0.00265923  0.09102806  0.00196323 ...,  0.00196323  0.99769646\n",
      "  0.00196323]\n",
      "=================================================\n",
      "Processing fold  5\n",
      "=================================================\n",
      "gpu: 0  available: True\n",
      "epoch= 281 best_loss= 0.19984116653601328\n",
      "(4590, 2049) (8424, 2049)\n",
      "logistic regression tuner start tuning\n",
      "Selected hyper-params: {'solver': 'sag'}\n",
      "==============================> cv score: -0.0351\n",
      "lgb tuner start tuning\n",
      "Selected hyper-params: {'learning_rate': 0.05, 'n_estimators': 800}\n",
      "==============================> cv score: -0.0374\n",
      "Selected hyper-params: {'min_split_gain': 0.0, 'num_leaves': 3}\n",
      "==============================> cv score: -0.0370\n",
      "Selected hyper-params: {'colsample_bytree': 1.0, 'subsample': 1.0}\n",
      "==============================> cv score: -0.0370\n",
      "Selected hyper-params: {'colsample_bytree': 1.0, 'subsample': 1.0}\n",
      "==============================> cv score: -0.0370\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.4}\n",
      "==============================> cv score: -0.0369\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.4}\n",
      "==============================> cv score: -0.0369\n",
      "Fold 5, lgb tuner predictions\n",
      " [  6.33709981e-04   1.21753052e-01   1.86734338e-03 ...,   1.86734338e-03\n",
      "   9.98037538e-01   7.35076134e-03]\n",
      "\n",
      "*** Start to train meta model for stacking averaged model ***\n",
      "\n",
      "\n",
      "==================\n",
      " clf_1\n",
      "score= 0.0314150246067\n",
      "score= 0.0219425545014\n",
      "score= 0.0308872443784\n",
      "score= 0.0454598505286\n",
      "score= 0.0458737732334\n",
      "Avg score =  0.0351156894497\n",
      "\n",
      "==================\n",
      " clf_2\n",
      "score= 0.0292142151033\n",
      "score= 0.024513849873\n",
      "score= 0.0312222122729\n",
      "score= 0.0482703096914\n",
      "score= 0.051461656624\n",
      "Avg score =  0.0369364487129\n",
      "\n",
      "==================\n",
      " knn_8\n",
      "score= 0.0590691607018\n",
      "score= 0.126057754916\n",
      "score= 0.132409429776\n",
      "score= 0.239674982273\n",
      "score= 0.27912356017\n",
      "Avg score =  0.167266977568\n",
      "\n",
      "==================\n",
      " knn_16\n",
      "score= 0.027372061631\n",
      "score= 0.0545253217115\n",
      "score= 0.095664031669\n",
      "score= 0.205423580932\n",
      "score= 0.244502005832\n",
      "Avg score =  0.125497400355\n",
      "\n",
      "==================\n",
      " knn_32\n",
      "score= 0.0284518262072\n",
      "score= 0.0546223518772\n",
      "score= 0.0601077064202\n",
      "score= 0.136735874282\n",
      "score= 0.175454833751\n",
      "Avg score =  0.0910745185077\n",
      "\n",
      "==================\n",
      " knn_64\n",
      "score= 0.0308175048512\n",
      "score= 0.022148295528\n",
      "score= 0.0609691183428\n",
      "score= 0.104278288915\n",
      "score= 0.0763738231291\n",
      "Avg score =  0.0589174061532\n",
      "\n",
      "==================\n",
      " kmean_2\n",
      "\n",
      "==================\n",
      " kmean_3\n",
      "\n",
      "==================\n",
      " kmean_4\n",
      "feature correlations\n",
      "                clf_1     clf_2  is_iceberg     knn_8  knn_8_dist    knn_16  \\\n",
      "clf_1        1.000000  0.998503    0.982300  0.997905   -0.266399  0.998876   \n",
      "clf_2        0.998503  1.000000    0.981922  0.996930   -0.261199  0.997673   \n",
      "is_iceberg   0.982300  0.981922    1.000000  0.980897   -0.262679  0.981689   \n",
      "knn_8        0.997905  0.996930    0.980897  1.000000   -0.268632  0.999022   \n",
      "knn_8_dist  -0.266399 -0.261199   -0.262679 -0.268632    1.000000 -0.265869   \n",
      "knn_16       0.998876  0.997673    0.981689  0.999022   -0.265869  1.000000   \n",
      "knn_16_dist -0.266337 -0.259347   -0.264165 -0.270021    0.977912 -0.267634   \n",
      "knn_32       0.999358  0.997686    0.982201  0.998532   -0.265784  0.999522   \n",
      "knn_32_dist -0.264356 -0.256244   -0.263603 -0.268689    0.917241 -0.266791   \n",
      "knn_64       0.999673  0.997962    0.982198  0.998149   -0.264152  0.999149   \n",
      "knn_64_dist -0.260184 -0.251045   -0.260103 -0.264800    0.809112 -0.263350   \n",
      "kmean_2_0    0.985823  0.987300    0.970227  0.984537   -0.214575  0.985297   \n",
      "kmean_2_1   -0.985823 -0.987300   -0.970227 -0.984537    0.214575 -0.985297   \n",
      "kmean_3_0    0.994178  0.992459    0.975209  0.990459   -0.261063  0.992100   \n",
      "kmean_3_1   -0.686780 -0.686523   -0.673906 -0.685427    0.004911 -0.686169   \n",
      "kmean_3_2   -0.416478 -0.414570   -0.408239 -0.413370    0.332983 -0.414556   \n",
      "kmean_4_0    0.946574  0.945464    0.927042  0.942188   -0.320676  0.942533   \n",
      "kmean_4_1   -0.306423 -0.304960   -0.300356 -0.304131    0.404163 -0.305004   \n",
      "kmean_4_2   -0.637921 -0.635411   -0.624930 -0.633373   -0.113508 -0.635190   \n",
      "kmean_4_3   -0.191383 -0.194382   -0.186994 -0.193303    0.240836 -0.190668   \n",
      "\n",
      "             knn_16_dist    knn_32  knn_32_dist    knn_64  knn_64_dist  \\\n",
      "clf_1          -0.266337  0.999358    -0.264356  0.999673    -0.260184   \n",
      "clf_2          -0.259347  0.997686    -0.256244  0.997962    -0.251045   \n",
      "is_iceberg     -0.264165  0.982201    -0.263603  0.982198    -0.260103   \n",
      "knn_8          -0.270021  0.998532    -0.268689  0.998149    -0.264800   \n",
      "knn_8_dist      0.977912 -0.265784     0.917241 -0.264152     0.809112   \n",
      "knn_16         -0.267634  0.999522    -0.266791  0.999149    -0.263350   \n",
      "knn_16_dist     1.000000 -0.267265     0.976933 -0.264601     0.899090   \n",
      "knn_32         -0.267265  1.000000    -0.266263  0.999696    -0.262756   \n",
      "knn_32_dist     0.976933 -0.266263     1.000000 -0.263158     0.968670   \n",
      "knn_64         -0.264601  0.999696    -0.263158  1.000000    -0.259623   \n",
      "knn_64_dist     0.899090 -0.262756     0.968670 -0.259623     1.000000   \n",
      "kmean_2_0      -0.207490  0.985788    -0.201440  0.986393    -0.195722   \n",
      "kmean_2_1       0.207490 -0.985788     0.201440 -0.986393     0.195722   \n",
      "kmean_3_0      -0.255982  0.993007    -0.251692  0.994419    -0.246646   \n",
      "kmean_3_1       0.002354 -0.686601     0.013875 -0.687513     0.043277   \n",
      "kmean_3_2       0.329640 -0.415184     0.309379 -0.415856     0.265344   \n",
      "kmean_4_0      -0.322785  0.942641    -0.318882  0.942793    -0.308600   \n",
      "kmean_4_1       0.398493 -0.305466     0.376313 -0.305960     0.329541   \n",
      "kmean_4_2      -0.123936 -0.636123    -0.130573 -0.636592    -0.127654   \n",
      "kmean_4_3       0.262038 -0.189211     0.284089 -0.188390     0.305794   \n",
      "\n",
      "             kmean_2_0  kmean_2_1  kmean_3_0  kmean_3_1  kmean_3_2  kmean_4_0  \\\n",
      "clf_1         0.985823  -0.985823   0.994178  -0.686780  -0.416478   0.946574   \n",
      "clf_2         0.987300  -0.987300   0.992459  -0.686523  -0.414570   0.945464   \n",
      "is_iceberg    0.970227  -0.970227   0.975209  -0.673906  -0.408239   0.927042   \n",
      "knn_8         0.984537  -0.984537   0.990459  -0.685427  -0.413370   0.942188   \n",
      "knn_8_dist   -0.214575   0.214575  -0.261063   0.004911   0.332983  -0.320676   \n",
      "knn_16        0.985297  -0.985297   0.992100  -0.686169  -0.414556   0.942533   \n",
      "knn_16_dist  -0.207490   0.207490  -0.255982   0.002354   0.329640  -0.322785   \n",
      "knn_32        0.985788  -0.985788   0.993007  -0.686601  -0.415184   0.942641   \n",
      "knn_32_dist  -0.201440   0.201440  -0.251692   0.013875   0.309379  -0.318882   \n",
      "knn_64        0.986393  -0.986393   0.994419  -0.687513  -0.415856   0.942793   \n",
      "knn_64_dist  -0.195722   0.195722  -0.246646   0.043277   0.265344  -0.308600   \n",
      "kmean_2_0     1.000000  -1.000000   0.979894  -0.671241  -0.417723   0.913868   \n",
      "kmean_2_1    -1.000000   1.000000  -0.979894   0.671241   0.417723  -0.913868   \n",
      "kmean_3_0     0.979894  -0.979894   1.000000  -0.698327  -0.409325   0.932619   \n",
      "kmean_3_1    -0.671241   0.671241  -0.698327   1.000000  -0.367227  -0.651273   \n",
      "kmean_3_2    -0.417723   0.417723  -0.409325  -0.367227   1.000000  -0.381744   \n",
      "kmean_4_0     0.913868  -0.913868   0.932619  -0.651273  -0.381744   1.000000   \n",
      "kmean_4_1    -0.307334   0.307334  -0.301155  -0.270182   0.735736  -0.280863   \n",
      "kmean_4_2    -0.640400   0.640400  -0.627524   0.582027   0.073550  -0.585241   \n",
      "kmean_4_3    -0.143162   0.143162  -0.190485   0.350665  -0.199457  -0.353734   \n",
      "\n",
      "             kmean_4_1  kmean_4_2  kmean_4_3  \n",
      "clf_1        -0.306423  -0.637921  -0.191383  \n",
      "clf_2        -0.304960  -0.635411  -0.194382  \n",
      "is_iceberg   -0.300356  -0.624930  -0.186994  \n",
      "knn_8        -0.304131  -0.633373  -0.193303  \n",
      "knn_8_dist    0.404163  -0.113508   0.240836  \n",
      "knn_16       -0.305004  -0.635190  -0.190668  \n",
      "knn_16_dist   0.398493  -0.123936   0.262038  \n",
      "knn_32       -0.305466  -0.636123  -0.189211  \n",
      "knn_32_dist   0.376313  -0.130573   0.284089  \n",
      "knn_64       -0.305960  -0.636592  -0.188390  \n",
      "knn_64_dist   0.329541  -0.127654   0.305794  \n",
      "kmean_2_0    -0.307334  -0.640400  -0.143162  \n",
      "kmean_2_1     0.307334   0.640400   0.143162  \n",
      "kmean_3_0    -0.301155  -0.627524  -0.190485  \n",
      "kmean_3_1    -0.270182   0.582027   0.350665  \n",
      "kmean_3_2     0.735736   0.073550  -0.199457  \n",
      "kmean_4_0    -0.280863  -0.585241  -0.353734  \n",
      "kmean_4_1     1.000000  -0.242789  -0.146748  \n",
      "kmean_4_2    -0.242789   1.000000  -0.305782  \n",
      "kmean_4_3    -0.146748  -0.305782   1.000000  \n",
      "meta size:  (4590, 19) (4590, 19)\n",
      "lgb tuner start tuning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected hyper-params: {'learning_rate': 0.1, 'n_estimators': 400}\n",
      "==============================> cv score: -0.0406\n",
      "Selected hyper-params: {'min_split_gain': 0.0, 'num_leaves': 2}\n",
      "==============================> cv score: -0.0383\n",
      "Selected hyper-params: {'colsample_bytree': 0.4, 'subsample': 1.0}\n",
      "==============================> cv score: -0.0379\n",
      "Selected hyper-params: {'colsample_bytree': 0.30000000000000004, 'subsample': 0.95}\n",
      "==============================> cv score: -0.0375\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0375\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0375\n",
      "xgb tuner start tuning\n",
      "Selected hyper-params: {'booster': 'dart'}\n",
      "==============================> cv score: -0.0406\n",
      "Selected hyper-params: {'learning_rate': 0.01, 'n_estimators': 800}\n",
      "==============================> cv score: -0.0398\n",
      "Selected hyper-params: {'max_depth': 1}\n",
      "==============================> cv score: -0.0381\n",
      "Selected hyper-params: {'gamma': 0, 'min_child_weight': 2}\n",
      "==============================> cv score: -0.0381\n",
      "Selected hyper-params: {'colsample_bytree': 0.4, 'subsample': 0.8}\n",
      "==============================> cv score: -0.0380\n",
      "Selected hyper-params: {'colsample_bytree': 0.55, 'subsample': 0.9500000000000001}\n",
      "==============================> cv score: -0.0379\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0378\n",
      "Selected hyper-params: {'reg_alpha': 0.0, 'reg_lambda': 0.0}\n",
      "==============================> cv score: -0.0378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle Competitions\\kaggle-Iceberg-Ship-Classifier-\\stacking_models_api.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  out_of_fold_predictions[self.target_col] = self.out_of_fold_predictions[self.target_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.0324641439372 \n",
      "\n",
      "Fold 5, meta model (lgb tuner) predictions\n",
      " [ 0.00231271  0.19204495  0.00212978 ...,  0.00231271  0.99691895\n",
      "  0.00196867]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Kaggle Competitions\\kaggle-Iceberg-Ship-Classifier-\\stacking_models_api.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  out_of_fold_predictions[self.target_col] = self.out_of_fold_predictions[self.target_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta model's training set score=  0.0314214897927 \n",
      "\n",
      "Fold 5, meta model (xgb tuner) predictions\n",
      " [ 0.00170587  0.13889556  0.00162751 ...,  0.00170587  0.99758363\n",
      "  0.00182244]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "train_df = pd.read_json('Data/no_denoise_processed_train.json')\n",
    "test_df = pd.read_json('Data/test.json')\n",
    "print(\"Test data shape: {}\".format(test_df.shape))\n",
    "test_ids = test_df['id']\n",
    "del test_df\n",
    "test_df = pd.read_json('Data/no_denoise_processed_test.json')\n",
    "\n",
    "train_df.sort_index(inplace=True)\n",
    "\n",
    "# pl part\n",
    "pl_train_df = pd.read_json('Data/public_lb_1229_cpl_test.json')\n",
    "pl_train_df.sort_index(inplace=True)\n",
    "pl_train_df.is_iceberg = [1.0 if v >= 0.5 else 0. for v in pl_train_df.is_iceberg.values]\n",
    "new_train = pd.concat([train_df, pl_train_df]).reset_index(drop=True)\n",
    "\n",
    "del train_df, pl_train_df\n",
    "train_df = new_train\n",
    "#\n",
    "\n",
    "test_df.sort_index(inplace=True)\n",
    "\n",
    "features = train_df.columns.tolist()\n",
    "features.remove('is_iceberg')\n",
    "\n",
    "train_y = train_df['is_iceberg'].values\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    fold = i + 1\n",
    "    \n",
    "    print(\"=================================================\")\n",
    "    print(\"Processing fold \", fold)\n",
    "    print(\"=================================================\")\n",
    "    \n",
    "    train_X, test_X = get_features(fold, train_df, test_df)\n",
    "    print(train_X.shape, test_X.shape)\n",
    "    \n",
    "    tuners = [lr_tuner(train_X, train_y),\n",
    "              #mlp_tuner(train_X, train_y),\n",
    "              #adb_tuner(train_X, train_y),\n",
    "              #bg_tuner(train_X, train_y),\n",
    "              #gb_tuner(train_X, train_y),\n",
    "              #rf_tuner(train_X, train_y),\n",
    "              #et_tuner(train_X, train_y),\n",
    "              lgbm_tuner(train_X, train_y), \n",
    "              #xgb_tuner(train_X, train_y)\n",
    "             ]\n",
    "    clfs = []\n",
    "    \n",
    "    for tuner in tuners:\n",
    "        tuner.tune()\n",
    "        clfs.append(tuner.get_clf())\n",
    "    \n",
    "    for i, clf in enumerate(clfs):\n",
    "        if isinstance(tuners[i], lgbm_tuner) or isinstance(tuners[i], xgb_tuner):\n",
    "            if isinstance(tuners[i], lgbm_tuner):\n",
    "                name = 'lgb'\n",
    "            else:\n",
    "                name = 'xgb'\n",
    "            \n",
    "            clf.fit(train_X, train_y)\n",
    "            predictions = clf.predict_proba(test_X)[:,1]\n",
    "            print(\"Fold {}, {} tuner predictions\\n\".format(fold, name), predictions)\n",
    "        \n",
    "            submission = pd.DataFrame()\n",
    "            submission['id'] = test_ids\n",
    "            submission['is_iceberg'] = predictions\n",
    "            submission.to_csv('Submissions/submission_{}_0117_auto_fine_tune_fold_{}.csv'.format(name, fold), \n",
    "                              float_format=\"%.15f\", index=False)\n",
    "     \n",
    "    \n",
    "    print(\"\\n*** Start to train meta model for stacking averaged model ***\\n\")\n",
    "    \n",
    "    sl_base_models_dict = {}\n",
    "    for i, clf in enumerate(clfs):\n",
    "        sl_base_models_dict['clf_'+str(i+1)] = clf\n",
    "        \n",
    "    semi_sl_base_models_dict = {\n",
    "        'knn_8': KNeighborsClassifier(n_neighbors=8),\n",
    "        'knn_16': KNeighborsClassifier(n_neighbors=16),\n",
    "        'knn_32': KNeighborsClassifier(n_neighbors=32),\n",
    "        'knn_64': KNeighborsClassifier(n_neighbors=64)\n",
    "    }\n",
    "\n",
    "    usl_base_models_dict = {\n",
    "        'kmean_2': KMeans(n_clusters=2),\n",
    "        'kmean_3': KMeans(n_clusters=3),\n",
    "        'kmean_4': KMeans(n_clusters=4)\n",
    "    }\n",
    "    \n",
    "    sam = StackingAveragedModels(sl_base_models_dict=sl_base_models_dict, \n",
    "                             semi_sl_base_models_dict=semi_sl_base_models_dict,\n",
    "                             usl_base_models_dict=usl_base_models_dict,\n",
    "                             meta_model=LogisticRegression(),\n",
    "                             target_col='is_iceberg',\n",
    "                             eval_func=log_loss,\n",
    "                             is_classification=True,\n",
    "                             random_state=999)\n",
    "    \n",
    "    sam.fit(train_X, train_y)\n",
    "    \n",
    "    # get meta dataframe to train\n",
    "    meta_df = sam.get_meta_train_dataframe(get_dummies=True, pca_enabled=False)\n",
    "    # shuffle meta data frame\n",
    "    meta_df = meta_df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "    print('feature correlations')\n",
    "    print(meta_df.corr())\n",
    "    \n",
    "    features = meta_df.columns.tolist()\n",
    "    features.remove('is_iceberg')\n",
    "    meta_X = meta_df[features]\n",
    "    meta_y = np.array(meta_df['is_iceberg']).reshape((meta_df.shape[0],))\n",
    "    print(\"meta size: \", meta_X.shape, meta_X.shape)\n",
    "    \n",
    "    # fine tune for meta model\n",
    "    meta_tuners = [lgbm_tuner(meta_X, meta_y), xgb_tuner(meta_X, meta_y)]\n",
    "    meta_clfs = [] \n",
    "    for tuner in meta_tuners:\n",
    "        tuner.tune()\n",
    "        meta_clfs.append(tuner.get_clf())\n",
    "        \n",
    "    for i, clf in enumerate(meta_clfs):\n",
    "        if isinstance(meta_tuners[i], lgbm_tuner) or isinstance(meta_tuners[i], xgb_tuner):\n",
    "            if isinstance(meta_tuners[i], lgbm_tuner):\n",
    "                name = 'lgb'\n",
    "            else:\n",
    "                name = 'xgb'\n",
    "            \n",
    "            sam.reset_meta_model(clf)\n",
    "            predictions = sam.predict_proba(test_X)[:,1]\n",
    "            print(\"Fold {}, meta model ({} tuner) predictions\\n\".format(fold, name), predictions)\n",
    "        \n",
    "            submission = pd.DataFrame()\n",
    "            submission['id'] = test_ids\n",
    "            submission['is_iceberg'] = predictions\n",
    "            submission.to_csv('Submissions/submission_{}_sam_0117_auto_fine_tune_fold_{}.csv'.format(name, fold), \n",
    "                              float_format=\"%.15f\", index=False)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
